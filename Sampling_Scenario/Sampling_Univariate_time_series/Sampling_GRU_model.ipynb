{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling - Baseline : GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "import lightgbm\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with former MRR X data\n",
    "def get_orig_data(dataset):\n",
    "\n",
    "    train_orig = pd.read_csv(f'./data/{dataset}/train.csv', sep=',', index_col=0).reset_index(drop=True)\n",
    "    test_orig = pd.read_csv(f'./data/{dataset}/test.csv', sep=',', index_col=0).reset_index(drop=True)\n",
    "\n",
    "    short_sampled_orig = train_orig.iloc[316*2:, :].reset_index(drop=True)\n",
    "    former_mrr_sampled = train_orig.iloc[:-316*2, -1].rename('former_MRR').reset_index(drop=True)\n",
    "    addmrr_sampled_orig = pd.concat([short_sampled_orig, former_mrr_sampled], axis=1)\n",
    "    fmrr_scaler = MinMaxScaler().fit(addmrr_sampled_orig[['former_MRR']])\n",
    "    addmrr_sampled_orig['former_MRR'] = fmrr_scaler.transform(addmrr_sampled_orig[['former_MRR']])\n",
    "\n",
    "    short_unsampled_orig = train_orig.iloc[316*1:, :].reset_index(drop=True)\n",
    "    former_mrr_unsampled = train_orig.iloc[:-316*1, -1].rename('former_MRR').reset_index(drop=True)\n",
    "    addmrr_unsampled_orig = pd.concat([short_unsampled_orig, former_mrr_unsampled], axis=1)\n",
    "    addmrr_unsampled_orig['former_MRR'] = fmrr_scaler.transform(addmrr_unsampled_orig[['former_MRR']])\n",
    "\n",
    "    former_mrr_test = pd.concat([train_orig.iloc[-316*1:, -1], test_orig.iloc[:-316*1, -1]], ignore_index=True).rename(\"former_MRR\").reset_index(drop=True)\n",
    "    addmrr_test_orig = pd.concat([test_orig, former_mrr_test], axis=1)\n",
    "    addmrr_test_orig['former_MRR'] = fmrr_scaler.transform(addmrr_test_orig[['former_MRR']])\n",
    "    \n",
    "    return addmrr_sampled_orig, addmrr_unsampled_orig, addmrr_test_orig\n",
    "\n",
    "def get_stats_data(data):\n",
    "    orig_X = data.iloc[:, :-2].to_numpy()\n",
    "    orig_X = orig_X.reshape(-1, 316, orig_X.shape[1])\n",
    "    orig_y = data.iloc[:, -2].tolist()\n",
    "    data_y = [orig_y[i] for i in range(0, len(orig_y), 316)]\n",
    "    former_mrr = data.iloc[:, -1].tolist()\n",
    "    former_mrr = [former_mrr[i] for i in range(0, len(former_mrr), 316)]\n",
    "    \n",
    "    # calculate statistics\n",
    "    means = np.mean(orig_X, axis=1)\n",
    "    stds = np.std(orig_X, axis=1)\n",
    "    medians = np.median(orig_X, axis=1)\n",
    "    mins = np.min(orig_X, axis=1)\n",
    "    maxs = np.max(orig_X, axis=1)\n",
    "    kurts = kurtosis(orig_X, axis=1)\n",
    "    skews = skew(orig_X, axis=1)\n",
    "    stats_X = np.hstack([means, stds, medians, mins, maxs, kurts, skews])\n",
    "    stats_X = np.nan_to_num(stats_X, nan=0.0)\n",
    "\n",
    "    # add MRR\n",
    "    former_mrr = np.array(former_mrr).reshape(-1,1)\n",
    "    data_X = np.concatenate((stats_X, former_mrr), axis=1)\n",
    "\n",
    "    return data_X, data_y\n",
    "\n",
    "def fit_XGB(X_train, y_train):\n",
    "    import xgboost as xgb\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # 回歸問題\n",
    "        'max_depth': 3,                    # 樹的最大深度\n",
    "        'learning_rate': 0.01,              # 學習率\n",
    "        'n_estimators': 200                # 樹的數量\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def fit_RF(X_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def fit_KNN(X_train, y_train):\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    model = KNeighborsRegressor(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def fit_MLP(X_train, y_train):\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    model = MLPRegressor(hidden_layer_sizes=(128, 16), activation='relu', solver='adam', max_iter=2000, random_state=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def get_Stats_pred(dataset, mode_type):  # model_type: 'XGB'/'RF'/'KNN'\n",
    "    \n",
    "    addmrr_sampled_orig, addmrr_unsampled_orig, addmrr_test_orig = get_orig_data(dataset)\n",
    "    # retain only sampled section\n",
    "    sampled_train_orig = pd.concat([addmrr_sampled_orig.iloc[i:i+316] for i in range(0, len(addmrr_sampled_orig), 316*2)], ignore_index=True)\n",
    "    unsampled_train_orig = pd.concat([addmrr_unsampled_orig.iloc[i:i+316] for i in range(316, len(addmrr_unsampled_orig), 316*2)], ignore_index=True)\n",
    "    #test_orig = pd.concat([test_orig.iloc[i:i+316] for i in range(0, len(test_orig), 316*2)], ignore_index=True)\n",
    "\n",
    "    all_test_orig = pd.concat([unsampled_train_orig, addmrr_test_orig], ignore_index=True)\n",
    "    extend_test_orig = pd.concat([addmrr_unsampled_orig.iloc[-316*4:], addmrr_test_orig], ignore_index=True)\n",
    "\n",
    "    y_pred = {}\n",
    "    X_train, y_train = get_stats_data(sampled_train_orig)\n",
    "\n",
    "    data_modes = {'unsampled':unsampled_train_orig, 'test':addmrr_test_orig, 'all':all_test_orig, 'extend':extend_test_orig}\n",
    "    for mode, data in data_modes.items():\n",
    "        match mode_type:\n",
    "            case 'XGB':\n",
    "                model = fit_XGB(X_train, y_train)\n",
    "            case 'RF':\n",
    "                model = fit_RF(X_train, y_train)\n",
    "            case 'KNN':\n",
    "                model = fit_KNN(X_train, y_train)\n",
    "            case 'MLP':\n",
    "                model = fit_MLP(X_train, y_train)\n",
    "\n",
    "        X_test, y_test = get_stats_data(data)\n",
    "        pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, pred)\n",
    "\n",
    "        print('------------------------------------------------')\n",
    "        print(mode)\n",
    "        print(f\"statistic-{mode_type} VM test loss\", round(mse, 3))\n",
    "        y_pred[mode] = model.predict(X_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PHM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x000001EC9690A770>\n",
      "NVIDIA GeForce RTX 3090 Ti\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "# check GPU situation\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to seed random seed\n",
    "def setup_seed(seed):\n",
    "     random.seed(seed)\n",
    "     np.random.seed(seed)\n",
    "     if torch.cuda.is_available():\n",
    "          torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "     torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data\n",
    "def get_data(dataset):\n",
    "    data = pd.read_csv(f'./data/{dataset}_MRR.csv')\n",
    "    mrr_data = data['MRR']\n",
    "    mrr_train = mrr_data[:int(len(mrr_data) * 0.7)]\n",
    "    mrr_test = mrr_data[int(len(mrr_data) * 0.7):] \n",
    "\n",
    "    return mrr_train, mrr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer raw data to dataset class\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data, data_orig, past_wafer, future_step, mode='train'):\n",
    "        data = torch.tensor(data)\n",
    "        data_orig = torch.tensor(data_orig.values)\n",
    "        seqs = []\n",
    "        tars = []\n",
    "        future_step = future_step - 1\n",
    "        rang = range(past_wafer, len(data) - future_step, 2) if mode == 'train' else range(past_wafer, len(data) - future_step)\n",
    "        for i in rang:\n",
    "            seq = data[i - past_wafer:i]\n",
    "            tar = data_orig[i + future_step]\n",
    "            seqs.append(seq)\n",
    "            tars.append(tar)\n",
    "        \n",
    "        self.x = torch.unsqueeze(torch.stack(seqs), 2).contiguous()\n",
    "        self.y = torch.stack(tars).contiguous()\n",
    "        self.len = len(seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = self.x[idx].double()\n",
    "        y = self.y[idx].double()\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU model setting\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(self, input_dim, inter_dim, layer_num):\n",
    "        super(GRUmodel, self).__init__()\n",
    "        self.inter_dim = inter_dim\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "        # define GRU layer\n",
    "        self.gru = nn.GRU(input_dim, inter_dim, layer_num, batch_first=True)\n",
    "\n",
    "        # define MLP layer\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(inter_dim, 1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # initialize original memory\n",
    "        h0 = torch.zeros(self.layer_num, x.size(0), self.inter_dim).double().to(x.device)\n",
    "\n",
    "        # forward propagation，x size (batch_size, sequence_length, input_dim)\n",
    "        out, _ = self.gru(x, h0)\n",
    "\n",
    "        # retain the last memory\n",
    "        out = self.mlp(out[:, -1, :])\n",
    "\n",
    "        return out.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train_dataloader and val_dataloader from train_dataset\n",
    "def get_loaders(train_dataset, seed, batch_size, val_ratio=0.1):\n",
    "    dataset_len = int(len(train_dataset))\n",
    "    train_use_len = int(dataset_len * (1 - val_ratio))\n",
    "    val_use_len = int(dataset_len * val_ratio)\n",
    "    val_start_index = random.randrange(train_use_len)\n",
    "    indices = torch.arange(dataset_len)\n",
    "\n",
    "    train_sub_indices = torch.cat([indices[:val_start_index], indices[val_start_index+val_use_len:]])\n",
    "    train_subset = Subset(train_dataset, train_sub_indices)\n",
    "\n",
    "    val_sub_indices = indices[val_start_index:val_start_index+val_use_len]\n",
    "    val_subset = Subset(train_dataset, val_sub_indices)\n",
    "\n",
    "    train_dataloader = DataLoader(train_subset, batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "    val_dataloader = DataLoader(val_subset, batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    test_pred_list = []\n",
    "    test_ground_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    for x, y in test_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model = model.double()\n",
    "            out = model(x).to(device)\n",
    "            loss = F.mse_loss(out, y, reduction='mean')\n",
    "            \n",
    "            test_pred_list.extend(out.detach().cpu().tolist())\n",
    "            test_ground_list.extend(y.detach().cpu().tolist())\n",
    "            \n",
    "        loss_list.append(loss.detach().cpu().item())\n",
    "    \n",
    "    avg_loss = sum(loss_list)/len(loss_list)\n",
    "\n",
    "    return avg_loss, [test_pred_list, test_ground_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, optimizer, epoch, device, path):\n",
    "    min_loss = 1e+8\n",
    "    early_stop_win = 30\n",
    "\n",
    "    for i_epoch in range(epoch):\n",
    "\n",
    "        loss_list = []\n",
    "        acu_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model = model.double()\n",
    "            out = model(x).to(device)\n",
    "            loss = F.mse_loss(out, y, reduction='mean')\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            acu_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "\n",
    "        # early stopping by validation\n",
    "        if val_dataloader is not None:\n",
    "\n",
    "            val_loss, val_result = test(model, val_dataloader, 'cuda')\n",
    "\n",
    "            if val_loss < min_loss:\n",
    "                torch.save(model.state_dict(), path)\n",
    "\n",
    "                min_loss = val_loss\n",
    "                stop_improve_count = 0\n",
    "            else:\n",
    "                stop_improve_count += 1\n",
    "\n",
    "            if stop_improve_count >= early_stop_win:\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            if acu_loss < min_loss:\n",
    "                torch.save(model.state_dict(), path)\n",
    "                min_loss = acu_loss\n",
    "\n",
    "        # print each epoch\n",
    "        print(\n",
    "            'epoch ({} / {}) (Train_loss:{:.8f}, ACU_loss:{:.8f}, Val_loss:{:.8f})'\n",
    "            .format(\n",
    "                i_epoch + 1,\n",
    "                epoch,\n",
    "                acu_loss / len(train_dataloader),\n",
    "                acu_loss,\n",
    "                val_loss,\n",
    "            ),\n",
    "            flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併VM資料\n",
    "def combine_vm_data(train, test, vm_train, vm_test):\n",
    "    train = train[2:].reset_index(drop=True)\n",
    "    com_trian = [train[i] if i % 2 == 0 else vm_train[int(i / 2)] for i in range(len(train))]\n",
    "    test = test.reset_index(drop=True)\n",
    "    com_test = [test[i] if i % 2 == 0 else vm_test[i] for i in range(len(test))]\n",
    "\n",
    "    return com_trian, com_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "dataset = 'A456'\n",
    "batch_size = 8\n",
    "input_dim = 1\n",
    "inter_dim = 64\n",
    "layer_num = 1\n",
    "past_wafer = 4\n",
    "future_step = 1\n",
    "val_ratio = 0.3\n",
    "seed = 2\n",
    "\n",
    "# set random seed\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "unsampled\n",
      "statistic-RF VM test loss 4.381\n",
      "------------------------------------------------\n",
      "test\n",
      "statistic-RF VM test loss 12.192\n",
      "------------------------------------------------\n",
      "all\n",
      "statistic-RF VM test loss 7.993\n",
      "------------------------------------------------\n",
      "extend\n",
      "statistic-RF VM test loss 12.179\n"
     ]
    }
   ],
   "source": [
    "# get training and testing dataset\n",
    "train_orig, test_orig = get_data(dataset)\n",
    "# concat the first n wafer data from training set\n",
    "test_extend = pd.concat((train_orig[-past_wafer:], test_orig))\n",
    "\n",
    "vm_pred = get_Stats_pred(dataset,'RF')\n",
    "vm_train = vm_pred['unsampled']\n",
    "vm_test = vm_pred['extend']\n",
    "com_train, com_test = combine_vm_data(train_orig, test_extend, vm_train, vm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1 / 2000) (Train_loss:4736.97056979, ACU_loss:71054.55854691, Val_loss:5681.08114423)\n",
      "epoch (2 / 2000) (Train_loss:4570.03348613, ACU_loss:68550.50229200, Val_loss:5486.99250867)\n",
      "epoch (3 / 2000) (Train_loss:4368.50667065, ACU_loss:65527.60005970, Val_loss:5255.64622219)\n",
      "epoch (4 / 2000) (Train_loss:4179.46985749, ACU_loss:62692.04786235, Val_loss:5061.76948043)\n",
      "epoch (5 / 2000) (Train_loss:4021.21695303, ACU_loss:60318.25429548, Val_loss:4896.31617296)\n",
      "epoch (6 / 2000) (Train_loss:3887.55501926, ACU_loss:58313.32528891, Val_loss:4755.23171936)\n",
      "epoch (7 / 2000) (Train_loss:3759.73099891, ACU_loss:56395.96498372, Val_loss:4610.31035646)\n",
      "epoch (8 / 2000) (Train_loss:3629.16373808, ACU_loss:54437.45607118, Val_loss:4465.08529309)\n",
      "epoch (9 / 2000) (Train_loss:3509.38430377, ACU_loss:52640.76455650, Val_loss:4337.07715036)\n",
      "epoch (10 / 2000) (Train_loss:3397.00991709, ACU_loss:50955.14875642, Val_loss:4209.90095067)\n",
      "epoch (11 / 2000) (Train_loss:3271.38109326, ACU_loss:49070.71639888, Val_loss:4063.33586819)\n",
      "epoch (12 / 2000) (Train_loss:3149.98050245, ACU_loss:47249.70753680, Val_loss:3923.58453435)\n",
      "epoch (13 / 2000) (Train_loss:3023.93187296, ACU_loss:45358.97809447, Val_loss:3786.52898289)\n",
      "epoch (14 / 2000) (Train_loss:2906.38650412, ACU_loss:43595.79756181, Val_loss:3653.64465201)\n",
      "epoch (15 / 2000) (Train_loss:2795.98069363, ACU_loss:41939.71040448, Val_loss:3533.02487406)\n",
      "epoch (16 / 2000) (Train_loss:2692.76432328, ACU_loss:40391.46484917, Val_loss:3418.01721203)\n",
      "epoch (17 / 2000) (Train_loss:2594.31830463, ACU_loss:38914.77456947, Val_loss:3307.75887374)\n",
      "epoch (18 / 2000) (Train_loss:2499.96932992, ACU_loss:37499.53994887, Val_loss:3201.61982033)\n",
      "epoch (19 / 2000) (Train_loss:2409.24101467, ACU_loss:36138.61522011, Val_loss:3099.16729010)\n",
      "epoch (20 / 2000) (Train_loss:2321.80031098, ACU_loss:34827.00466470, Val_loss:3000.09299637)\n",
      "epoch (21 / 2000) (Train_loss:2237.40279303, ACU_loss:33561.04189551, Val_loss:2904.16544144)\n",
      "epoch (22 / 2000) (Train_loss:2155.85961610, ACU_loss:32337.89424146, Val_loss:2811.20245991)\n",
      "epoch (23 / 2000) (Train_loss:2077.01839879, ACU_loss:31155.27598190, Val_loss:2721.05512265)\n",
      "epoch (24 / 2000) (Train_loss:2000.75191510, ACU_loss:30011.27872656, Val_loss:2633.59792782)\n",
      "epoch (25 / 2000) (Train_loss:1926.95214321, ACU_loss:28904.28214820, Val_loss:2548.72318637)\n",
      "epoch (26 / 2000) (Train_loss:1855.52422387, ACU_loss:27832.86335807, Val_loss:2466.33574692)\n",
      "epoch (27 / 2000) (Train_loss:1786.38246156, ACU_loss:26795.73692340, Val_loss:2386.35018027)\n",
      "epoch (28 / 2000) (Train_loss:1719.44965447, ACU_loss:25791.74481703, Val_loss:2308.68910737)\n",
      "epoch (29 / 2000) (Train_loss:1654.65513427, ACU_loss:24819.82701402, Val_loss:2233.28151889)\n",
      "epoch (30 / 2000) (Train_loss:1591.93343786, ACU_loss:23879.00156787, Val_loss:2160.06158112)\n",
      "epoch (31 / 2000) (Train_loss:1531.22337786, ACU_loss:22968.35066790, Val_loss:2088.96774037)\n",
      "epoch (32 / 2000) (Train_loss:1472.46733350, ACU_loss:22087.01000247, Val_loss:2019.94202952)\n",
      "epoch (33 / 2000) (Train_loss:1415.61069690, ACU_loss:21234.16045343, Val_loss:1952.92952237)\n",
      "epoch (34 / 2000) (Train_loss:1360.60143460, ACU_loss:20409.02151895, Val_loss:1887.87789855)\n",
      "epoch (35 / 2000) (Train_loss:1307.38973631, ACU_loss:19610.84604469, Val_loss:1824.73709314)\n",
      "epoch (36 / 2000) (Train_loss:1255.92773071, ACU_loss:18838.91596068, Val_loss:1763.45901158)\n",
      "epoch (37 / 2000) (Train_loss:1206.16925344, ACU_loss:18092.53880160, Val_loss:1703.99729588)\n",
      "epoch (38 / 2000) (Train_loss:1158.06965628, ACU_loss:17371.04484414, Val_loss:1646.30713142)\n",
      "epoch (39 / 2000) (Train_loss:1111.58564906, ACU_loss:16673.78473592, Val_loss:1590.34508621)\n",
      "epoch (40 / 2000) (Train_loss:1066.67516796, ACU_loss:16000.12751944, Val_loss:1536.06897638)\n",
      "epoch (41 / 2000) (Train_loss:1023.29726510, ACU_loss:15349.45897646, Val_loss:1483.43775301)\n",
      "epoch (42 / 2000) (Train_loss:981.41201561, ACU_loss:14721.18023422, Val_loss:1432.41140648)\n",
      "epoch (43 / 2000) (Train_loss:940.98043916, ACU_loss:14114.70658741, Val_loss:1382.95088532)\n",
      "epoch (44 / 2000) (Train_loss:901.96443325, ACU_loss:13529.46649876, Val_loss:1335.01802697)\n",
      "epoch (45 / 2000) (Train_loss:864.32671660, ACU_loss:12964.90074894, Val_loss:1288.57549875)\n",
      "epoch (46 / 2000) (Train_loss:828.03078076, ACU_loss:12420.46171145, Val_loss:1243.58674721)\n",
      "epoch (47 / 2000) (Train_loss:793.04084887, ACU_loss:11895.61273300, Val_loss:1200.01595459)\n",
      "epoch (48 / 2000) (Train_loss:759.32184022, ACU_loss:11389.82760331, Val_loss:1157.82800148)\n",
      "epoch (49 / 2000) (Train_loss:726.83934006, ACU_loss:10902.59010096, Val_loss:1116.98843453)\n",
      "epoch (50 / 2000) (Train_loss:695.55957361, ACU_loss:10433.39360419, Val_loss:1077.46343866)\n",
      "epoch (51 / 2000) (Train_loss:665.44938383, ACU_loss:9981.74075740, Val_loss:1039.21981309)\n",
      "epoch (52 / 2000) (Train_loss:636.47621236, ACU_loss:9547.14318544, Val_loss:1002.22495056)\n",
      "epoch (53 / 2000) (Train_loss:608.60808328, ACU_loss:9129.12124925, Val_loss:966.44681951)\n",
      "epoch (54 / 2000) (Train_loss:581.81358913, ACU_loss:8727.20383699, Val_loss:931.85394862)\n",
      "epoch (55 / 2000) (Train_loss:556.06187907, ACU_loss:8340.92818601, Val_loss:898.41541347)\n",
      "epoch (56 / 2000) (Train_loss:531.32264876, ACU_loss:7969.83973139, Val_loss:866.10082508)\n",
      "epoch (57 / 2000) (Train_loss:507.56613184, ACU_loss:7613.49197758, Val_loss:834.88032007)\n",
      "epoch (58 / 2000) (Train_loss:484.76309266, ACU_loss:7271.44638985, Val_loss:804.72455212)\n",
      "epoch (59 / 2000) (Train_loss:462.88482020, ACU_loss:6943.27230301, Val_loss:775.60468469)\n",
      "epoch (60 / 2000) (Train_loss:441.90312299, ACU_loss:6628.54684489, Val_loss:747.49238481)\n",
      "epoch (61 / 2000) (Train_loss:421.79032483, ACU_loss:6326.85487243, Val_loss:720.35981767)\n",
      "epoch (62 / 2000) (Train_loss:402.51926125, ACU_loss:6037.78891873, Val_loss:694.17964209)\n",
      "epoch (63 / 2000) (Train_loss:384.06327661, ACU_loss:5760.94914910, Val_loss:668.92500655)\n",
      "epoch (64 / 2000) (Train_loss:366.39622166, ACU_loss:5495.94332485, Val_loss:644.56954585)\n",
      "epoch (65 / 2000) (Train_loss:349.49245156, ACU_loss:5242.38677345, Val_loss:621.08737821)\n",
      "epoch (66 / 2000) (Train_loss:333.32682425, ACU_loss:4999.90236376, Val_loss:598.45310275)\n",
      "epoch (67 / 2000) (Train_loss:317.87469902, ACU_loss:4768.12048533, Val_loss:576.64179730)\n",
      "epoch (68 / 2000) (Train_loss:303.11193539, ACU_loss:4546.67903088, Val_loss:555.62901647)\n",
      "epoch (69 / 2000) (Train_loss:289.01489206, ACU_loss:4335.22338083, Val_loss:535.39078988)\n",
      "epoch (70 / 2000) (Train_loss:275.56042596, ACU_loss:4133.40638940, Val_loss:515.90362055)\n",
      "epoch (71 / 2000) (Train_loss:262.72589141, ACU_loss:3940.88837116, Val_loss:497.14448341)\n",
      "epoch (72 / 2000) (Train_loss:250.48913919, ACU_loss:3757.33708782, Val_loss:479.09082379)\n",
      "epoch (73 / 2000) (Train_loss:238.82851561, ACU_loss:3582.42773421, Val_loss:461.72055596)\n",
      "epoch (74 / 2000) (Train_loss:227.72286155, ACU_loss:3415.84292320, Val_loss:445.01206166)\n",
      "epoch (75 / 2000) (Train_loss:217.15151126, ACU_loss:3257.27266891, Val_loss:428.94418851)\n",
      "epoch (76 / 2000) (Train_loss:207.09429119, ACU_loss:3106.41436786, Val_loss:413.49624838)\n",
      "epoch (77 / 2000) (Train_loss:197.53151850, ACU_loss:2962.97277753, Val_loss:398.64801560)\n",
      "epoch (78 / 2000) (Train_loss:188.44399947, ACU_loss:2826.65999203, Val_loss:384.37972507)\n",
      "epoch (79 / 2000) (Train_loss:179.81302764, ACU_loss:2697.19541456, Val_loss:370.67207021)\n",
      "epoch (80 / 2000) (Train_loss:171.62038176, ACU_loss:2574.30572638, Val_loss:357.50620063)\n",
      "epoch (81 / 2000) (Train_loss:163.84832346, ACU_loss:2457.72485188, Val_loss:344.86371975)\n",
      "epoch (82 / 2000) (Train_loss:156.47959465, ACU_loss:2347.19391981, Val_loss:332.72668211)\n",
      "epoch (83 / 2000) (Train_loss:149.49741468, ACU_loss:2242.46122019, Val_loss:321.07759046)\n",
      "epoch (84 / 2000) (Train_loss:142.88547713, ACU_loss:2143.28215694, Val_loss:309.89939266)\n",
      "epoch (85 / 2000) (Train_loss:136.62794640, ACU_loss:2049.41919602, Val_loss:299.17547829)\n",
      "epoch (86 / 2000) (Train_loss:130.70945393, ACU_loss:1960.64180896, Val_loss:288.88967506)\n",
      "epoch (87 / 2000) (Train_loss:125.11509412, ACU_loss:1876.72641185, Val_loss:279.02624490)\n",
      "epoch (88 / 2000) (Train_loss:119.83041997, ACU_loss:1797.45629954, Val_loss:269.56987985)\n",
      "epoch (89 / 2000) (Train_loss:114.84143835, ACU_loss:1722.62157521, Val_loss:260.50569770)\n",
      "epoch (90 / 2000) (Train_loss:110.13460502, ACU_loss:1652.01907529, Val_loss:251.81923731)\n",
      "epoch (91 / 2000) (Train_loss:105.69681931, ACU_loss:1585.45228967, Val_loss:243.49645372)\n",
      "epoch (92 / 2000) (Train_loss:101.51541850, ACU_loss:1522.73127743, Val_loss:235.52371303)\n",
      "epoch (93 / 2000) (Train_loss:97.57817187, ACU_loss:1463.67257801, Val_loss:227.88778698)\n",
      "epoch (94 / 2000) (Train_loss:93.87327454, ACU_loss:1408.09911805, Val_loss:220.57584733)\n",
      "epoch (95 / 2000) (Train_loss:90.38934093, ACU_loss:1355.84011395, Val_loss:213.57545999)\n",
      "epoch (96 / 2000) (Train_loss:87.11539803, ACU_loss:1306.73097039, Val_loss:206.87457894)\n",
      "epoch (97 / 2000) (Train_loss:84.04087832, ACU_loss:1260.61317487, Val_loss:200.46153992)\n",
      "epoch (98 / 2000) (Train_loss:81.15561257, ACU_loss:1217.33418851, Val_loss:194.32505393)\n",
      "epoch (99 / 2000) (Train_loss:78.44982222, ACU_loss:1176.74733333, Val_loss:188.45420056)\n",
      "epoch (100 / 2000) (Train_loss:75.91411175, ACU_loss:1138.71167624, Val_loss:182.83842106)\n",
      "epoch (101 / 2000) (Train_loss:73.53946065, ACU_loss:1103.09190979, Val_loss:177.46751135)\n",
      "epoch (102 / 2000) (Train_loss:71.31721535, ACU_loss:1069.75823024, Val_loss:172.33161484)\n",
      "epoch (103 / 2000) (Train_loss:69.23908086, ACU_loss:1038.58621285, Val_loss:167.42121502)\n",
      "epoch (104 / 2000) (Train_loss:67.29711233, ACU_loss:1009.45668493, Val_loss:162.72712812)\n",
      "epoch (105 / 2000) (Train_loss:65.48370645, ACU_loss:982.25559676, Val_loss:158.24049547)\n",
      "epoch (106 / 2000) (Train_loss:63.79159271, ACU_loss:956.87389063, Val_loss:153.95277587)\n",
      "epoch (107 / 2000) (Train_loss:62.21382456, ACU_loss:933.20736840, Val_loss:149.85573786)\n",
      "epoch (108 / 2000) (Train_loss:60.74377052, ACU_loss:911.15655774, Val_loss:145.94145197)\n",
      "epoch (109 / 2000) (Train_loss:59.37510516, ACU_loss:890.62657739, Val_loss:142.20228280)\n",
      "epoch (110 / 2000) (Train_loss:58.10180011, ACU_loss:871.52700166, Val_loss:138.63088123)\n",
      "epoch (111 / 2000) (Train_loss:56.91811497, ACU_loss:853.77172450, Val_loss:135.22017650)\n",
      "epoch (112 / 2000) (Train_loss:55.81858822, ACU_loss:837.27882335, Val_loss:131.96336833)\n",
      "epoch (113 / 2000) (Train_loss:54.79802821, ACU_loss:821.97042313, Val_loss:128.85391905)\n",
      "epoch (114 / 2000) (Train_loss:53.85150403, ACU_loss:807.77256048, Val_loss:125.88554579)\n",
      "epoch (115 / 2000) (Train_loss:52.97433658, ACU_loss:794.61504867, Val_loss:123.05221262)\n",
      "epoch (116 / 2000) (Train_loss:52.16208955, ACU_loss:782.43134328, Val_loss:120.34812286)\n",
      "epoch (117 / 2000) (Train_loss:51.41056060, ACU_loss:771.15840898, Val_loss:117.76771140)\n",
      "epoch (118 / 2000) (Train_loss:50.71577251, ACU_loss:760.73658762, Val_loss:115.30563707)\n",
      "epoch (119 / 2000) (Train_loss:50.07396452, ACU_loss:751.10946781, Val_loss:112.95677517)\n",
      "epoch (120 / 2000) (Train_loss:49.48158374, ACU_loss:742.22375617, Val_loss:110.71621008)\n",
      "epoch (121 / 2000) (Train_loss:48.93527671, ACU_loss:734.02915059, Val_loss:108.57922795)\n",
      "epoch (122 / 2000) (Train_loss:48.43188103, ACU_loss:726.47821549, Val_loss:106.54130954)\n",
      "epoch (123 / 2000) (Train_loss:47.96841729, ACU_loss:719.52625938, Val_loss:104.59812320)\n",
      "epoch (124 / 2000) (Train_loss:47.54208099, ACU_loss:713.13121479, Val_loss:102.74551797)\n",
      "epoch (125 / 2000) (Train_loss:47.15023472, ACU_loss:707.25352081, Val_loss:100.97951684)\n",
      "epoch (126 / 2000) (Train_loss:46.79040055, ACU_loss:701.85600825, Val_loss:99.29631016)\n",
      "epoch (127 / 2000) (Train_loss:46.46025251, ACU_loss:696.90378762, Val_loss:97.69224917)\n",
      "epoch (128 / 2000) (Train_loss:46.15760934, ACU_loss:692.36414005, Val_loss:96.16383980)\n",
      "epoch (129 / 2000) (Train_loss:45.88042741, ACU_loss:688.20641109, Val_loss:94.70773647)\n",
      "epoch (130 / 2000) (Train_loss:45.62679385, ACU_loss:684.40190768, Val_loss:93.32073625)\n",
      "epoch (131 / 2000) (Train_loss:45.39491988, ACU_loss:680.92379813, Val_loss:91.99977304)\n",
      "epoch (132 / 2000) (Train_loss:45.18313436, ACU_loss:677.74701539, Val_loss:90.74191199)\n",
      "epoch (133 / 2000) (Train_loss:44.98987755, ACU_loss:674.84816327, Val_loss:89.54434411)\n",
      "epoch (134 / 2000) (Train_loss:44.81369486, ACU_loss:672.20542295, Val_loss:88.40438239)\n",
      "epoch (135 / 2000) (Train_loss:44.65323072, ACU_loss:669.79846073, Val_loss:87.31975435)\n",
      "epoch (136 / 2000) (Train_loss:44.52226774, ACU_loss:667.83401613, Val_loss:86.30221618)\n",
      "epoch (137 / 2000) (Train_loss:44.37684469, ACU_loss:665.65267030, Val_loss:85.47807400)\n",
      "epoch (138 / 2000) (Train_loss:45.10224705, ACU_loss:676.53370579, Val_loss:84.05112008)\n",
      "epoch (139 / 2000) (Train_loss:44.03333838, ACU_loss:660.50007563, Val_loss:83.05629257)\n",
      "epoch (140 / 2000) (Train_loss:43.98043648, ACU_loss:659.70654724, Val_loss:82.22457215)\n",
      "epoch (141 / 2000) (Train_loss:43.89956393, ACU_loss:658.49345891, Val_loss:81.44938366)\n",
      "epoch (142 / 2000) (Train_loss:43.79468437, ACU_loss:656.92026552, Val_loss:80.78251242)\n",
      "epoch (143 / 2000) (Train_loss:43.74774022, ACU_loss:656.21610331, Val_loss:80.50992433)\n",
      "epoch (144 / 2000) (Train_loss:43.44049394, ACU_loss:651.60740915, Val_loss:79.59589777)\n",
      "epoch (145 / 2000) (Train_loss:42.85581522, ACU_loss:642.83722829, Val_loss:81.22335796)\n",
      "epoch (146 / 2000) (Train_loss:41.77282489, ACU_loss:626.59237338, Val_loss:78.51777654)\n",
      "epoch (147 / 2000) (Train_loss:41.37354910, ACU_loss:620.60323656, Val_loss:79.80281013)\n",
      "epoch (148 / 2000) (Train_loss:39.66750906, ACU_loss:595.01263590, Val_loss:77.82190352)\n",
      "epoch (149 / 2000) (Train_loss:38.69263073, ACU_loss:580.38946100, Val_loss:77.04457919)\n",
      "epoch (150 / 2000) (Train_loss:35.85516063, ACU_loss:537.82740941, Val_loss:75.28808942)\n",
      "epoch (151 / 2000) (Train_loss:33.88232016, ACU_loss:508.23480236, Val_loss:73.85598757)\n",
      "epoch (152 / 2000) (Train_loss:32.83129447, ACU_loss:492.46941705, Val_loss:71.66791989)\n",
      "epoch (153 / 2000) (Train_loss:29.91004947, ACU_loss:448.65074198, Val_loss:70.50816396)\n",
      "epoch (154 / 2000) (Train_loss:27.82455348, ACU_loss:417.36830219, Val_loss:67.86492894)\n",
      "epoch (155 / 2000) (Train_loss:26.85708386, ACU_loss:402.85625790, Val_loss:66.11566558)\n",
      "epoch (156 / 2000) (Train_loss:25.70592279, ACU_loss:385.58884187, Val_loss:63.98566896)\n",
      "epoch (157 / 2000) (Train_loss:24.00986219, ACU_loss:360.14793278, Val_loss:61.94819665)\n",
      "epoch (158 / 2000) (Train_loss:23.27237502, ACU_loss:349.08562535, Val_loss:60.13340834)\n",
      "epoch (159 / 2000) (Train_loss:21.59436711, ACU_loss:323.91550662, Val_loss:58.67086786)\n",
      "epoch (160 / 2000) (Train_loss:19.88808314, ACU_loss:298.32124706, Val_loss:57.01361059)\n",
      "epoch (161 / 2000) (Train_loss:18.58084609, ACU_loss:278.71269135, Val_loss:55.51804682)\n",
      "epoch (162 / 2000) (Train_loss:17.50231845, ACU_loss:262.53477674, Val_loss:53.88524396)\n",
      "epoch (163 / 2000) (Train_loss:16.71337532, ACU_loss:250.70062976, Val_loss:51.88130138)\n",
      "epoch (164 / 2000) (Train_loss:16.69220786, ACU_loss:250.38311788, Val_loss:50.51648507)\n",
      "epoch (165 / 2000) (Train_loss:16.08789321, ACU_loss:241.31839819, Val_loss:48.62131007)\n",
      "epoch (166 / 2000) (Train_loss:16.09399152, ACU_loss:241.40987280, Val_loss:47.52955405)\n",
      "epoch (167 / 2000) (Train_loss:15.22324524, ACU_loss:228.34867856, Val_loss:46.08023516)\n",
      "epoch (168 / 2000) (Train_loss:14.42298078, ACU_loss:216.34471171, Val_loss:44.90830325)\n",
      "epoch (169 / 2000) (Train_loss:13.53549443, ACU_loss:203.03241645, Val_loss:43.75749308)\n",
      "epoch (170 / 2000) (Train_loss:12.80133707, ACU_loss:192.02005610, Val_loss:42.58774864)\n",
      "epoch (171 / 2000) (Train_loss:12.27324253, ACU_loss:184.09863801, Val_loss:41.40112853)\n",
      "epoch (172 / 2000) (Train_loss:11.91346113, ACU_loss:178.70191702, Val_loss:40.29920832)\n",
      "epoch (173 / 2000) (Train_loss:11.58975566, ACU_loss:173.84633488, Val_loss:38.99770698)\n",
      "epoch (174 / 2000) (Train_loss:11.73570828, ACU_loss:176.03562418, Val_loss:38.15932545)\n",
      "epoch (175 / 2000) (Train_loss:11.20703667, ACU_loss:168.10554998, Val_loss:36.91826847)\n",
      "epoch (176 / 2000) (Train_loss:11.34233363, ACU_loss:170.13500447, Val_loss:36.14374804)\n",
      "epoch (177 / 2000) (Train_loss:10.78605434, ACU_loss:161.79081512, Val_loss:35.21082177)\n",
      "epoch (178 / 2000) (Train_loss:10.28120523, ACU_loss:154.21807841, Val_loss:34.31040296)\n",
      "epoch (179 / 2000) (Train_loss:9.87693387, ACU_loss:148.15400808, Val_loss:33.46604267)\n",
      "epoch (180 / 2000) (Train_loss:9.58990201, ACU_loss:143.84853019, Val_loss:32.72343678)\n",
      "epoch (181 / 2000) (Train_loss:9.08247528, ACU_loss:136.23712921, Val_loss:31.92099958)\n",
      "epoch (182 / 2000) (Train_loss:8.67997567, ACU_loss:130.19963512, Val_loss:31.15202919)\n",
      "epoch (183 / 2000) (Train_loss:8.43025389, ACU_loss:126.45380841, Val_loss:30.43375770)\n",
      "epoch (184 / 2000) (Train_loss:8.10126826, ACU_loss:121.51902389, Val_loss:29.71230510)\n",
      "epoch (185 / 2000) (Train_loss:7.82643920, ACU_loss:117.39658807, Val_loss:29.01620067)\n",
      "epoch (186 / 2000) (Train_loss:7.58999642, ACU_loss:113.84994626, Val_loss:28.33646626)\n",
      "epoch (187 / 2000) (Train_loss:7.36592786, ACU_loss:110.48891794, Val_loss:27.67200286)\n",
      "epoch (188 / 2000) (Train_loss:7.15570896, ACU_loss:107.33563433, Val_loss:27.02573201)\n",
      "epoch (189 / 2000) (Train_loss:6.95872233, ACU_loss:104.38083496, Val_loss:26.39639518)\n",
      "epoch (190 / 2000) (Train_loss:6.77209553, ACU_loss:101.58143294, Val_loss:25.78576254)\n",
      "epoch (191 / 2000) (Train_loss:6.59252219, ACU_loss:98.88783278, Val_loss:25.19618610)\n",
      "epoch (192 / 2000) (Train_loss:6.41746322, ACU_loss:96.26194834, Val_loss:24.62867549)\n",
      "epoch (193 / 2000) (Train_loss:6.24517573, ACU_loss:93.67763590, Val_loss:24.08341730)\n",
      "epoch (194 / 2000) (Train_loss:6.07478013, ACU_loss:91.12170194, Val_loss:23.55926802)\n",
      "epoch (195 / 2000) (Train_loss:5.90679433, ACU_loss:88.60191491, Val_loss:23.05006453)\n",
      "epoch (196 / 2000) (Train_loss:5.74505357, ACU_loss:86.17580356, Val_loss:22.54694813)\n",
      "epoch (197 / 2000) (Train_loss:5.58863322, ACU_loss:83.82949835, Val_loss:22.03137505)\n",
      "epoch (198 / 2000) (Train_loss:5.43036443, ACU_loss:81.45546642, Val_loss:21.54339084)\n",
      "epoch (199 / 2000) (Train_loss:5.28986395, ACU_loss:79.34795926, Val_loss:21.02568068)\n",
      "epoch (200 / 2000) (Train_loss:5.16366075, ACU_loss:77.45491123, Val_loss:20.53340127)\n",
      "epoch (201 / 2000) (Train_loss:5.08808355, ACU_loss:76.32125320, Val_loss:20.04037604)\n",
      "epoch (202 / 2000) (Train_loss:5.11572308, ACU_loss:76.73584613, Val_loss:19.74733213)\n",
      "epoch (203 / 2000) (Train_loss:5.00735898, ACU_loss:75.11038470, Val_loss:19.56063649)\n",
      "epoch (204 / 2000) (Train_loss:4.97192545, ACU_loss:74.57888176, Val_loss:19.08988381)\n",
      "epoch (205 / 2000) (Train_loss:5.07185731, ACU_loss:76.07785964, Val_loss:18.32336580)\n",
      "epoch (206 / 2000) (Train_loss:5.45600627, ACU_loss:81.84009412, Val_loss:17.94160331)\n",
      "epoch (207 / 2000) (Train_loss:8.51248756, ACU_loss:127.68731335, Val_loss:18.82187674)\n",
      "epoch (208 / 2000) (Train_loss:6.28774604, ACU_loss:94.31619061, Val_loss:20.37976498)\n",
      "epoch (209 / 2000) (Train_loss:5.95664979, ACU_loss:89.34974687, Val_loss:19.36873362)\n",
      "epoch (210 / 2000) (Train_loss:5.26364890, ACU_loss:78.95473356, Val_loss:19.67577955)\n",
      "epoch (211 / 2000) (Train_loss:5.18616512, ACU_loss:77.79247680, Val_loss:19.29541505)\n",
      "epoch (212 / 2000) (Train_loss:5.29768581, ACU_loss:79.46528716, Val_loss:19.15934503)\n",
      "epoch (213 / 2000) (Train_loss:5.15877409, ACU_loss:77.38161141, Val_loss:18.63588714)\n",
      "epoch (214 / 2000) (Train_loss:5.52860611, ACU_loss:82.92909166, Val_loss:18.77867160)\n",
      "epoch (215 / 2000) (Train_loss:5.19003742, ACU_loss:77.85056134, Val_loss:17.95711657)\n",
      "epoch (216 / 2000) (Train_loss:5.41883284, ACU_loss:81.28249259, Val_loss:18.26916684)\n",
      "epoch (217 / 2000) (Train_loss:4.89636175, ACU_loss:73.44542629, Val_loss:17.31663101)\n",
      "epoch (218 / 2000) (Train_loss:5.15023319, ACU_loss:77.25349792, Val_loss:17.53800182)\n",
      "epoch (219 / 2000) (Train_loss:4.70418470, ACU_loss:70.56277051, Val_loss:16.54782979)\n",
      "epoch (220 / 2000) (Train_loss:4.76341522, ACU_loss:71.45122837, Val_loss:16.72485598)\n",
      "epoch (221 / 2000) (Train_loss:4.38834271, ACU_loss:65.82514071, Val_loss:15.85389152)\n",
      "epoch (222 / 2000) (Train_loss:4.46441253, ACU_loss:66.96618795, Val_loss:15.91263446)\n",
      "epoch (223 / 2000) (Train_loss:4.21501447, ACU_loss:63.22521704, Val_loss:15.15766135)\n",
      "epoch (224 / 2000) (Train_loss:4.20209631, ACU_loss:63.03144467, Val_loss:15.22460263)\n",
      "epoch (225 / 2000) (Train_loss:4.02585773, ACU_loss:60.38786595, Val_loss:14.54361313)\n",
      "epoch (226 / 2000) (Train_loss:3.96020224, ACU_loss:59.40303353, Val_loss:14.55711175)\n",
      "epoch (227 / 2000) (Train_loss:3.86831272, ACU_loss:58.02469087, Val_loss:13.96312212)\n",
      "epoch (228 / 2000) (Train_loss:3.70020498, ACU_loss:55.50307465, Val_loss:13.94611485)\n",
      "epoch (229 / 2000) (Train_loss:3.68456816, ACU_loss:55.26852233, Val_loss:13.44176888)\n",
      "epoch (230 / 2000) (Train_loss:3.40994766, ACU_loss:51.14921496, Val_loss:13.39156976)\n",
      "epoch (231 / 2000) (Train_loss:3.40984186, ACU_loss:51.14762796, Val_loss:13.01282185)\n",
      "epoch (232 / 2000) (Train_loss:3.21073179, ACU_loss:48.16097681, Val_loss:12.89510744)\n",
      "epoch (233 / 2000) (Train_loss:3.16956301, ACU_loss:47.54344510, Val_loss:12.55442680)\n",
      "epoch (234 / 2000) (Train_loss:3.04426891, ACU_loss:45.66403366, Val_loss:12.36056572)\n",
      "epoch (235 / 2000) (Train_loss:3.00059117, ACU_loss:45.00886750, Val_loss:12.08059732)\n",
      "epoch (236 / 2000) (Train_loss:2.91688053, ACU_loss:43.75320800, Val_loss:11.87500504)\n",
      "epoch (237 / 2000) (Train_loss:2.86136711, ACU_loss:42.92050663, Val_loss:11.65467153)\n",
      "epoch (238 / 2000) (Train_loss:2.81598112, ACU_loss:42.23971683, Val_loss:11.44318039)\n",
      "epoch (239 / 2000) (Train_loss:2.76882150, ACU_loss:41.53232257, Val_loss:11.26991223)\n",
      "epoch (240 / 2000) (Train_loss:2.86296741, ACU_loss:42.94451111, Val_loss:10.97730370)\n",
      "epoch (241 / 2000) (Train_loss:2.71121426, ACU_loss:40.66821395, Val_loss:10.93490140)\n",
      "epoch (242 / 2000) (Train_loss:2.64094704, ACU_loss:39.61420561, Val_loss:10.62006291)\n",
      "epoch (243 / 2000) (Train_loss:2.80851082, ACU_loss:42.12766223, Val_loss:10.42553291)\n",
      "epoch (244 / 2000) (Train_loss:2.61807783, ACU_loss:39.27116750, Val_loss:10.41521631)\n",
      "epoch (245 / 2000) (Train_loss:2.51920599, ACU_loss:37.78808989, Val_loss:10.08764554)\n",
      "epoch (246 / 2000) (Train_loss:2.63435659, ACU_loss:39.51534890, Val_loss:9.92931828)\n",
      "epoch (247 / 2000) (Train_loss:2.54628071, ACU_loss:38.19421072, Val_loss:9.94562934)\n",
      "epoch (248 / 2000) (Train_loss:2.48805412, ACU_loss:37.32081186, Val_loss:9.60675977)\n",
      "epoch (249 / 2000) (Train_loss:2.61444966, ACU_loss:39.21674493, Val_loss:9.43711407)\n",
      "epoch (250 / 2000) (Train_loss:2.47327711, ACU_loss:37.09915661, Val_loss:9.49814357)\n",
      "epoch (251 / 2000) (Train_loss:2.33680255, ACU_loss:35.05203830, Val_loss:9.14935719)\n",
      "epoch (252 / 2000) (Train_loss:2.32735528, ACU_loss:34.91032922, Val_loss:9.00828323)\n",
      "epoch (253 / 2000) (Train_loss:2.19839068, ACU_loss:32.97586018, Val_loss:8.96417411)\n",
      "epoch (254 / 2000) (Train_loss:2.09213764, ACU_loss:31.38206463, Val_loss:8.69850963)\n",
      "epoch (255 / 2000) (Train_loss:2.03372079, ACU_loss:30.50581189, Val_loss:8.62146283)\n",
      "epoch (256 / 2000) (Train_loss:1.98331236, ACU_loss:29.74968540, Val_loss:8.50196551)\n",
      "epoch (257 / 2000) (Train_loss:1.96547577, ACU_loss:29.48213651, Val_loss:8.26050811)\n",
      "epoch (258 / 2000) (Train_loss:2.10274453, ACU_loss:31.54116798, Val_loss:8.30858726)\n",
      "epoch (259 / 2000) (Train_loss:2.09810035, ACU_loss:31.47150518, Val_loss:8.11495952)\n",
      "epoch (260 / 2000) (Train_loss:1.92341319, ACU_loss:28.85119784, Val_loss:7.87813246)\n",
      "epoch (261 / 2000) (Train_loss:2.05828298, ACU_loss:30.87424474, Val_loss:7.95523323)\n",
      "epoch (262 / 2000) (Train_loss:2.16184342, ACU_loss:32.42765135, Val_loss:7.64971096)\n",
      "epoch (263 / 2000) (Train_loss:2.84632749, ACU_loss:42.69491232, Val_loss:7.62021954)\n",
      "epoch (264 / 2000) (Train_loss:2.38342563, ACU_loss:35.75138448, Val_loss:7.65133556)\n",
      "epoch (265 / 2000) (Train_loss:2.14940394, ACU_loss:32.24105916, Val_loss:7.40179013)\n",
      "epoch (266 / 2000) (Train_loss:1.80002257, ACU_loss:27.00033853, Val_loss:7.37716960)\n",
      "epoch (267 / 2000) (Train_loss:1.73650068, ACU_loss:26.04751025, Val_loss:7.19434090)\n",
      "epoch (268 / 2000) (Train_loss:1.63049188, ACU_loss:24.45737823, Val_loss:7.09820002)\n",
      "epoch (269 / 2000) (Train_loss:1.57089701, ACU_loss:23.56345512, Val_loss:6.97098065)\n",
      "epoch (270 / 2000) (Train_loss:1.51420413, ACU_loss:22.71306202, Val_loss:6.89707608)\n",
      "epoch (271 / 2000) (Train_loss:1.50013192, ACU_loss:22.50197887, Val_loss:6.74459083)\n",
      "epoch (272 / 2000) (Train_loss:1.59037718, ACU_loss:23.85565771, Val_loss:6.77964701)\n",
      "epoch (273 / 2000) (Train_loss:1.75191758, ACU_loss:26.27876369, Val_loss:6.60540753)\n",
      "epoch (274 / 2000) (Train_loss:1.64676518, ACU_loss:24.70147763, Val_loss:6.46158890)\n",
      "epoch (275 / 2000) (Train_loss:1.88017566, ACU_loss:28.20263495, Val_loss:6.60878204)\n",
      "epoch (276 / 2000) (Train_loss:2.10254878, ACU_loss:31.53823170, Val_loss:6.29629711)\n",
      "epoch (277 / 2000) (Train_loss:2.90746351, ACU_loss:43.61195267, Val_loss:6.35661388)\n",
      "epoch (278 / 2000) (Train_loss:2.28999686, ACU_loss:34.34995288, Val_loss:6.33034761)\n",
      "epoch (279 / 2000) (Train_loss:1.74725797, ACU_loss:26.20886956, Val_loss:6.13511462)\n",
      "epoch (280 / 2000) (Train_loss:1.40250405, ACU_loss:21.03756068, Val_loss:6.08865923)\n",
      "epoch (281 / 2000) (Train_loss:1.32563739, ACU_loss:19.88456087, Val_loss:5.96237393)\n",
      "epoch (282 / 2000) (Train_loss:1.26522111, ACU_loss:18.97831667, Val_loss:5.86941944)\n",
      "epoch (283 / 2000) (Train_loss:1.23987809, ACU_loss:18.59817131, Val_loss:5.79246582)\n",
      "epoch (284 / 2000) (Train_loss:1.20642653, ACU_loss:18.09639789, Val_loss:5.70437555)\n",
      "epoch (285 / 2000) (Train_loss:1.17583156, ACU_loss:17.63747335, Val_loss:5.61946233)\n",
      "epoch (286 / 2000) (Train_loss:1.18307516, ACU_loss:17.74612735, Val_loss:5.58672911)\n",
      "epoch (287 / 2000) (Train_loss:1.26289961, ACU_loss:18.94349420, Val_loss:5.43639914)\n",
      "epoch (288 / 2000) (Train_loss:1.40213486, ACU_loss:21.03202285, Val_loss:5.53389026)\n",
      "epoch (289 / 2000) (Train_loss:1.78060647, ACU_loss:26.70909700, Val_loss:5.52461427)\n",
      "epoch (290 / 2000) (Train_loss:1.84115316, ACU_loss:27.61729733, Val_loss:5.48210811)\n",
      "epoch (291 / 2000) (Train_loss:2.34909575, ACU_loss:35.23643631, Val_loss:5.59333127)\n",
      "epoch (292 / 2000) (Train_loss:2.83229422, ACU_loss:42.48441329, Val_loss:5.45605401)\n",
      "epoch (293 / 2000) (Train_loss:2.34568775, ACU_loss:35.18531619, Val_loss:5.17177709)\n",
      "epoch (294 / 2000) (Train_loss:1.83685920, ACU_loss:27.55288797, Val_loss:5.22000165)\n",
      "epoch (295 / 2000) (Train_loss:2.31352803, ACU_loss:34.70292042, Val_loss:5.08646354)\n",
      "epoch (296 / 2000) (Train_loss:1.46581283, ACU_loss:21.98719242, Val_loss:5.14830672)\n",
      "epoch (297 / 2000) (Train_loss:1.08191367, ACU_loss:16.22870505, Val_loss:4.96928894)\n",
      "epoch (298 / 2000) (Train_loss:1.02452592, ACU_loss:15.36788878, Val_loss:4.90182174)\n",
      "epoch (299 / 2000) (Train_loss:0.99646830, ACU_loss:14.94702445, Val_loss:4.82458055)\n",
      "epoch (300 / 2000) (Train_loss:0.96515196, ACU_loss:14.47727943, Val_loss:4.74792616)\n",
      "epoch (301 / 2000) (Train_loss:0.94463367, ACU_loss:14.16950512, Val_loss:4.68847252)\n",
      "epoch (302 / 2000) (Train_loss:0.92152114, ACU_loss:13.82281705, Val_loss:4.61570576)\n",
      "epoch (303 / 2000) (Train_loss:0.90398048, ACU_loss:13.55970718, Val_loss:4.56958535)\n",
      "epoch (304 / 2000) (Train_loss:0.88531977, ACU_loss:13.27979657, Val_loss:4.49923581)\n",
      "epoch (305 / 2000) (Train_loss:0.89843394, ACU_loss:13.47650913, Val_loss:4.43324910)\n",
      "epoch (306 / 2000) (Train_loss:1.01535065, ACU_loss:15.23025970, Val_loss:4.46924269)\n",
      "epoch (307 / 2000) (Train_loss:1.24359101, ACU_loss:18.65386518, Val_loss:4.35382466)\n",
      "epoch (308 / 2000) (Train_loss:1.20646277, ACU_loss:18.09694155, Val_loss:4.36199898)\n",
      "epoch (309 / 2000) (Train_loss:1.46131709, ACU_loss:21.91975631, Val_loss:4.42690471)\n",
      "epoch (310 / 2000) (Train_loss:1.96611300, ACU_loss:29.49169503, Val_loss:4.25458232)\n",
      "epoch (311 / 2000) (Train_loss:2.53001800, ACU_loss:37.95026993, Val_loss:4.23962281)\n",
      "epoch (312 / 2000) (Train_loss:1.89699962, ACU_loss:28.45499434, Val_loss:4.28104660)\n",
      "epoch (313 / 2000) (Train_loss:1.56373788, ACU_loss:23.45606821, Val_loss:4.12518399)\n",
      "epoch (314 / 2000) (Train_loss:1.27108585, ACU_loss:19.06628776, Val_loss:4.15557816)\n",
      "epoch (315 / 2000) (Train_loss:1.49760131, ACU_loss:22.46401967, Val_loss:4.04091276)\n",
      "epoch (316 / 2000) (Train_loss:1.30307945, ACU_loss:19.54619176, Val_loss:4.06945462)\n",
      "epoch (317 / 2000) (Train_loss:1.51642341, ACU_loss:22.74635113, Val_loss:3.96712463)\n",
      "epoch (318 / 2000) (Train_loss:1.19569445, ACU_loss:17.93541674, Val_loss:3.98443183)\n",
      "epoch (319 / 2000) (Train_loss:1.24459883, ACU_loss:18.66898244, Val_loss:3.88438453)\n",
      "epoch (320 / 2000) (Train_loss:1.09628919, ACU_loss:16.44433791, Val_loss:3.87777402)\n",
      "epoch (321 / 2000) (Train_loss:1.22399247, ACU_loss:18.35988705, Val_loss:3.80190605)\n",
      "epoch (322 / 2000) (Train_loss:1.10739114, ACU_loss:16.61086711, Val_loss:3.79513572)\n",
      "epoch (323 / 2000) (Train_loss:1.17117584, ACU_loss:17.56763756, Val_loss:3.72333364)\n",
      "epoch (324 / 2000) (Train_loss:1.06703422, ACU_loss:16.00551331, Val_loss:3.71133027)\n",
      "epoch (325 / 2000) (Train_loss:1.07646774, ACU_loss:16.14701604, Val_loss:3.64588944)\n",
      "epoch (326 / 2000) (Train_loss:1.00002739, ACU_loss:15.00041090, Val_loss:3.62456060)\n",
      "epoch (327 / 2000) (Train_loss:0.98926102, ACU_loss:14.83891531, Val_loss:3.56978716)\n",
      "epoch (328 / 2000) (Train_loss:0.92924702, ACU_loss:13.93870529, Val_loss:3.53791460)\n",
      "epoch (329 / 2000) (Train_loss:0.88085128, ACU_loss:13.21276917, Val_loss:3.49447848)\n",
      "epoch (330 / 2000) (Train_loss:0.82655242, ACU_loss:12.39828636, Val_loss:3.44991368)\n",
      "epoch (331 / 2000) (Train_loss:0.74559822, ACU_loss:11.18397327, Val_loss:3.42117210)\n",
      "epoch (332 / 2000) (Train_loss:0.68912611, ACU_loss:10.33689158, Val_loss:3.36289922)\n",
      "epoch (333 / 2000) (Train_loss:0.64710883, ACU_loss:9.70663250, Val_loss:3.34548068)\n",
      "epoch (334 / 2000) (Train_loss:0.69340367, ACU_loss:10.40105512, Val_loss:3.30060069)\n",
      "epoch (335 / 2000) (Train_loss:0.75678445, ACU_loss:11.35176680, Val_loss:3.23416587)\n",
      "epoch (336 / 2000) (Train_loss:0.82014566, ACU_loss:12.30218483, Val_loss:3.25196656)\n",
      "epoch (337 / 2000) (Train_loss:0.89144652, ACU_loss:13.37169781, Val_loss:3.23772710)\n",
      "epoch (338 / 2000) (Train_loss:0.90869167, ACU_loss:13.63037510, Val_loss:3.19109369)\n",
      "epoch (339 / 2000) (Train_loss:1.28350772, ACU_loss:19.25261587, Val_loss:3.25617904)\n",
      "epoch (340 / 2000) (Train_loss:1.64289203, ACU_loss:24.64338044, Val_loss:3.26368944)\n",
      "epoch (341 / 2000) (Train_loss:1.18183082, ACU_loss:17.72746231, Val_loss:3.10278636)\n",
      "epoch (342 / 2000) (Train_loss:0.90139021, ACU_loss:13.52085322, Val_loss:3.08034885)\n",
      "epoch (343 / 2000) (Train_loss:0.91986875, ACU_loss:13.79803131, Val_loss:3.02675046)\n",
      "epoch (344 / 2000) (Train_loss:0.89230032, ACU_loss:13.38450480, Val_loss:2.99947125)\n",
      "epoch (345 / 2000) (Train_loss:0.89543221, ACU_loss:13.43148312, Val_loss:2.96295832)\n",
      "epoch (346 / 2000) (Train_loss:0.83014592, ACU_loss:12.45218879, Val_loss:2.94421809)\n",
      "epoch (347 / 2000) (Train_loss:0.70341670, ACU_loss:10.55125052, Val_loss:2.91011736)\n",
      "epoch (348 / 2000) (Train_loss:0.61797733, ACU_loss:9.26965993, Val_loss:2.86448891)\n",
      "epoch (349 / 2000) (Train_loss:0.55483606, ACU_loss:8.32254093, Val_loss:2.86049200)\n",
      "epoch (350 / 2000) (Train_loss:0.58499574, ACU_loss:8.77493603, Val_loss:2.80820517)\n",
      "epoch (351 / 2000) (Train_loss:0.63592374, ACU_loss:9.53885613, Val_loss:2.76163182)\n",
      "epoch (352 / 2000) (Train_loss:0.77762964, ACU_loss:11.66444467, Val_loss:2.79834674)\n",
      "epoch (353 / 2000) (Train_loss:0.91241756, ACU_loss:13.68626333, Val_loss:2.82575840)\n",
      "epoch (354 / 2000) (Train_loss:0.92057202, ACU_loss:13.80858029, Val_loss:2.80749772)\n",
      "epoch (355 / 2000) (Train_loss:1.36741514, ACU_loss:20.51122708, Val_loss:2.84598986)\n",
      "epoch (356 / 2000) (Train_loss:1.71057748, ACU_loss:25.65866216, Val_loss:2.91932624)\n",
      "epoch (357 / 2000) (Train_loss:1.01823402, ACU_loss:15.27351032, Val_loss:2.77621512)\n",
      "epoch (358 / 2000) (Train_loss:0.68805572, ACU_loss:10.32083576, Val_loss:2.65083261)\n",
      "epoch (359 / 2000) (Train_loss:0.71721382, ACU_loss:10.75820728, Val_loss:2.62378124)\n",
      "epoch (360 / 2000) (Train_loss:0.68221510, ACU_loss:10.23322651, Val_loss:2.56971536)\n",
      "epoch (361 / 2000) (Train_loss:0.66027794, ACU_loss:9.90416904, Val_loss:2.56355220)\n",
      "epoch (362 / 2000) (Train_loss:0.58727282, ACU_loss:8.80909225, Val_loss:2.52514484)\n",
      "epoch (363 / 2000) (Train_loss:0.53129282, ACU_loss:7.96939235, Val_loss:2.52436117)\n",
      "epoch (364 / 2000) (Train_loss:0.72570091, ACU_loss:10.88551368, Val_loss:2.49341147)\n",
      "epoch (365 / 2000) (Train_loss:0.85207069, ACU_loss:12.78106029, Val_loss:2.47291102)\n",
      "epoch (366 / 2000) (Train_loss:0.72803856, ACU_loss:10.92057844, Val_loss:2.46774470)\n",
      "epoch (367 / 2000) (Train_loss:0.59813424, ACU_loss:8.97201353, Val_loss:2.42080178)\n",
      "epoch (368 / 2000) (Train_loss:0.64312078, ACU_loss:9.64681171, Val_loss:2.40551396)\n",
      "epoch (369 / 2000) (Train_loss:1.44612478, ACU_loss:21.69187165, Val_loss:2.45802493)\n",
      "epoch (370 / 2000) (Train_loss:1.84476569, ACU_loss:27.67148535, Val_loss:2.76396079)\n",
      "epoch (371 / 2000) (Train_loss:0.82076280, ACU_loss:12.31144207, Val_loss:2.39725988)\n",
      "epoch (372 / 2000) (Train_loss:0.72302988, ACU_loss:10.84544826, Val_loss:2.39554844)\n",
      "epoch (373 / 2000) (Train_loss:1.10963140, ACU_loss:16.64447105, Val_loss:2.35161402)\n",
      "epoch (374 / 2000) (Train_loss:0.96182754, ACU_loss:14.42741311, Val_loss:2.37840807)\n",
      "epoch (375 / 2000) (Train_loss:0.95545693, ACU_loss:14.33185398, Val_loss:2.31590220)\n",
      "epoch (376 / 2000) (Train_loss:0.84146124, ACU_loss:12.62191865, Val_loss:2.32378142)\n",
      "epoch (377 / 2000) (Train_loss:0.93578861, ACU_loss:14.03682921, Val_loss:2.28692579)\n",
      "epoch (378 / 2000) (Train_loss:0.82635403, ACU_loss:12.39531047, Val_loss:2.29182430)\n",
      "epoch (379 / 2000) (Train_loss:0.89375213, ACU_loss:13.40628199, Val_loss:2.25643385)\n",
      "epoch (380 / 2000) (Train_loss:0.78743480, ACU_loss:11.81152200, Val_loss:2.25439967)\n",
      "epoch (381 / 2000) (Train_loss:0.83796894, ACU_loss:12.56953415, Val_loss:2.22564121)\n",
      "epoch (382 / 2000) (Train_loss:0.74025064, ACU_loss:11.10375962, Val_loss:2.21545664)\n",
      "epoch (383 / 2000) (Train_loss:0.75588660, ACU_loss:11.33829899, Val_loss:2.19326588)\n",
      "epoch (384 / 2000) (Train_loss:0.66837096, ACU_loss:10.02556437, Val_loss:2.17180875)\n",
      "epoch (385 / 2000) (Train_loss:0.63889115, ACU_loss:9.58336725, Val_loss:2.15973216)\n",
      "epoch (386 / 2000) (Train_loss:0.55893943, ACU_loss:8.38409147, Val_loss:2.12305671)\n",
      "epoch (387 / 2000) (Train_loss:0.48696861, ACU_loss:7.30452908, Val_loss:2.12644814)\n",
      "epoch (388 / 2000) (Train_loss:0.41957335, ACU_loss:6.29360021, Val_loss:2.07222445)\n",
      "epoch (389 / 2000) (Train_loss:0.39561527, ACU_loss:5.93422907, Val_loss:2.07892413)\n",
      "epoch (390 / 2000) (Train_loss:0.51787232, ACU_loss:7.76808478, Val_loss:2.04633468)\n",
      "epoch (391 / 2000) (Train_loss:0.57503680, ACU_loss:8.62555203, Val_loss:2.01032497)\n",
      "epoch (392 / 2000) (Train_loss:0.55932964, ACU_loss:8.38994460, Val_loss:2.03217078)\n",
      "epoch (393 / 2000) (Train_loss:0.53827164, ACU_loss:8.07407454, Val_loss:2.00585085)\n",
      "epoch (394 / 2000) (Train_loss:0.65274764, ACU_loss:9.79121464, Val_loss:1.98024579)\n",
      "epoch (395 / 2000) (Train_loss:1.55826173, ACU_loss:23.37392601, Val_loss:2.10623347)\n",
      "epoch (396 / 2000) (Train_loss:1.97818922, ACU_loss:29.67283835, Val_loss:2.44751651)\n",
      "epoch (397 / 2000) (Train_loss:0.88293419, ACU_loss:13.24401280, Val_loss:2.01752903)\n",
      "epoch (398 / 2000) (Train_loss:0.74592617, ACU_loss:11.18889258, Val_loss:2.03568271)\n",
      "epoch (399 / 2000) (Train_loss:1.23587828, ACU_loss:18.53817426, Val_loss:1.98178190)\n",
      "epoch (400 / 2000) (Train_loss:0.95445573, ACU_loss:14.31683594, Val_loss:2.03297595)\n",
      "epoch (401 / 2000) (Train_loss:1.14028226, ACU_loss:17.10423394, Val_loss:1.97293460)\n",
      "epoch (402 / 2000) (Train_loss:0.88375837, ACU_loss:13.25637551, Val_loss:1.99183731)\n",
      "epoch (403 / 2000) (Train_loss:1.05591031, ACU_loss:15.83865468, Val_loss:1.95335889)\n",
      "epoch (404 / 2000) (Train_loss:0.79453983, ACU_loss:11.91809744, Val_loss:1.97370101)\n",
      "epoch (405 / 2000) (Train_loss:0.93431947, ACU_loss:14.01479203, Val_loss:1.93429358)\n",
      "epoch (406 / 2000) (Train_loss:0.72342570, ACU_loss:10.85138553, Val_loss:1.93219919)\n",
      "epoch (407 / 2000) (Train_loss:0.85420793, ACU_loss:12.81311890, Val_loss:1.91206288)\n",
      "epoch (408 / 2000) (Train_loss:0.67763720, ACU_loss:10.16455799, Val_loss:1.89689318)\n",
      "epoch (409 / 2000) (Train_loss:0.76949652, ACU_loss:11.54244785, Val_loss:1.88666529)\n",
      "epoch (410 / 2000) (Train_loss:0.62847484, ACU_loss:9.42712263, Val_loss:1.86055488)\n",
      "epoch (411 / 2000) (Train_loss:0.68187548, ACU_loss:10.22813217, Val_loss:1.85971084)\n",
      "epoch (412 / 2000) (Train_loss:0.57267247, ACU_loss:8.59008707, Val_loss:1.82377923)\n",
      "epoch (413 / 2000) (Train_loss:0.58291995, ACU_loss:8.74379932, Val_loss:1.83088887)\n",
      "epoch (414 / 2000) (Train_loss:0.49670097, ACU_loss:7.45051453, Val_loss:1.78578344)\n",
      "epoch (415 / 2000) (Train_loss:0.45974618, ACU_loss:6.89619274, Val_loss:1.80118646)\n",
      "epoch (416 / 2000) (Train_loss:0.38932392, ACU_loss:5.83985885, Val_loss:1.74549322)\n",
      "epoch (417 / 2000) (Train_loss:0.35055159, ACU_loss:5.25827381, Val_loss:1.76346232)\n",
      "epoch (418 / 2000) (Train_loss:0.37702136, ACU_loss:5.65532040, Val_loss:1.70976898)\n",
      "epoch (419 / 2000) (Train_loss:0.40072849, ACU_loss:6.01092728, Val_loss:1.68085756)\n",
      "epoch (420 / 2000) (Train_loss:0.59042587, ACU_loss:8.85638798, Val_loss:1.73722478)\n",
      "epoch (421 / 2000) (Train_loss:0.68338464, ACU_loss:10.25076957, Val_loss:1.73125847)\n",
      "epoch (422 / 2000) (Train_loss:0.59276723, ACU_loss:8.89150841, Val_loss:1.75673469)\n",
      "epoch (423 / 2000) (Train_loss:0.52490334, ACU_loss:7.87355015, Val_loss:1.65846673)\n",
      "epoch (424 / 2000) (Train_loss:0.56595128, ACU_loss:8.48926925, Val_loss:1.60949568)\n",
      "epoch (425 / 2000) (Train_loss:1.03592950, ACU_loss:15.53894250, Val_loss:1.67780163)\n",
      "epoch (426 / 2000) (Train_loss:1.14250694, ACU_loss:17.13760410, Val_loss:1.79805030)\n",
      "epoch (427 / 2000) (Train_loss:0.60594737, ACU_loss:9.08921050, Val_loss:1.72974729)\n",
      "epoch (428 / 2000) (Train_loss:0.34026582, ACU_loss:5.10398727, Val_loss:1.64352059)\n",
      "epoch (429 / 2000) (Train_loss:0.33097266, ACU_loss:4.96458997, Val_loss:1.58958394)\n",
      "epoch (430 / 2000) (Train_loss:0.43879135, ACU_loss:6.58187030, Val_loss:1.60014088)\n",
      "epoch (431 / 2000) (Train_loss:0.42337442, ACU_loss:6.35061625, Val_loss:1.55562053)\n",
      "epoch (432 / 2000) (Train_loss:0.38547811, ACU_loss:5.78217169, Val_loss:1.58538802)\n",
      "epoch (433 / 2000) (Train_loss:0.50832434, ACU_loss:7.62486508, Val_loss:1.53613845)\n",
      "epoch (434 / 2000) (Train_loss:0.59534719, ACU_loss:8.93020788, Val_loss:1.49957918)\n",
      "epoch (435 / 2000) (Train_loss:0.85825852, ACU_loss:12.87387782, Val_loss:1.60172486)\n",
      "epoch (436 / 2000) (Train_loss:0.97208715, ACU_loss:14.58130724, Val_loss:1.67421505)\n",
      "epoch (437 / 2000) (Train_loss:0.67758503, ACU_loss:10.16377550, Val_loss:1.65883799)\n",
      "epoch (438 / 2000) (Train_loss:0.75748984, ACU_loss:11.36234765, Val_loss:1.58350686)\n",
      "epoch (439 / 2000) (Train_loss:0.77285152, ACU_loss:11.59277278, Val_loss:1.51699699)\n",
      "epoch (440 / 2000) (Train_loss:0.75870035, ACU_loss:11.38050531, Val_loss:1.53367299)\n",
      "epoch (441 / 2000) (Train_loss:0.57879929, ACU_loss:8.68198935, Val_loss:1.53361064)\n",
      "epoch (442 / 2000) (Train_loss:0.36257695, ACU_loss:5.43865419, Val_loss:1.51413626)\n",
      "epoch (443 / 2000) (Train_loss:0.46765556, ACU_loss:7.01483343, Val_loss:1.46692781)\n",
      "epoch (444 / 2000) (Train_loss:0.47438942, ACU_loss:7.11584133, Val_loss:1.43231703)\n",
      "epoch (445 / 2000) (Train_loss:0.56256847, ACU_loss:8.43852710, Val_loss:1.47907310)\n",
      "epoch (446 / 2000) (Train_loss:0.54276696, ACU_loss:8.14150433, Val_loss:1.46303931)\n",
      "epoch (447 / 2000) (Train_loss:0.49050395, ACU_loss:7.35755921, Val_loss:1.47482509)\n",
      "epoch (448 / 2000) (Train_loss:0.87779359, ACU_loss:13.16690384, Val_loss:1.46446459)\n",
      "epoch (449 / 2000) (Train_loss:1.00441188, ACU_loss:15.06617818, Val_loss:1.49202970)\n",
      "epoch (450 / 2000) (Train_loss:0.84517579, ACU_loss:12.67763690, Val_loss:1.42760343)\n",
      "epoch (451 / 2000) (Train_loss:0.67850003, ACU_loss:10.17750041, Val_loss:1.46998707)\n",
      "epoch (452 / 2000) (Train_loss:0.37814995, ACU_loss:5.67224920, Val_loss:1.43556346)\n",
      "epoch (453 / 2000) (Train_loss:0.28715764, ACU_loss:4.30736465, Val_loss:1.39297562)\n",
      "epoch (454 / 2000) (Train_loss:0.27593892, ACU_loss:4.13908385, Val_loss:1.37620782)\n",
      "epoch (455 / 2000) (Train_loss:0.38767447, ACU_loss:5.81511707, Val_loss:1.38005531)\n",
      "epoch (456 / 2000) (Train_loss:0.39844763, ACU_loss:5.97671451, Val_loss:1.33867893)\n",
      "epoch (457 / 2000) (Train_loss:0.38076483, ACU_loss:5.71147249, Val_loss:1.38396474)\n",
      "epoch (458 / 2000) (Train_loss:0.47838371, ACU_loss:7.17575570, Val_loss:1.33402114)\n",
      "epoch (459 / 2000) (Train_loss:0.55765861, ACU_loss:8.36487913, Val_loss:1.29033212)\n",
      "epoch (460 / 2000) (Train_loss:1.04267456, ACU_loss:15.64011840, Val_loss:1.50521206)\n",
      "epoch (461 / 2000) (Train_loss:1.28891622, ACU_loss:19.33374325, Val_loss:1.55744685)\n",
      "epoch (462 / 2000) (Train_loss:0.74023484, ACU_loss:11.10352254, Val_loss:1.60939054)\n",
      "epoch (463 / 2000) (Train_loss:0.49505519, ACU_loss:7.42582787, Val_loss:1.40776063)\n",
      "epoch (464 / 2000) (Train_loss:0.51424511, ACU_loss:7.71367661, Val_loss:1.31203308)\n",
      "epoch (465 / 2000) (Train_loss:0.46312247, ACU_loss:6.94683704, Val_loss:1.35745165)\n",
      "epoch (466 / 2000) (Train_loss:0.41147331, ACU_loss:6.17209966, Val_loss:1.29490397)\n",
      "epoch (467 / 2000) (Train_loss:0.46249681, ACU_loss:6.93745222, Val_loss:1.28218337)\n",
      "epoch (468 / 2000) (Train_loss:1.26785938, ACU_loss:19.01789064, Val_loss:1.40711476)\n",
      "epoch (469 / 2000) (Train_loss:1.60893695, ACU_loss:24.13405423, Val_loss:1.56482627)\n",
      "epoch (470 / 2000) (Train_loss:0.64085348, ACU_loss:9.61280227, Val_loss:1.44213967)\n",
      "epoch (471 / 2000) (Train_loss:0.40325653, ACU_loss:6.04884790, Val_loss:1.34436038)\n",
      "epoch (472 / 2000) (Train_loss:0.30045520, ACU_loss:4.50682798, Val_loss:1.33568148)\n",
      "epoch (473 / 2000) (Train_loss:0.24939589, ACU_loss:3.74093839, Val_loss:1.25142548)\n",
      "epoch (474 / 2000) (Train_loss:0.24084510, ACU_loss:3.61267643, Val_loss:1.25645988)\n",
      "epoch (475 / 2000) (Train_loss:0.30252275, ACU_loss:4.53784129, Val_loss:1.23219781)\n",
      "epoch (476 / 2000) (Train_loss:0.32363976, ACU_loss:4.85459637, Val_loss:1.19083944)\n",
      "epoch (477 / 2000) (Train_loss:0.37622098, ACU_loss:5.64331469, Val_loss:1.29759130)\n",
      "epoch (478 / 2000) (Train_loss:0.45186553, ACU_loss:6.77798297, Val_loss:1.22741111)\n",
      "epoch (479 / 2000) (Train_loss:0.61859432, ACU_loss:9.27891483, Val_loss:1.19058259)\n",
      "epoch (480 / 2000) (Train_loss:1.61661541, ACU_loss:24.24923117, Val_loss:1.61002304)\n",
      "epoch (481 / 2000) (Train_loss:2.20382201, ACU_loss:33.05733009, Val_loss:1.37066717)\n",
      "epoch (482 / 2000) (Train_loss:1.24739400, ACU_loss:18.71091003, Val_loss:1.46850390)\n",
      "epoch (483 / 2000) (Train_loss:1.15078797, ACU_loss:17.26181950, Val_loss:1.59138530)\n",
      "epoch (484 / 2000) (Train_loss:0.70766052, ACU_loss:10.61490780, Val_loss:1.54082312)\n",
      "epoch (485 / 2000) (Train_loss:0.45599747, ACU_loss:6.83996209, Val_loss:1.42968732)\n",
      "epoch (486 / 2000) (Train_loss:0.36389090, ACU_loss:5.45836350, Val_loss:1.46963646)\n",
      "epoch (487 / 2000) (Train_loss:0.36521535, ACU_loss:5.47823027, Val_loss:1.34451305)\n",
      "epoch (488 / 2000) (Train_loss:0.31459358, ACU_loss:4.71890368, Val_loss:1.28144799)\n",
      "epoch (489 / 2000) (Train_loss:0.35912023, ACU_loss:5.38680350, Val_loss:1.34267411)\n",
      "epoch (490 / 2000) (Train_loss:0.38087598, ACU_loss:5.71313968, Val_loss:1.19920996)\n",
      "epoch (491 / 2000) (Train_loss:0.48914672, ACU_loss:7.33720074, Val_loss:1.23431424)\n",
      "epoch (492 / 2000) (Train_loss:1.07761408, ACU_loss:16.16421124, Val_loss:1.41077079)\n",
      "epoch (493 / 2000) (Train_loss:1.54016791, ACU_loss:23.10251868, Val_loss:1.18948950)\n",
      "epoch (494 / 2000) (Train_loss:1.40425127, ACU_loss:21.06376901, Val_loss:1.20948532)\n",
      "epoch (495 / 2000) (Train_loss:1.11003437, ACU_loss:16.65051550, Val_loss:1.40606069)\n",
      "epoch (496 / 2000) (Train_loss:0.48848586, ACU_loss:7.32728790, Val_loss:1.25194642)\n",
      "epoch (497 / 2000) (Train_loss:0.65509972, ACU_loss:9.82649585, Val_loss:1.21303244)\n",
      "epoch (498 / 2000) (Train_loss:0.62769130, ACU_loss:9.41536952, Val_loss:1.17654537)\n",
      "epoch (499 / 2000) (Train_loss:0.69018812, ACU_loss:10.35282179, Val_loss:1.21396589)\n",
      "epoch (500 / 2000) (Train_loss:0.51751916, ACU_loss:7.76278746, Val_loss:1.17817526)\n",
      "epoch (501 / 2000) (Train_loss:0.33138158, ACU_loss:4.97072364, Val_loss:1.18983885)\n",
      "epoch (502 / 2000) (Train_loss:0.42764787, ACU_loss:6.41471808, Val_loss:1.13417422)\n",
      "epoch (503 / 2000) (Train_loss:0.45523772, ACU_loss:6.82856582, Val_loss:1.09992261)\n",
      "epoch (504 / 2000) (Train_loss:0.70051516, ACU_loss:10.50772739, Val_loss:1.19249131)\n",
      "epoch (505 / 2000) (Train_loss:0.62473142, ACU_loss:9.37097124, Val_loss:1.13472811)\n",
      "epoch (506 / 2000) (Train_loss:0.43099328, ACU_loss:6.46489916, Val_loss:1.16492636)\n",
      "epoch (507 / 2000) (Train_loss:0.49751220, ACU_loss:7.46268296, Val_loss:1.10299466)\n",
      "epoch (508 / 2000) (Train_loss:0.54918483, ACU_loss:8.23777248, Val_loss:1.06625183)\n",
      "epoch (509 / 2000) (Train_loss:1.02094335, ACU_loss:15.31415019, Val_loss:1.19862554)\n",
      "epoch (510 / 2000) (Train_loss:0.91258834, ACU_loss:13.68882507, Val_loss:1.15844900)\n",
      "epoch (511 / 2000) (Train_loss:0.50016477, ACU_loss:7.50247157, Val_loss:1.18565550)\n",
      "epoch (512 / 2000) (Train_loss:0.42778439, ACU_loss:6.41676586, Val_loss:1.09996822)\n",
      "epoch (513 / 2000) (Train_loss:0.46723146, ACU_loss:7.00847188, Val_loss:1.05950510)\n",
      "epoch (514 / 2000) (Train_loss:0.95490183, ACU_loss:14.32352743, Val_loss:1.15235300)\n",
      "epoch (515 / 2000) (Train_loss:0.85875038, ACU_loss:12.88125571, Val_loss:1.12627459)\n",
      "epoch (516 / 2000) (Train_loss:0.49383499, ACU_loss:7.40752486, Val_loss:1.13570400)\n",
      "epoch (517 / 2000) (Train_loss:0.31488049, ACU_loss:4.72320736, Val_loss:1.07888375)\n",
      "epoch (518 / 2000) (Train_loss:0.28362415, ACU_loss:4.25436226, Val_loss:1.06767917)\n",
      "epoch (519 / 2000) (Train_loss:0.54728906, ACU_loss:8.20933590, Val_loss:1.06209158)\n",
      "epoch (520 / 2000) (Train_loss:0.56995296, ACU_loss:8.54929433, Val_loss:1.02635062)\n",
      "epoch (521 / 2000) (Train_loss:0.69847616, ACU_loss:10.47714246, Val_loss:1.09483004)\n",
      "epoch (522 / 2000) (Train_loss:0.61405967, ACU_loss:9.21089506, Val_loss:1.07077138)\n",
      "epoch (523 / 2000) (Train_loss:0.40860663, ACU_loss:6.12909940, Val_loss:1.08819446)\n",
      "epoch (524 / 2000) (Train_loss:0.38720730, ACU_loss:5.80810946, Val_loss:1.03291105)\n",
      "epoch (525 / 2000) (Train_loss:0.42319132, ACU_loss:6.34786982, Val_loss:0.99701885)\n",
      "epoch (526 / 2000) (Train_loss:0.97397716, ACU_loss:14.60965746, Val_loss:1.09154890)\n",
      "epoch (527 / 2000) (Train_loss:0.99185115, ACU_loss:14.87776722, Val_loss:1.07533760)\n",
      "epoch (528 / 2000) (Train_loss:0.63978736, ACU_loss:9.59681044, Val_loss:1.08160014)\n",
      "epoch (529 / 2000) (Train_loss:0.42451927, ACU_loss:6.36778909, Val_loss:1.06366518)\n",
      "epoch (530 / 2000) (Train_loss:0.29545129, ACU_loss:4.43176942, Val_loss:1.06334910)\n",
      "epoch (531 / 2000) (Train_loss:0.35364878, ACU_loss:5.30473169, Val_loss:1.00831601)\n",
      "epoch (532 / 2000) (Train_loss:0.36139188, ACU_loss:5.42087826, Val_loss:0.97611058)\n",
      "epoch (533 / 2000) (Train_loss:0.70360558, ACU_loss:10.55408376, Val_loss:1.04502487)\n",
      "epoch (534 / 2000) (Train_loss:0.71400215, ACU_loss:10.71003227, Val_loss:1.00724819)\n",
      "epoch (535 / 2000) (Train_loss:0.56839260, ACU_loss:8.52588905, Val_loss:1.03398825)\n",
      "epoch (536 / 2000) (Train_loss:0.42724829, ACU_loss:6.40872430, Val_loss:1.01712091)\n",
      "epoch (537 / 2000) (Train_loss:0.33197367, ACU_loss:4.97960508, Val_loss:1.02094532)\n",
      "epoch (538 / 2000) (Train_loss:0.55413916, ACU_loss:8.31208737, Val_loss:0.99402409)\n",
      "epoch (539 / 2000) (Train_loss:0.60618065, ACU_loss:9.09270981, Val_loss:0.94859034)\n",
      "epoch (540 / 2000) (Train_loss:1.01772604, ACU_loss:15.26589063, Val_loss:1.06164703)\n",
      "epoch (541 / 2000) (Train_loss:0.98647542, ACU_loss:14.79713133, Val_loss:1.05650788)\n",
      "epoch (542 / 2000) (Train_loss:0.57051929, ACU_loss:8.55778941, Val_loss:1.05942878)\n",
      "epoch (543 / 2000) (Train_loss:0.34557906, ACU_loss:5.18368587, Val_loss:1.01662265)\n",
      "epoch (544 / 2000) (Train_loss:0.26837997, ACU_loss:4.02569960, Val_loss:1.00434494)\n",
      "epoch (545 / 2000) (Train_loss:0.41483103, ACU_loss:6.22246542, Val_loss:0.97395543)\n",
      "epoch (546 / 2000) (Train_loss:0.42278712, ACU_loss:6.34180677, Val_loss:0.93482380)\n",
      "epoch (547 / 2000) (Train_loss:0.72145480, ACU_loss:10.82182202, Val_loss:1.01436516)\n",
      "epoch (548 / 2000) (Train_loss:0.70959578, ACU_loss:10.64393668, Val_loss:0.97834037)\n",
      "epoch (549 / 2000) (Train_loss:0.53139232, ACU_loss:7.97088484, Val_loss:0.99598337)\n",
      "epoch (550 / 2000) (Train_loss:0.39100191, ACU_loss:5.86502862, Val_loss:0.97694590)\n",
      "epoch (551 / 2000) (Train_loss:0.30831025, ACU_loss:4.62465373, Val_loss:0.97819266)\n",
      "epoch (552 / 2000) (Train_loss:0.51597753, ACU_loss:7.73966299, Val_loss:0.95365899)\n",
      "epoch (553 / 2000) (Train_loss:0.56232480, ACU_loss:8.43487201, Val_loss:0.90617214)\n",
      "epoch (554 / 2000) (Train_loss:0.97342416, ACU_loss:14.60136235, Val_loss:1.02320564)\n",
      "epoch (555 / 2000) (Train_loss:0.96570383, ACU_loss:14.48555748, Val_loss:1.00331953)\n",
      "epoch (556 / 2000) (Train_loss:0.60710244, ACU_loss:9.10653661, Val_loss:1.01176967)\n",
      "epoch (557 / 2000) (Train_loss:0.39106441, ACU_loss:5.86596611, Val_loss:0.99205406)\n",
      "epoch (558 / 2000) (Train_loss:0.28484173, ACU_loss:4.27262598, Val_loss:0.98404143)\n",
      "epoch (559 / 2000) (Train_loss:0.40145619, ACU_loss:6.02184282, Val_loss:0.93899368)\n",
      "epoch (560 / 2000) (Train_loss:0.40960483, ACU_loss:6.14407242, Val_loss:0.89881130)\n",
      "epoch (561 / 2000) (Train_loss:0.78772099, ACU_loss:11.81581485, Val_loss:0.98828782)\n",
      "epoch (562 / 2000) (Train_loss:0.79533504, ACU_loss:11.93002562, Val_loss:0.94888141)\n",
      "epoch (563 / 2000) (Train_loss:0.63160729, ACU_loss:9.47410941, Val_loss:0.96250165)\n",
      "epoch (564 / 2000) (Train_loss:0.48985673, ACU_loss:7.34785097, Val_loss:0.97379898)\n",
      "epoch (565 / 2000) (Train_loss:0.32156246, ACU_loss:4.82343697, Val_loss:0.97443359)\n",
      "epoch (566 / 2000) (Train_loss:0.33417420, ACU_loss:5.01261303, Val_loss:0.91573220)\n",
      "epoch (567 / 2000) (Train_loss:0.34808838, ACU_loss:5.22132570, Val_loss:0.88232676)\n",
      "epoch (568 / 2000) (Train_loss:0.77979773, ACU_loss:11.69696591, Val_loss:0.95956271)\n",
      "epoch (569 / 2000) (Train_loss:0.82573547, ACU_loss:12.38603209, Val_loss:0.91721439)\n",
      "epoch (570 / 2000) (Train_loss:0.75844034, ACU_loss:11.37660516, Val_loss:0.94226165)\n",
      "epoch (571 / 2000) (Train_loss:0.64814751, ACU_loss:9.72221259, Val_loss:0.99075488)\n",
      "epoch (572 / 2000) (Train_loss:0.38394205, ACU_loss:5.75913080, Val_loss:0.97926691)\n",
      "epoch (573 / 2000) (Train_loss:0.29691855, ACU_loss:4.45377822, Val_loss:0.91019576)\n",
      "epoch (574 / 2000) (Train_loss:0.28892171, ACU_loss:4.33382559, Val_loss:0.89033149)\n",
      "epoch (575 / 2000) (Train_loss:0.65420149, ACU_loss:9.81302232, Val_loss:0.92475763)\n",
      "epoch (576 / 2000) (Train_loss:0.70797408, ACU_loss:10.61961115, Val_loss:0.88131453)\n",
      "epoch (577 / 2000) (Train_loss:0.85734901, ACU_loss:12.86023520, Val_loss:0.94929148)\n",
      "epoch (578 / 2000) (Train_loss:0.80174334, ACU_loss:12.02615005, Val_loss:0.97377509)\n",
      "epoch (579 / 2000) (Train_loss:0.48874767, ACU_loss:7.33121510, Val_loss:0.95717679)\n",
      "epoch (580 / 2000) (Train_loss:0.32097972, ACU_loss:4.81469573, Val_loss:0.92158791)\n",
      "epoch (581 / 2000) (Train_loss:0.26208711, ACU_loss:3.93130664, Val_loss:0.90957422)\n",
      "epoch (582 / 2000) (Train_loss:0.46637136, ACU_loss:6.99557037, Val_loss:0.89209567)\n",
      "epoch (583 / 2000) (Train_loss:0.49560624, ACU_loss:7.43409366, Val_loss:0.84854913)\n",
      "epoch (584 / 2000) (Train_loss:0.81611763, ACU_loss:12.24176438, Val_loss:0.95117537)\n",
      "epoch (585 / 2000) (Train_loss:0.79503918, ACU_loss:11.92558776, Val_loss:0.91114646)\n",
      "epoch (586 / 2000) (Train_loss:0.56635686, ACU_loss:8.49535295, Val_loss:0.92910465)\n",
      "epoch (587 / 2000) (Train_loss:0.40524959, ACU_loss:6.07874390, Val_loss:0.92505775)\n",
      "epoch (588 / 2000) (Train_loss:0.29686481, ACU_loss:4.45297222, Val_loss:0.92109209)\n",
      "epoch (589 / 2000) (Train_loss:0.44453954, ACU_loss:6.66809317, Val_loss:0.87677489)\n",
      "epoch (590 / 2000) (Train_loss:0.46681763, ACU_loss:7.00226443, Val_loss:0.83231164)\n",
      "epoch (591 / 2000) (Train_loss:0.91628161, ACU_loss:13.74422410, Val_loss:0.95204487)\n",
      "epoch (592 / 2000) (Train_loss:0.91405387, ACU_loss:13.71080803, Val_loss:0.90112297)\n",
      "epoch (593 / 2000) (Train_loss:0.67002418, ACU_loss:10.05036273, Val_loss:0.92678074)\n",
      "epoch (594 / 2000) (Train_loss:0.50402853, ACU_loss:7.56042801, Val_loss:0.94798967)\n",
      "epoch (595 / 2000) (Train_loss:0.32266093, ACU_loss:4.83991393, Val_loss:0.95380662)\n",
      "epoch (596 / 2000) (Train_loss:0.30966270, ACU_loss:4.64494050, Val_loss:0.86470054)\n",
      "epoch (597 / 2000) (Train_loss:0.30334626, ACU_loss:4.55019393, Val_loss:0.83942125)\n",
      "epoch (598 / 2000) (Train_loss:0.68754608, ACU_loss:10.31319120, Val_loss:0.89598020)\n",
      "epoch (599 / 2000) (Train_loss:0.73071162, ACU_loss:10.96067428, Val_loss:0.84731530)\n",
      "epoch (600 / 2000) (Train_loss:0.81406485, ACU_loss:12.21097270, Val_loss:0.91280783)\n",
      "epoch (601 / 2000) (Train_loss:0.74765688, ACU_loss:11.21485325, Val_loss:0.93031572)\n",
      "epoch (602 / 2000) (Train_loss:0.46462497, ACU_loss:6.96937450, Val_loss:0.92410333)\n",
      "epoch (603 / 2000) (Train_loss:0.31429166, ACU_loss:4.71437496, Val_loss:0.87639510)\n",
      "epoch (604 / 2000) (Train_loss:0.25747005, ACU_loss:3.86205077, Val_loss:0.86922347)\n",
      "epoch (605 / 2000) (Train_loss:0.46361579, ACU_loss:6.95423681, Val_loss:0.85043830)\n",
      "epoch (606 / 2000) (Train_loss:0.49915895, ACU_loss:7.48738418, Val_loss:0.80719299)\n",
      "epoch (607 / 2000) (Train_loss:0.83800165, ACU_loss:12.57002477, Val_loss:0.92033900)\n",
      "epoch (608 / 2000) (Train_loss:0.81034768, ACU_loss:12.15521518, Val_loss:0.86945049)\n",
      "epoch (609 / 2000) (Train_loss:0.57942947, ACU_loss:8.69144208, Val_loss:0.90013499)\n",
      "epoch (610 / 2000) (Train_loss:0.42031422, ACU_loss:6.30471324, Val_loss:0.89684785)\n",
      "epoch (611 / 2000) (Train_loss:0.29840944, ACU_loss:4.47614161, Val_loss:0.89645683)\n",
      "epoch (612 / 2000) (Train_loss:0.42076653, ACU_loss:6.31149794, Val_loss:0.83804517)\n",
      "epoch (613 / 2000) (Train_loss:0.43694603, ACU_loss:6.55419040, Val_loss:0.79682161)\n",
      "epoch (614 / 2000) (Train_loss:0.90615342, ACU_loss:13.59230128, Val_loss:0.91480683)\n",
      "epoch (615 / 2000) (Train_loss:0.89762235, ACU_loss:13.46433528, Val_loss:0.85771964)\n",
      "epoch (616 / 2000) (Train_loss:0.67587848, ACU_loss:10.13817718, Val_loss:0.89183917)\n",
      "epoch (617 / 2000) (Train_loss:0.52931532, ACU_loss:7.93972984, Val_loss:0.91648263)\n",
      "epoch (618 / 2000) (Train_loss:0.33390564, ACU_loss:5.00858459, Val_loss:0.92495490)\n",
      "epoch (619 / 2000) (Train_loss:0.28392996, ACU_loss:4.25894940, Val_loss:0.82786742)\n",
      "epoch (620 / 2000) (Train_loss:0.26665639, ACU_loss:3.99984581, Val_loss:0.81264274)\n",
      "epoch (621 / 2000) (Train_loss:0.58256468, ACU_loss:8.73847021, Val_loss:0.84143607)\n",
      "epoch (622 / 2000) (Train_loss:0.62970961, ACU_loss:9.44564412, Val_loss:0.79273732)\n",
      "epoch (623 / 2000) (Train_loss:0.82132353, ACU_loss:12.31985293, Val_loss:0.89708683)\n",
      "epoch (624 / 2000) (Train_loss:0.76264654, ACU_loss:11.43969813, Val_loss:0.86447001)\n",
      "epoch (625 / 2000) (Train_loss:0.49593750, ACU_loss:7.43906243, Val_loss:0.88886166)\n",
      "epoch (626 / 2000) (Train_loss:0.34484214, ACU_loss:5.17263213, Val_loss:0.85017859)\n",
      "epoch (627 / 2000) (Train_loss:0.27981471, ACU_loss:4.19722059, Val_loss:0.84551950)\n",
      "epoch (628 / 2000) (Train_loss:0.52245488, ACU_loss:7.83682315, Val_loss:0.81948004)\n",
      "epoch (629 / 2000) (Train_loss:0.56284995, ACU_loss:8.44274918, Val_loss:0.77734279)\n",
      "epoch (630 / 2000) (Train_loss:0.96839372, ACU_loss:14.52590581, Val_loss:0.91400798)\n",
      "epoch (631 / 2000) (Train_loss:0.90711470, ACU_loss:13.60672053, Val_loss:0.85058547)\n",
      "epoch (632 / 2000) (Train_loss:0.58322443, ACU_loss:8.74836640, Val_loss:0.90538419)\n",
      "epoch (633 / 2000) (Train_loss:0.40410568, ACU_loss:6.06158524, Val_loss:0.88435588)\n",
      "epoch (634 / 2000) (Train_loss:0.28395143, ACU_loss:4.25927144, Val_loss:0.88915822)\n",
      "epoch (635 / 2000) (Train_loss:0.34986350, ACU_loss:5.24795253, Val_loss:0.80786813)\n",
      "epoch (636 / 2000) (Train_loss:0.34914114, ACU_loss:5.23711716, Val_loss:0.77344789)\n",
      "epoch (637 / 2000) (Train_loss:0.76123647, ACU_loss:11.41854699, Val_loss:0.85608232)\n",
      "epoch (638 / 2000) (Train_loss:0.76593200, ACU_loss:11.48897993, Val_loss:0.80286368)\n",
      "epoch (639 / 2000) (Train_loss:0.69384693, ACU_loss:10.40770401, Val_loss:0.86475355)\n",
      "epoch (640 / 2000) (Train_loss:0.59054181, ACU_loss:8.85812708, Val_loss:0.85200915)\n",
      "epoch (641 / 2000) (Train_loss:0.37842587, ACU_loss:5.67638799, Val_loss:0.87980238)\n",
      "epoch (642 / 2000) (Train_loss:0.28760656, ACU_loss:4.31409842, Val_loss:0.79604488)\n",
      "epoch (643 / 2000) (Train_loss:0.25689128, ACU_loss:3.85336913, Val_loss:0.79509560)\n",
      "epoch (644 / 2000) (Train_loss:0.53341855, ACU_loss:8.00127824, Val_loss:0.79259098)\n",
      "epoch (645 / 2000) (Train_loss:0.58865257, ACU_loss:8.82978852, Val_loss:0.75023481)\n",
      "epoch (646 / 2000) (Train_loss:0.88027746, ACU_loss:13.20416191, Val_loss:0.88175855)\n",
      "epoch (647 / 2000) (Train_loss:0.81012211, ACU_loss:12.15183163, Val_loss:0.81634834)\n",
      "epoch (648 / 2000) (Train_loss:0.53106947, ACU_loss:7.96604206, Val_loss:0.87532434)\n",
      "epoch (649 / 2000) (Train_loss:0.37369317, ACU_loss:5.60539751, Val_loss:0.83790366)\n",
      "epoch (650 / 2000) (Train_loss:0.28518215, ACU_loss:4.27773232, Val_loss:0.84178042)\n",
      "epoch (651 / 2000) (Train_loss:0.48187468, ACU_loss:7.22812027, Val_loss:0.78693315)\n",
      "epoch (652 / 2000) (Train_loss:0.50858369, ACU_loss:7.62875542, Val_loss:0.74656909)\n",
      "epoch (653 / 2000) (Train_loss:0.95912122, ACU_loss:14.38681837, Val_loss:0.87892474)\n",
      "epoch (654 / 2000) (Train_loss:0.87941782, ACU_loss:13.19126727, Val_loss:0.80975798)\n",
      "epoch (655 / 2000) (Train_loss:0.55157211, ACU_loss:8.27358169, Val_loss:0.87360995)\n",
      "epoch (656 / 2000) (Train_loss:0.38621174, ACU_loss:5.79317616, Val_loss:0.83698691)\n",
      "epoch (657 / 2000) (Train_loss:0.26911839, ACU_loss:4.03677583, Val_loss:0.85397848)\n",
      "epoch (658 / 2000) (Train_loss:0.30616604, ACU_loss:4.59249058, Val_loss:0.76617685)\n",
      "epoch (659 / 2000) (Train_loss:0.30490948, ACU_loss:4.57364221, Val_loss:0.73977245)\n",
      "epoch (660 / 2000) (Train_loss:0.66694854, ACU_loss:10.00422811, Val_loss:0.79938975)\n",
      "epoch (661 / 2000) (Train_loss:0.68725492, ACU_loss:10.30882385, Val_loss:0.74434838)\n",
      "epoch (662 / 2000) (Train_loss:0.70716303, ACU_loss:10.60744540, Val_loss:0.84653487)\n",
      "epoch (663 / 2000) (Train_loss:0.60683876, ACU_loss:9.10258137, Val_loss:0.79291660)\n",
      "epoch (664 / 2000) (Train_loss:0.38946541, ACU_loss:5.84198122, Val_loss:0.85004391)\n",
      "epoch (665 / 2000) (Train_loss:0.31017715, ACU_loss:4.65265730, Val_loss:0.76152648)\n",
      "epoch (666 / 2000) (Train_loss:0.28550019, ACU_loss:4.28250285, Val_loss:0.76411330)\n",
      "epoch (667 / 2000) (Train_loss:0.64294907, ACU_loss:9.64423604, Val_loss:0.76786300)\n",
      "epoch (668 / 2000) (Train_loss:0.71652012, ACU_loss:10.74780184, Val_loss:0.73376618)\n",
      "epoch (669 / 2000) (Train_loss:0.99267982, ACU_loss:14.89019727, Val_loss:0.87371587)\n",
      "epoch (670 / 2000) (Train_loss:0.87467390, ACU_loss:13.12010843, Val_loss:0.80867355)\n",
      "epoch (671 / 2000) (Train_loss:0.51757123, ACU_loss:7.76356843, Val_loss:0.89284907)\n",
      "epoch (672 / 2000) (Train_loss:0.34720729, ACU_loss:5.20810941, Val_loss:0.82923271)\n",
      "epoch (673 / 2000) (Train_loss:0.25522555, ACU_loss:3.82838326, Val_loss:0.82986681)\n",
      "epoch (674 / 2000) (Train_loss:0.39181087, ACU_loss:5.87716303, Val_loss:0.75530104)\n",
      "epoch (675 / 2000) (Train_loss:0.40249636, ACU_loss:6.03744537, Val_loss:0.71631092)\n",
      "epoch (676 / 2000) (Train_loss:0.76979412, ACU_loss:11.54691173, Val_loss:0.80953043)\n",
      "epoch (677 / 2000) (Train_loss:0.71403409, ACU_loss:10.71051136, Val_loss:0.74415371)\n",
      "epoch (678 / 2000) (Train_loss:0.54530844, ACU_loss:8.17962658, Val_loss:0.82715389)\n",
      "epoch (679 / 2000) (Train_loss:0.41880040, ACU_loss:6.28200593, Val_loss:0.76228713)\n",
      "epoch (680 / 2000) (Train_loss:0.28205024, ACU_loss:4.23075355, Val_loss:0.81451334)\n",
      "epoch (681 / 2000) (Train_loss:0.30340370, ACU_loss:4.55105544, Val_loss:0.71926637)\n",
      "epoch (682 / 2000) (Train_loss:0.30909010, ACU_loss:4.63635151, Val_loss:0.70894967)\n",
      "epoch (683 / 2000) (Train_loss:0.70248944, ACU_loss:10.53734166, Val_loss:0.75581603)\n",
      "epoch (684 / 2000) (Train_loss:0.74856333, ACU_loss:11.22845000, Val_loss:0.70892210)\n",
      "epoch (685 / 2000) (Train_loss:0.79306449, ACU_loss:11.89596735, Val_loss:0.83148562)\n",
      "epoch (686 / 2000) (Train_loss:0.66844335, ACU_loss:10.02665020, Val_loss:0.77555378)\n",
      "epoch (687 / 2000) (Train_loss:0.40952282, ACU_loss:6.14284226, Val_loss:0.84908922)\n",
      "epoch (688 / 2000) (Train_loss:0.30622048, ACU_loss:4.59330723, Val_loss:0.74750455)\n",
      "epoch (689 / 2000) (Train_loss:0.26026113, ACU_loss:3.90391702, Val_loss:0.75601412)\n",
      "epoch (690 / 2000) (Train_loss:0.53982261, ACU_loss:8.09733909, Val_loss:0.72676727)\n",
      "epoch (691 / 2000) (Train_loss:0.59699685, ACU_loss:8.95495270, Val_loss:0.69663662)\n",
      "epoch (692 / 2000) (Train_loss:0.90684831, ACU_loss:13.60272470, Val_loss:0.82857337)\n",
      "epoch (693 / 2000) (Train_loss:0.77373151, ACU_loss:11.60597272, Val_loss:0.74091554)\n",
      "epoch (694 / 2000) (Train_loss:0.48127212, ACU_loss:7.21908182, Val_loss:0.84740879)\n",
      "epoch (695 / 2000) (Train_loss:0.34163836, ACU_loss:5.12457544, Val_loss:0.76873331)\n",
      "epoch (696 / 2000) (Train_loss:0.25574306, ACU_loss:3.83614586, Val_loss:0.78754234)\n",
      "epoch (697 / 2000) (Train_loss:0.41720998, ACU_loss:6.25814967, Val_loss:0.71256442)\n",
      "epoch (698 / 2000) (Train_loss:0.44160349, ACU_loss:6.62405230, Val_loss:0.68042743)\n",
      "epoch (699 / 2000) (Train_loss:0.83911947, ACU_loss:12.58679202, Val_loss:0.78338868)\n",
      "epoch (700 / 2000) (Train_loss:0.75569260, ACU_loss:11.33538896, Val_loss:0.71238930)\n",
      "epoch (701 / 2000) (Train_loss:0.51732541, ACU_loss:7.75988119, Val_loss:0.81436407)\n",
      "epoch (702 / 2000) (Train_loss:0.37955271, ACU_loss:5.69329060, Val_loss:0.73421232)\n",
      "epoch (703 / 2000) (Train_loss:0.25889604, ACU_loss:3.88344063, Val_loss:0.78677628)\n",
      "epoch (704 / 2000) (Train_loss:0.31169978, ACU_loss:4.67549677, Val_loss:0.68698464)\n",
      "epoch (705 / 2000) (Train_loss:0.32115129, ACU_loss:4.81726932, Val_loss:0.67344617)\n",
      "epoch (706 / 2000) (Train_loss:0.71328574, ACU_loss:10.69928616, Val_loss:0.72547325)\n",
      "epoch (707 / 2000) (Train_loss:0.73589631, ACU_loss:11.03844459, Val_loss:0.67665235)\n",
      "epoch (708 / 2000) (Train_loss:0.71042379, ACU_loss:10.65635680, Val_loss:0.80510544)\n",
      "epoch (709 / 2000) (Train_loss:0.57117798, ACU_loss:8.56766975, Val_loss:0.72453384)\n",
      "epoch (710 / 2000) (Train_loss:0.35901917, ACU_loss:5.38528749, Val_loss:0.81676158)\n",
      "epoch (711 / 2000) (Train_loss:0.29479743, ACU_loss:4.42196152, Val_loss:0.69813182)\n",
      "epoch (712 / 2000) (Train_loss:0.26270504, ACU_loss:3.94057564, Val_loss:0.71214245)\n",
      "epoch (713 / 2000) (Train_loss:0.57523236, ACU_loss:8.62848534, Val_loss:0.68951128)\n",
      "epoch (714 / 2000) (Train_loss:0.64651174, ACU_loss:9.69767605, Val_loss:0.66681396)\n",
      "epoch (715 / 2000) (Train_loss:0.91180099, ACU_loss:13.67701478, Val_loss:0.80312627)\n",
      "epoch (716 / 2000) (Train_loss:0.75200824, ACU_loss:11.28012353, Val_loss:0.70798675)\n",
      "epoch (717 / 2000) (Train_loss:0.45826766, ACU_loss:6.87401493, Val_loss:0.83262708)\n",
      "epoch (718 / 2000) (Train_loss:0.32899539, ACU_loss:4.93493091, Val_loss:0.73549106)\n",
      "epoch (719 / 2000) (Train_loss:0.24760633, ACU_loss:3.71409497, Val_loss:0.75520781)\n",
      "epoch (720 / 2000) (Train_loss:0.42335938, ACU_loss:6.35039063, Val_loss:0.67765249)\n",
      "epoch (721 / 2000) (Train_loss:0.45536724, ACU_loss:6.83050856, Val_loss:0.65236421)\n",
      "epoch (722 / 2000) (Train_loss:0.84059051, ACU_loss:12.60885760, Val_loss:0.75059516)\n",
      "epoch (723 / 2000) (Train_loss:0.73439764, ACU_loss:11.01596462, Val_loss:0.67867846)\n",
      "epoch (724 / 2000) (Train_loss:0.47922709, ACU_loss:7.18840635, Val_loss:0.79362700)\n",
      "epoch (725 / 2000) (Train_loss:0.34647453, ACU_loss:5.19711788, Val_loss:0.69280496)\n",
      "epoch (726 / 2000) (Train_loss:0.24011722, ACU_loss:3.60175831, Val_loss:0.74760900)\n",
      "epoch (727 / 2000) (Train_loss:0.31419939, ACU_loss:4.71299086, Val_loss:0.64904359)\n",
      "epoch (728 / 2000) (Train_loss:0.32892514, ACU_loss:4.93387715, Val_loss:0.63781195)\n",
      "epoch (729 / 2000) (Train_loss:0.70344034, ACU_loss:10.55160514, Val_loss:0.68781981)\n",
      "epoch (730 / 2000) (Train_loss:0.71378415, ACU_loss:10.70676230, Val_loss:0.63864422)\n",
      "epoch (731 / 2000) (Train_loss:0.66832254, ACU_loss:10.02483815, Val_loss:0.77938522)\n",
      "epoch (732 / 2000) (Train_loss:0.52130107, ACU_loss:7.81951610, Val_loss:0.67956226)\n",
      "epoch (733 / 2000) (Train_loss:0.32902971, ACU_loss:4.93544562, Val_loss:0.78458620)\n",
      "epoch (734 / 2000) (Train_loss:0.29189246, ACU_loss:4.37838693, Val_loss:0.65749994)\n",
      "epoch (735 / 2000) (Train_loss:0.26922832, ACU_loss:4.03842481, Val_loss:0.67529834)\n",
      "epoch (736 / 2000) (Train_loss:0.60645474, ACU_loss:9.09682109, Val_loss:0.65492240)\n",
      "epoch (737 / 2000) (Train_loss:0.68716068, ACU_loss:10.30741017, Val_loss:0.64198996)\n",
      "epoch (738 / 2000) (Train_loss:0.91333408, ACU_loss:13.70001115, Val_loss:0.77529886)\n",
      "epoch (739 / 2000) (Train_loss:0.73258564, ACU_loss:10.98878465, Val_loss:0.67798164)\n",
      "epoch (740 / 2000) (Train_loss:0.44404621, ACU_loss:6.66069318, Val_loss:0.81258408)\n",
      "epoch (741 / 2000) (Train_loss:0.31813189, ACU_loss:4.77197832, Val_loss:0.70399371)\n",
      "epoch (742 / 2000) (Train_loss:0.23315283, ACU_loss:3.49729251, Val_loss:0.72556319)\n",
      "epoch (743 / 2000) (Train_loss:0.38774728, ACU_loss:5.81620919, Val_loss:0.63960584)\n",
      "epoch (744 / 2000) (Train_loss:0.41878793, ACU_loss:6.28181902, Val_loss:0.62158671)\n",
      "epoch (745 / 2000) (Train_loss:0.78108870, ACU_loss:11.71633051, Val_loss:0.70120327)\n",
      "epoch (746 / 2000) (Train_loss:0.69517513, ACU_loss:10.42762697, Val_loss:0.63551393)\n",
      "epoch (747 / 2000) (Train_loss:0.48921288, ACU_loss:7.33819315, Val_loss:0.76312974)\n",
      "epoch (748 / 2000) (Train_loss:0.35864016, ACU_loss:5.37960246, Val_loss:0.64989717)\n",
      "epoch (749 / 2000) (Train_loss:0.24202580, ACU_loss:3.63038705, Val_loss:0.72448001)\n",
      "epoch (750 / 2000) (Train_loss:0.29694872, ACU_loss:4.45423074, Val_loss:0.61420394)\n",
      "epoch (751 / 2000) (Train_loss:0.31082185, ACU_loss:4.66232780, Val_loss:0.61851605)\n",
      "epoch (752 / 2000) (Train_loss:0.68892582, ACU_loss:10.33388729, Val_loss:0.64409632)\n",
      "epoch (753 / 2000) (Train_loss:0.73058091, ACU_loss:10.95871369, Val_loss:0.61424332)\n",
      "epoch (754 / 2000) (Train_loss:0.73323012, ACU_loss:10.99845187, Val_loss:0.75525543)\n",
      "epoch (755 / 2000) (Train_loss:0.56758027, ACU_loss:8.51370412, Val_loss:0.65130324)\n",
      "epoch (756 / 2000) (Train_loss:0.36199071, ACU_loss:5.42986070, Val_loss:0.77110137)\n",
      "epoch (757 / 2000) (Train_loss:0.28580570, ACU_loss:4.28708548, Val_loss:0.64233035)\n",
      "epoch (758 / 2000) (Train_loss:0.23677396, ACU_loss:3.55160936, Val_loss:0.67123559)\n",
      "epoch (759 / 2000) (Train_loss:0.47758313, ACU_loss:7.16374692, Val_loss:0.61109962)\n",
      "epoch (760 / 2000) (Train_loss:0.54675872, ACU_loss:8.20138078, Val_loss:0.60459131)\n",
      "epoch (761 / 2000) (Train_loss:0.86914951, ACU_loss:13.03724265, Val_loss:0.71175387)\n",
      "epoch (762 / 2000) (Train_loss:0.72277119, ACU_loss:10.84156782, Val_loss:0.62358911)\n",
      "epoch (763 / 2000) (Train_loss:0.45860137, ACU_loss:6.87902054, Val_loss:0.76870829)\n",
      "epoch (764 / 2000) (Train_loss:0.33071824, ACU_loss:4.96077359, Val_loss:0.65750248)\n",
      "epoch (765 / 2000) (Train_loss:0.22989064, ACU_loss:3.44835957, Val_loss:0.70311507)\n",
      "epoch (766 / 2000) (Train_loss:0.34067353, ACU_loss:5.11010289, Val_loss:0.60054477)\n",
      "epoch (767 / 2000) (Train_loss:0.36815632, ACU_loss:5.52234483, Val_loss:0.59343357)\n",
      "epoch (768 / 2000) (Train_loss:0.75361802, ACU_loss:11.30427027, Val_loss:0.64515911)\n",
      "epoch (769 / 2000) (Train_loss:0.72578726, ACU_loss:10.88680897, Val_loss:0.60251714)\n",
      "epoch (770 / 2000) (Train_loss:0.57330171, ACU_loss:8.59952565, Val_loss:0.73462189)\n",
      "epoch (771 / 2000) (Train_loss:0.42251668, ACU_loss:6.33775014, Val_loss:0.62252091)\n",
      "epoch (772 / 2000) (Train_loss:0.27595005, ACU_loss:4.13925080, Val_loss:0.72070993)\n",
      "epoch (773 / 2000) (Train_loss:0.25910009, ACU_loss:3.88650133, Val_loss:0.59303197)\n",
      "epoch (774 / 2000) (Train_loss:0.24259336, ACU_loss:3.63890037, Val_loss:0.61792973)\n",
      "epoch (775 / 2000) (Train_loss:0.52802187, ACU_loss:7.92032806, Val_loss:0.58518199)\n",
      "epoch (776 / 2000) (Train_loss:0.60816893, ACU_loss:9.12253396, Val_loss:0.57824685)\n",
      "epoch (777 / 2000) (Train_loss:0.83485862, ACU_loss:12.52287937, Val_loss:0.70763817)\n",
      "epoch (778 / 2000) (Train_loss:0.67313407, ACU_loss:10.09701101, Val_loss:0.59894621)\n",
      "epoch (779 / 2000) (Train_loss:0.43600868, ACU_loss:6.54013016, Val_loss:0.75568592)\n",
      "epoch (780 / 2000) (Train_loss:0.32615309, ACU_loss:4.89229640, Val_loss:0.63838652)\n",
      "epoch (781 / 2000) (Train_loss:0.23782054, ACU_loss:3.56730810, Val_loss:0.68209811)\n",
      "epoch (782 / 2000) (Train_loss:0.40735454, ACU_loss:6.11031805, Val_loss:0.58399344)\n",
      "epoch (783 / 2000) (Train_loss:0.45860552, ACU_loss:6.87908276, Val_loss:0.58372274)\n",
      "epoch (784 / 2000) (Train_loss:0.87439202, ACU_loss:13.11588037, Val_loss:0.65329199)\n",
      "epoch (785 / 2000) (Train_loss:0.77402430, ACU_loss:11.61036448, Val_loss:0.60686083)\n",
      "epoch (786 / 2000) (Train_loss:0.47865514, ACU_loss:7.17982709, Val_loss:0.72928284)\n",
      "epoch (787 / 2000) (Train_loss:0.32972373, ACU_loss:4.94585602, Val_loss:0.61515356)\n",
      "epoch (788 / 2000) (Train_loss:0.22057784, ACU_loss:3.30866753, Val_loss:0.67574821)\n",
      "epoch (789 / 2000) (Train_loss:0.23593666, ACU_loss:3.53904984, Val_loss:0.56296622)\n",
      "epoch (790 / 2000) (Train_loss:0.23294551, ACU_loss:3.49418265, Val_loss:0.57590467)\n",
      "epoch (791 / 2000) (Train_loss:0.49025335, ACU_loss:7.35380031, Val_loss:0.55987020)\n",
      "epoch (792 / 2000) (Train_loss:0.54766295, ACU_loss:8.21494430, Val_loss:0.53735895)\n",
      "epoch (793 / 2000) (Train_loss:0.69794194, ACU_loss:10.46912907, Val_loss:0.68259306)\n",
      "epoch (794 / 2000) (Train_loss:0.56430206, ACU_loss:8.46453091, Val_loss:0.55409153)\n",
      "epoch (795 / 2000) (Train_loss:0.38838457, ACU_loss:5.82576848, Val_loss:0.72116220)\n",
      "epoch (796 / 2000) (Train_loss:0.32527185, ACU_loss:4.87907776, Val_loss:0.58728416)\n",
      "epoch (797 / 2000) (Train_loss:0.26903897, ACU_loss:4.03558455, Val_loss:0.64956542)\n",
      "epoch (798 / 2000) (Train_loss:0.55823455, ACU_loss:8.37351829, Val_loss:0.57190513)\n",
      "epoch (799 / 2000) (Train_loss:0.66772557, ACU_loss:10.01588361, Val_loss:0.59560253)\n",
      "epoch (800 / 2000) (Train_loss:1.10233253, ACU_loss:16.53498801, Val_loss:0.68842612)\n",
      "epoch (801 / 2000) (Train_loss:0.86505681, ACU_loss:12.97585213, Val_loss:0.62879355)\n",
      "epoch (802 / 2000) (Train_loss:0.40691329, ACU_loss:6.10369935, Val_loss:0.77589713)\n",
      "epoch (803 / 2000) (Train_loss:0.27470895, ACU_loss:4.12063426, Val_loss:0.63234609)\n",
      "epoch (804 / 2000) (Train_loss:0.18990687, ACU_loss:2.84860309, Val_loss:0.63187993)\n",
      "epoch (805 / 2000) (Train_loss:0.26616939, ACU_loss:3.99254081, Val_loss:0.54944106)\n",
      "epoch (806 / 2000) (Train_loss:0.28092547, ACU_loss:4.21388210, Val_loss:0.54447141)\n",
      "epoch (807 / 2000) (Train_loss:0.54186348, ACU_loss:8.12795224, Val_loss:0.57097912)\n",
      "epoch (808 / 2000) (Train_loss:0.53279919, ACU_loss:7.99198782, Val_loss:0.52208466)\n",
      "epoch (809 / 2000) (Train_loss:0.51177898, ACU_loss:7.67668472, Val_loss:0.67613462)\n",
      "epoch (810 / 2000) (Train_loss:0.39847192, ACU_loss:5.97707887, Val_loss:0.52893094)\n",
      "epoch (811 / 2000) (Train_loss:0.27793557, ACU_loss:4.16903353, Val_loss:0.67436592)\n",
      "epoch (812 / 2000) (Train_loss:0.30174202, ACU_loss:4.52613026, Val_loss:0.53623071)\n",
      "epoch (813 / 2000) (Train_loss:0.30960445, ACU_loss:4.64406672, Val_loss:0.59270854)\n",
      "epoch (814 / 2000) (Train_loss:0.71917959, ACU_loss:10.78769392, Val_loss:0.56283949)\n",
      "epoch (815 / 2000) (Train_loss:0.86093544, ACU_loss:12.91403158, Val_loss:0.60971643)\n",
      "epoch (816 / 2000) (Train_loss:1.04627664, ACU_loss:15.69414964, Val_loss:0.68711560)\n",
      "epoch (817 / 2000) (Train_loss:0.79906268, ACU_loss:11.98594014, Val_loss:0.62877676)\n",
      "epoch (818 / 2000) (Train_loss:0.46183664, ACU_loss:6.92754964, Val_loss:0.76994196)\n",
      "epoch (819 / 2000) (Train_loss:0.29869559, ACU_loss:4.48043381, Val_loss:0.65166332)\n",
      "epoch (820 / 2000) (Train_loss:0.19412295, ACU_loss:2.91184421, Val_loss:0.65587342)\n",
      "epoch (821 / 2000) (Train_loss:0.20336865, ACU_loss:3.05052974, Val_loss:0.53896612)\n",
      "epoch (822 / 2000) (Train_loss:0.19534110, ACU_loss:2.93011656, Val_loss:0.54161880)\n",
      "epoch (823 / 2000) (Train_loss:0.35879172, ACU_loss:5.38187576, Val_loss:0.51945756)\n",
      "epoch (824 / 2000) (Train_loss:0.38384821, ACU_loss:5.75772316, Val_loss:0.49316472)\n",
      "epoch (825 / 2000) (Train_loss:0.49824574, ACU_loss:7.47368614, Val_loss:0.60673983)\n",
      "epoch (826 / 2000) (Train_loss:0.41774451, ACU_loss:6.26616764, Val_loss:0.48394447)\n",
      "epoch (827 / 2000) (Train_loss:0.33178947, ACU_loss:4.97684198, Val_loss:0.66516069)\n",
      "epoch (828 / 2000) (Train_loss:0.31392316, ACU_loss:4.70884733, Val_loss:0.50641430)\n",
      "epoch (829 / 2000) (Train_loss:0.28499457, ACU_loss:4.27491851, Val_loss:0.61211673)\n",
      "epoch (830 / 2000) (Train_loss:0.61490963, ACU_loss:9.22364443, Val_loss:0.53636959)\n",
      "epoch (831 / 2000) (Train_loss:0.77927749, ACU_loss:11.68916232, Val_loss:0.59772907)\n",
      "epoch (832 / 2000) (Train_loss:1.25834911, ACU_loss:18.87523658, Val_loss:0.67466215)\n",
      "epoch (833 / 2000) (Train_loss:0.97972357, ACU_loss:14.69585352, Val_loss:0.61855216)\n",
      "epoch (834 / 2000) (Train_loss:0.41603189, ACU_loss:6.24047832, Val_loss:0.80128291)\n",
      "epoch (835 / 2000) (Train_loss:0.28786223, ACU_loss:4.31793339, Val_loss:0.61406229)\n",
      "epoch (836 / 2000) (Train_loss:0.18484255, ACU_loss:2.77263830, Val_loss:0.59648711)\n",
      "epoch (837 / 2000) (Train_loss:0.23184638, ACU_loss:3.47769577, Val_loss:0.51948653)\n",
      "epoch (838 / 2000) (Train_loss:0.24364281, ACU_loss:3.65464214, Val_loss:0.52173877)\n",
      "epoch (839 / 2000) (Train_loss:0.47235350, ACU_loss:7.08530250, Val_loss:0.52675741)\n",
      "epoch (840 / 2000) (Train_loss:0.47875976, ACU_loss:7.18139638, Val_loss:0.49147893)\n",
      "epoch (841 / 2000) (Train_loss:0.49173747, ACU_loss:7.37606198, Val_loss:0.63346374)\n",
      "epoch (842 / 2000) (Train_loss:0.38900207, ACU_loss:5.83503101, Val_loss:0.48466098)\n",
      "epoch (843 / 2000) (Train_loss:0.29338196, ACU_loss:4.40072946, Val_loss:0.65408523)\n",
      "epoch (844 / 2000) (Train_loss:0.29788226, ACU_loss:4.46823386, Val_loss:0.50224923)\n",
      "epoch (845 / 2000) (Train_loss:0.29086570, ACU_loss:4.36298552, Val_loss:0.59551556)\n",
      "epoch (846 / 2000) (Train_loss:0.64336137, ACU_loss:9.65042051, Val_loss:0.52846946)\n",
      "epoch (847 / 2000) (Train_loss:0.80581308, ACU_loss:12.08719614, Val_loss:0.60726078)\n",
      "epoch (848 / 2000) (Train_loss:1.16713916, ACU_loss:17.50708734, Val_loss:0.64445629)\n",
      "epoch (849 / 2000) (Train_loss:0.90383099, ACU_loss:13.55746482, Val_loss:0.61711418)\n",
      "epoch (850 / 2000) (Train_loss:0.40577519, ACU_loss:6.08662781, Val_loss:0.75313256)\n",
      "epoch (851 / 2000) (Train_loss:0.26507318, ACU_loss:3.97609769, Val_loss:0.58717924)\n",
      "epoch (852 / 2000) (Train_loss:0.17322294, ACU_loss:2.59834410, Val_loss:0.59071288)\n",
      "epoch (853 / 2000) (Train_loss:0.18386107, ACU_loss:2.75791611, Val_loss:0.50248449)\n",
      "epoch (854 / 2000) (Train_loss:0.18323680, ACU_loss:2.74855201, Val_loss:0.51375049)\n",
      "epoch (855 / 2000) (Train_loss:0.33024328, ACU_loss:4.95364921, Val_loss:0.48617029)\n",
      "epoch (856 / 2000) (Train_loss:0.35754512, ACU_loss:5.36317678, Val_loss:0.46524037)\n",
      "epoch (857 / 2000) (Train_loss:0.47541322, ACU_loss:7.13119828, Val_loss:0.56890789)\n",
      "epoch (858 / 2000) (Train_loss:0.41227625, ACU_loss:6.18414377, Val_loss:0.44927230)\n",
      "epoch (859 / 2000) (Train_loss:0.35339693, ACU_loss:5.30095402, Val_loss:0.65459088)\n",
      "epoch (860 / 2000) (Train_loss:0.32752547, ACU_loss:4.91288202, Val_loss:0.47853014)\n",
      "epoch (861 / 2000) (Train_loss:0.28573078, ACU_loss:4.28596173, Val_loss:0.61991365)\n",
      "epoch (862 / 2000) (Train_loss:0.57259592, ACU_loss:8.58893885, Val_loss:0.51726829)\n",
      "epoch (863 / 2000) (Train_loss:0.73073390, ACU_loss:10.96100855, Val_loss:0.59775552)\n",
      "epoch (864 / 2000) (Train_loss:1.30721072, ACU_loss:19.60816078, Val_loss:0.63517507)\n",
      "epoch (865 / 2000) (Train_loss:1.11715469, ACU_loss:16.75732041, Val_loss:0.61849546)\n",
      "epoch (866 / 2000) (Train_loss:0.43584487, ACU_loss:6.53767301, Val_loss:0.76226043)\n",
      "epoch (867 / 2000) (Train_loss:0.27726939, ACU_loss:4.15904079, Val_loss:0.57274629)\n",
      "epoch (868 / 2000) (Train_loss:0.19544016, ACU_loss:2.93160233, Val_loss:0.57641279)\n",
      "epoch (869 / 2000) (Train_loss:0.15039474, ACU_loss:2.25592111, Val_loss:0.49398376)\n",
      "epoch (870 / 2000) (Train_loss:0.12741938, ACU_loss:1.91129073, Val_loss:0.51610350)\n",
      "epoch (871 / 2000) (Train_loss:0.14324821, ACU_loss:2.14872319, Val_loss:0.44919466)\n",
      "epoch (872 / 2000) (Train_loss:0.14152487, ACU_loss:2.12287310, Val_loss:0.47509494)\n",
      "epoch (873 / 2000) (Train_loss:0.22379380, ACU_loss:3.35690701, Val_loss:0.44164224)\n",
      "epoch (874 / 2000) (Train_loss:0.25123154, ACU_loss:3.76847307, Val_loss:0.41931439)\n",
      "epoch (875 / 2000) (Train_loss:0.36996879, ACU_loss:5.54953191, Val_loss:0.51724776)\n",
      "epoch (876 / 2000) (Train_loss:0.37005052, ACU_loss:5.55075782, Val_loss:0.40441779)\n",
      "epoch (877 / 2000) (Train_loss:0.37670973, ACU_loss:5.65064590, Val_loss:0.68121867)\n",
      "epoch (878 / 2000) (Train_loss:0.38555595, ACU_loss:5.78333931, Val_loss:0.45003027)\n",
      "epoch (879 / 2000) (Train_loss:0.35923572, ACU_loss:5.38853575, Val_loss:0.66248251)\n",
      "epoch (880 / 2000) (Train_loss:0.75085203, ACU_loss:11.26278050, Val_loss:0.56053991)\n",
      "epoch (881 / 2000) (Train_loss:0.98056657, ACU_loss:14.70849852, Val_loss:0.65376484)\n",
      "epoch (882 / 2000) (Train_loss:1.66908032, ACU_loss:25.03620486, Val_loss:0.69404725)\n",
      "epoch (883 / 2000) (Train_loss:1.46435052, ACU_loss:21.96525779, Val_loss:0.62282382)\n",
      "epoch (884 / 2000) (Train_loss:1.39452597, ACU_loss:20.91788956, Val_loss:1.10255440)\n",
      "epoch (885 / 2000) (Train_loss:1.59750135, ACU_loss:23.96252031, Val_loss:1.46338191)\n",
      "epoch (886 / 2000) (Train_loss:0.61108782, ACU_loss:9.16631727, Val_loss:1.23759973)\n",
      "epoch (887 / 2000) (Train_loss:0.63566095, ACU_loss:9.53491429, Val_loss:0.85385103)\n",
      "epoch (888 / 2000) (Train_loss:0.37941775, ACU_loss:5.69126623, Val_loss:0.72614828)\n",
      "epoch (889 / 2000) (Train_loss:0.59214144, ACU_loss:8.88212156, Val_loss:0.66100450)\n",
      "epoch (890 / 2000) (Train_loss:0.33991454, ACU_loss:5.09871813, Val_loss:0.71035602)\n",
      "epoch (891 / 2000) (Train_loss:0.16600039, ACU_loss:2.49000581, Val_loss:0.62997218)\n",
      "epoch (892 / 2000) (Train_loss:0.12830589, ACU_loss:1.92458842, Val_loss:0.55778253)\n",
      "epoch (893 / 2000) (Train_loss:0.12430196, ACU_loss:1.86452941, Val_loss:0.53398540)\n",
      "epoch (894 / 2000) (Train_loss:0.11578335, ACU_loss:1.73675022, Val_loss:0.50265203)\n",
      "epoch (895 / 2000) (Train_loss:0.11234116, ACU_loss:1.68511733, Val_loss:0.50103793)\n",
      "epoch (896 / 2000) (Train_loss:0.11104507, ACU_loss:1.66567604, Val_loss:0.46894090)\n",
      "epoch (897 / 2000) (Train_loss:0.10524456, ACU_loss:1.57866833, Val_loss:0.47067913)\n",
      "epoch (898 / 2000) (Train_loss:0.11102445, ACU_loss:1.66536671, Val_loss:0.44592718)\n",
      "epoch (899 / 2000) (Train_loss:0.10449556, ACU_loss:1.56743336, Val_loss:0.44075545)\n",
      "epoch (900 / 2000) (Train_loss:0.11429553, ACU_loss:1.71443294, Val_loss:0.43536934)\n",
      "epoch (901 / 2000) (Train_loss:0.10944839, ACU_loss:1.64172587, Val_loss:0.40856275)\n",
      "epoch (902 / 2000) (Train_loss:0.11403391, ACU_loss:1.71050871, Val_loss:0.44009655)\n",
      "epoch (903 / 2000) (Train_loss:0.11483370, ACU_loss:1.72250549, Val_loss:0.38245405)\n",
      "epoch (904 / 2000) (Train_loss:0.10809853, ACU_loss:1.62147802, Val_loss:0.45014460)\n",
      "epoch (905 / 2000) (Train_loss:0.13975558, ACU_loss:2.09633377, Val_loss:0.36992033)\n",
      "epoch (906 / 2000) (Train_loss:0.15521323, ACU_loss:2.32819850, Val_loss:0.41507922)\n",
      "epoch (907 / 2000) (Train_loss:0.28225186, ACU_loss:4.23377783, Val_loss:0.39675225)\n",
      "epoch (908 / 2000) (Train_loss:0.37264127, ACU_loss:5.58961908, Val_loss:0.34564260)\n",
      "epoch (909 / 2000) (Train_loss:0.55757386, ACU_loss:8.36360797, Val_loss:0.62624548)\n",
      "epoch (910 / 2000) (Train_loss:0.55926303, ACU_loss:8.38894544, Val_loss:0.39734116)\n",
      "epoch (911 / 2000) (Train_loss:0.47462116, ACU_loss:7.11931741, Val_loss:0.80704118)\n",
      "epoch (912 / 2000) (Train_loss:0.62237783, ACU_loss:9.33566746, Val_loss:0.56693354)\n",
      "epoch (913 / 2000) (Train_loss:0.62787114, ACU_loss:9.41806714, Val_loss:0.62400525)\n",
      "epoch (914 / 2000) (Train_loss:1.60649144, ACU_loss:24.09737163, Val_loss:0.75831505)\n",
      "epoch (915 / 2000) (Train_loss:1.67430893, ACU_loss:25.11463394, Val_loss:0.60003050)\n",
      "epoch (916 / 2000) (Train_loss:0.87528966, ACU_loss:13.12934491, Val_loss:0.71222882)\n",
      "epoch (917 / 2000) (Train_loss:0.52134706, ACU_loss:7.82020591, Val_loss:0.60286306)\n",
      "epoch (918 / 2000) (Train_loss:0.32537890, ACU_loss:4.88068355, Val_loss:0.71175354)\n",
      "epoch (919 / 2000) (Train_loss:0.29062174, ACU_loss:4.35932615, Val_loss:0.52772142)\n",
      "epoch (920 / 2000) (Train_loss:0.27327877, ACU_loss:4.09918151, Val_loss:0.56271566)\n",
      "epoch (921 / 2000) (Train_loss:0.61507591, ACU_loss:9.22613861, Val_loss:0.50332330)\n",
      "epoch (922 / 2000) (Train_loss:0.61842128, ACU_loss:9.27631918, Val_loss:0.62099139)\n",
      "epoch (923 / 2000) (Train_loss:0.43707890, ACU_loss:6.55618345, Val_loss:0.54958104)\n",
      "epoch (924 / 2000) (Train_loss:0.29870704, ACU_loss:4.48060561, Val_loss:0.45872142)\n",
      "epoch (925 / 2000) (Train_loss:0.37413177, ACU_loss:5.61197652, Val_loss:0.53574507)\n",
      "epoch (926 / 2000) (Train_loss:0.27995990, ACU_loss:4.19939857, Val_loss:0.44604384)\n",
      "epoch (927 / 2000) (Train_loss:0.22632655, ACU_loss:3.39489819, Val_loss:0.60435074)\n",
      "epoch (928 / 2000) (Train_loss:0.23903037, ACU_loss:3.58545555, Val_loss:0.43446932)\n",
      "epoch (929 / 2000) (Train_loss:0.23342377, ACU_loss:3.50135660, Val_loss:0.56308307)\n",
      "epoch (930 / 2000) (Train_loss:0.44920223, ACU_loss:6.73803350, Val_loss:0.44672625)\n",
      "epoch (931 / 2000) (Train_loss:0.56188911, ACU_loss:8.42833666, Val_loss:0.55872107)\n",
      "epoch (932 / 2000) (Train_loss:0.93890294, ACU_loss:14.08354403, Val_loss:0.51867788)\n",
      "epoch (933 / 2000) (Train_loss:0.86953063, ACU_loss:13.04295940, Val_loss:0.62206347)\n",
      "epoch (934 / 2000) (Train_loss:0.40503985, ACU_loss:6.07559771, Val_loss:0.60897313)\n",
      "epoch (935 / 2000) (Train_loss:0.23711937, ACU_loss:3.55679055, Val_loss:0.45289391)\n",
      "epoch (936 / 2000) (Train_loss:0.22047560, ACU_loss:3.30713394, Val_loss:0.51410219)\n",
      "epoch (937 / 2000) (Train_loss:0.17729687, ACU_loss:2.65945307, Val_loss:0.43025241)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = myDataset(com_train, train_orig, past_wafer, future_step)\n",
    "test_dataset = myDataset(com_test, test_extend, past_wafer, future_step)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "# split training and validation dataset\n",
    "train_dataloader, val_dataloader = get_loaders(train_dataset, seed, batch_size, val_ratio)\n",
    "\n",
    "# establish the model\n",
    "model = GRUmodel(input_dim, inter_dim, layer_num).to('cuda')\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "# save path of the best model\n",
    "now = datetime.now()\n",
    "datestr = now.strftime('%m_%d-%H_%M_%S')\n",
    "save_path = f'./save_path/{datestr}.pt'\n",
    "\n",
    "# start training\n",
    "train(model, train_dataloader, val_dataloader, optimizer, 2000, 'cuda', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  12.161\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the best model for testing\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "best_model = model.to('cuda')\n",
    "avg_loss, test_list = test(best_model, test_dataloader, 'cuda')\n",
    "print('MSE : ', round(avg_loss, 3))\n",
    "\n",
    "# plot the result\n",
    "y_train = train_orig\n",
    "y_pred = test_list[0]\n",
    "y_truth = test_list[1]\n",
    "\n",
    "plt.figure(figsize=(15, 2), dpi=100)\n",
    "plt.plot(range(y_train.shape[0]), y_train, label='Train')\n",
    "plt.plot(range(y_train.shape[0], y_train.shape[0] + len(y_truth)), y_truth, label='Test')\n",
    "plt.plot(range(y_train.shape[0], y_train.shape[0] + len(y_truth)), y_pred, label='pred')\n",
    "plt.title(dataset)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "dataset = 'B456'\n",
    "batch_size = 64\n",
    "input_dim = 1\n",
    "inter_dim = 64\n",
    "layer_num = 1\n",
    "past_wafer = 4\n",
    "future_step = 1\n",
    "val_ratio = 0.3\n",
    "seed = 2\n",
    "\n",
    "# set random seed\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "unsampled\n",
      "statistic-RF VM test loss 5.976\n",
      "------------------------------------------------\n",
      "test\n",
      "statistic-RF VM test loss 17.214\n",
      "------------------------------------------------\n",
      "all\n",
      "statistic-RF VM test loss 11.18\n",
      "------------------------------------------------\n",
      "extend\n",
      "statistic-RF VM test loss 17.186\n"
     ]
    }
   ],
   "source": [
    "# get training and testing dataset\n",
    "train_orig, test_orig = get_data(dataset)\n",
    "# concat the first n wafer data from training set\n",
    "test_extend = pd.concat((train_orig[-past_wafer:], test_orig))\n",
    "\n",
    "vm_pred = get_Stats_pred(dataset,'RF')\n",
    "vm_train = vm_pred['unsampled']\n",
    "vm_test = vm_pred['extend']\n",
    "com_train, com_test = combine_vm_data(train_orig, test_extend, vm_train, vm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1 / 2000) (Train_loss:5602.65185432, ACU_loss:22410.60741726, Val_loss:6832.39277413)\n",
      "epoch (2 / 2000) (Train_loss:5546.49591949, ACU_loss:22185.98367797, Val_loss:6776.76415727)\n",
      "epoch (3 / 2000) (Train_loss:5498.00022918, ACU_loss:21992.00091671, Val_loss:6729.17139326)\n",
      "epoch (4 / 2000) (Train_loss:5454.76739576, ACU_loss:21819.06958305, Val_loss:6684.61507920)\n",
      "epoch (5 / 2000) (Train_loss:5412.24339835, ACU_loss:21648.97359339, Val_loss:6637.79311966)\n",
      "epoch (6 / 2000) (Train_loss:5366.19467688, ACU_loss:21464.77870752, Val_loss:6584.61950593)\n",
      "epoch (7 / 2000) (Train_loss:5314.22164500, ACU_loss:21256.88657999, Val_loss:6524.01358918)\n",
      "epoch (8 / 2000) (Train_loss:5256.73878059, ACU_loss:21026.95512235, Val_loss:6457.91209010)\n",
      "epoch (9 / 2000) (Train_loss:5195.19494002, ACU_loss:20780.77976010, Val_loss:6387.80512457)\n",
      "epoch (10 / 2000) (Train_loss:5132.76345492, ACU_loss:20531.05381969, Val_loss:6319.96490440)\n",
      "epoch (11 / 2000) (Train_loss:5074.30771578, ACU_loss:20297.23086313, Val_loss:6256.60802745)\n",
      "epoch (12 / 2000) (Train_loss:5017.73139855, ACU_loss:20070.92559422, Val_loss:6192.92267400)\n",
      "epoch (13 / 2000) (Train_loss:4963.67140817, ACU_loss:19854.68563268, Val_loss:6133.99460180)\n",
      "epoch (14 / 2000) (Train_loss:4914.08422827, ACU_loss:19656.33691308, Val_loss:6079.08553522)\n",
      "epoch (15 / 2000) (Train_loss:4865.39265621, ACU_loss:19461.57062485, Val_loss:6024.09233285)\n",
      "epoch (16 / 2000) (Train_loss:4817.75395047, ACU_loss:19271.01580189, Val_loss:5970.96035924)\n",
      "epoch (17 / 2000) (Train_loss:4773.20232795, ACU_loss:19092.80931178, Val_loss:5921.46190964)\n",
      "epoch (18 / 2000) (Train_loss:4730.89080710, ACU_loss:18923.56322842, Val_loss:5874.04875031)\n",
      "epoch (19 / 2000) (Train_loss:4690.20616310, ACU_loss:18760.82465242, Val_loss:5829.20534580)\n",
      "epoch (20 / 2000) (Train_loss:4651.65573984, ACU_loss:18606.62295934, Val_loss:5786.69135867)\n",
      "epoch (21 / 2000) (Train_loss:4614.53256543, ACU_loss:18458.13026172, Val_loss:5745.73168667)\n",
      "epoch (22 / 2000) (Train_loss:4578.41302285, ACU_loss:18313.65209140, Val_loss:5705.65663977)\n",
      "epoch (23 / 2000) (Train_loss:4542.23776640, ACU_loss:18168.95106562, Val_loss:5664.90768175)\n",
      "epoch (24 / 2000) (Train_loss:4504.79047436, ACU_loss:18019.16189744, Val_loss:5622.13208489)\n",
      "epoch (25 / 2000) (Train_loss:4466.04410972, ACU_loss:17864.17643889, Val_loss:5578.49833474)\n",
      "epoch (26 / 2000) (Train_loss:4427.79124927, ACU_loss:17711.16499709, Val_loss:5536.01691272)\n",
      "epoch (27 / 2000) (Train_loss:4389.33254357, ACU_loss:17557.33017428, Val_loss:5492.02729256)\n",
      "epoch (28 / 2000) (Train_loss:4349.86348024, ACU_loss:17399.45392094, Val_loss:5447.12281889)\n",
      "epoch (29 / 2000) (Train_loss:4311.62596534, ACU_loss:17246.50386135, Val_loss:5404.78356716)\n",
      "epoch (30 / 2000) (Train_loss:4275.47960170, ACU_loss:17101.91840681, Val_loss:5365.08423914)\n",
      "epoch (31 / 2000) (Train_loss:4240.90326709, ACU_loss:16963.61306838, Val_loss:5326.75416743)\n",
      "epoch (32 / 2000) (Train_loss:4207.08077354, ACU_loss:16828.32309417, Val_loss:5288.96451194)\n",
      "epoch (33 / 2000) (Train_loss:4173.52293910, ACU_loss:16694.09175641, Val_loss:5251.34941375)\n",
      "epoch (34 / 2000) (Train_loss:4139.68463278, ACU_loss:16558.73853114, Val_loss:5213.16764314)\n",
      "epoch (35 / 2000) (Train_loss:4104.18489857, ACU_loss:16416.73959428, Val_loss:5172.29459645)\n",
      "epoch (36 / 2000) (Train_loss:4064.76109944, ACU_loss:16259.04439775, Val_loss:5125.70235996)\n",
      "epoch (37 / 2000) (Train_loss:4022.45403122, ACU_loss:16089.81612487, Val_loss:5077.45204990)\n",
      "epoch (38 / 2000) (Train_loss:3983.02727799, ACU_loss:15932.10911195, Val_loss:5034.55442821)\n",
      "epoch (39 / 2000) (Train_loss:3945.86247117, ACU_loss:15783.44988469, Val_loss:4992.25195080)\n",
      "epoch (40 / 2000) (Train_loss:3907.84707990, ACU_loss:15631.38831959, Val_loss:4949.07767595)\n",
      "epoch (41 / 2000) (Train_loss:3870.53136754, ACU_loss:15482.12547015, Val_loss:4907.13743210)\n",
      "epoch (42 / 2000) (Train_loss:3832.11726407, ACU_loss:15328.46905627, Val_loss:4862.45089058)\n",
      "epoch (43 / 2000) (Train_loss:3792.77058097, ACU_loss:15171.08232386, Val_loss:4818.57002326)\n",
      "epoch (44 / 2000) (Train_loss:3756.71466378, ACU_loss:15026.85865513, Val_loss:4778.89630089)\n",
      "epoch (45 / 2000) (Train_loss:3722.19733753, ACU_loss:14888.78935011, Val_loss:4739.93012795)\n",
      "epoch (46 / 2000) (Train_loss:3687.39230105, ACU_loss:14749.56920418, Val_loss:4699.94142520)\n",
      "epoch (47 / 2000) (Train_loss:3651.15041116, ACU_loss:14604.60164463, Val_loss:4657.74579044)\n",
      "epoch (48 / 2000) (Train_loss:3614.65194104, ACU_loss:14458.60776414, Val_loss:4617.10605460)\n",
      "epoch (49 / 2000) (Train_loss:3580.47748231, ACU_loss:14321.90992925, Val_loss:4579.09605235)\n",
      "epoch (50 / 2000) (Train_loss:3547.51030892, ACU_loss:14190.04123570, Val_loss:4541.90888514)\n",
      "epoch (51 / 2000) (Train_loss:3515.05595513, ACU_loss:14060.22382054, Val_loss:4505.22090281)\n",
      "epoch (52 / 2000) (Train_loss:3483.03566169, ACU_loss:13932.14264677, Val_loss:4468.99575433)\n",
      "epoch (53 / 2000) (Train_loss:3451.43223439, ACU_loss:13805.72893757, Val_loss:4433.21468278)\n",
      "epoch (54 / 2000) (Train_loss:3420.22934977, ACU_loss:13680.91739907, Val_loss:4397.85837247)\n",
      "epoch (55 / 2000) (Train_loss:3389.40962674, ACU_loss:13557.63850696, Val_loss:4362.90734104)\n",
      "epoch (56 / 2000) (Train_loss:3358.95585782, ACU_loss:13435.82343126, Val_loss:4328.34293289)\n",
      "epoch (57 / 2000) (Train_loss:3328.85178201, ACU_loss:13315.40712805, Val_loss:4294.14783576)\n",
      "epoch (58 / 2000) (Train_loss:3299.08241910, ACU_loss:13196.32967640, Val_loss:4260.30625862)\n",
      "epoch (59 / 2000) (Train_loss:3269.63415352, ACU_loss:13078.53661409, Val_loss:4226.80392531)\n",
      "epoch (60 / 2000) (Train_loss:3240.49469070, ACU_loss:12961.97876278, Val_loss:4193.62797860)\n",
      "epoch (61 / 2000) (Train_loss:3211.65295481, ACU_loss:12846.61181923, Val_loss:4160.76684745)\n",
      "epoch (62 / 2000) (Train_loss:3183.09896543, ACU_loss:12732.39586174, Val_loss:4128.21010539)\n",
      "epoch (63 / 2000) (Train_loss:3154.82371225, ACU_loss:12619.29484901, Val_loss:4095.94833411)\n",
      "epoch (64 / 2000) (Train_loss:3126.81903724, ACU_loss:12507.27614898, Val_loss:4063.97299868)\n",
      "epoch (65 / 2000) (Train_loss:3099.07752838, ACU_loss:12396.31011352, Val_loss:4032.27633664)\n",
      "epoch (66 / 2000) (Train_loss:3071.59242582, ACU_loss:12286.36970330, Val_loss:4000.85126111)\n",
      "epoch (67 / 2000) (Train_loss:3044.35754032, ACU_loss:12177.43016130, Val_loss:3969.69127684)\n",
      "epoch (68 / 2000) (Train_loss:3017.36718269, ACU_loss:12069.46873074, Val_loss:3938.79040801)\n",
      "epoch (69 / 2000) (Train_loss:2990.61610305, ACU_loss:11962.46441222, Val_loss:3908.14313607)\n",
      "epoch (70 / 2000) (Train_loss:2964.09943863, ACU_loss:11856.39775451, Val_loss:3877.74434641)\n",
      "epoch (71 / 2000) (Train_loss:2937.81266855, ACU_loss:11751.25067420, Val_loss:3847.58928234)\n",
      "epoch (72 / 2000) (Train_loss:2911.75157480, ACU_loss:11647.00629921, Val_loss:3817.67350529)\n",
      "epoch (73 / 2000) (Train_loss:2885.91220818, ACU_loss:11543.64883272, Val_loss:3787.99286021)\n",
      "epoch (74 / 2000) (Train_loss:2860.29085867, ACU_loss:11441.16343469, Val_loss:3758.54344519)\n",
      "epoch (75 / 2000) (Train_loss:2834.88403042, ACU_loss:11339.53612168, Val_loss:3729.32158483)\n",
      "epoch (76 / 2000) (Train_loss:2809.68842316, ACU_loss:11238.75369264, Val_loss:3700.32380778)\n",
      "epoch (77 / 2000) (Train_loss:2784.70092474, ACU_loss:11138.80369895, Val_loss:3671.54683103)\n",
      "epoch (78 / 2000) (Train_loss:2759.91861826, ACU_loss:11039.67447304, Val_loss:3642.98755540)\n",
      "epoch (79 / 2000) (Train_loss:2735.33878867, ACU_loss:10941.35515468, Val_loss:3614.64306737)\n",
      "epoch (80 / 2000) (Train_loss:2710.95888441, ACU_loss:10843.83553764, Val_loss:3586.51061842)\n",
      "epoch (81 / 2000) (Train_loss:2686.77642959, ACU_loss:10747.10571838, Val_loss:3558.58757302)\n",
      "epoch (82 / 2000) (Train_loss:2662.78897919, ACU_loss:10651.15591676, Val_loss:3530.87137715)\n",
      "epoch (83 / 2000) (Train_loss:2638.99415513, ACU_loss:10555.97662052, Val_loss:3503.35956688)\n",
      "epoch (84 / 2000) (Train_loss:2615.38968502, ACU_loss:10461.55874009, Val_loss:3476.04978022)\n",
      "epoch (85 / 2000) (Train_loss:2591.97340439, ACU_loss:10367.89361754, Val_loss:3448.93975547)\n",
      "epoch (86 / 2000) (Train_loss:2568.74324308, ACU_loss:10274.97297233, Val_loss:3422.02732302)\n",
      "epoch (87 / 2000) (Train_loss:2545.69721266, ACU_loss:10182.78885065, Val_loss:3395.31039676)\n",
      "epoch (88 / 2000) (Train_loss:2522.83339740, ACU_loss:10091.33358962, Val_loss:3368.78696688)\n",
      "epoch (89 / 2000) (Train_loss:2500.14994781, ACU_loss:10000.59979123, Val_loss:3342.45509383)\n",
      "epoch (90 / 2000) (Train_loss:2477.64507546, ACU_loss:9910.58030185, Val_loss:3316.31290323)\n",
      "epoch (91 / 2000) (Train_loss:2455.31704870, ACU_loss:9821.26819479, Val_loss:3290.35858139)\n",
      "epoch (92 / 2000) (Train_loss:2433.16418876, ACU_loss:9732.65675505, Val_loss:3264.59037125)\n",
      "epoch (93 / 2000) (Train_loss:2411.18486638, ACU_loss:9644.73946552, Val_loss:3239.00656881)\n",
      "epoch (94 / 2000) (Train_loss:2389.37749863, ACU_loss:9557.50999451, Val_loss:3213.60551973)\n",
      "epoch (95 / 2000) (Train_loss:2367.74054608, ACU_loss:9470.96218432, Val_loss:3188.38561635)\n",
      "epoch (96 / 2000) (Train_loss:2346.27251019, ACU_loss:9385.09004074, Val_loss:3163.34529489)\n",
      "epoch (97 / 2000) (Train_loss:2324.97193086, ACU_loss:9299.88772345, Val_loss:3138.48303285)\n",
      "epoch (98 / 2000) (Train_loss:2303.83738427, ACU_loss:9215.34953710, Val_loss:3113.79734666)\n",
      "epoch (99 / 2000) (Train_loss:2282.86748076, ACU_loss:9131.46992305, Val_loss:3089.28678947)\n",
      "epoch (100 / 2000) (Train_loss:2262.06086296, ACU_loss:9048.24345186, Val_loss:3064.94994915)\n",
      "epoch (101 / 2000) (Train_loss:2241.41620404, ACU_loss:8965.66481616, Val_loss:3040.78544635)\n",
      "epoch (102 / 2000) (Train_loss:2220.93220604, ACU_loss:8883.72882416, Val_loss:3016.79193280)\n",
      "epoch (103 / 2000) (Train_loss:2200.60759839, ACU_loss:8802.43039354, Val_loss:2992.96808967)\n",
      "epoch (104 / 2000) (Train_loss:2180.44113646, ACU_loss:8721.76454583, Val_loss:2969.31262603)\n",
      "epoch (105 / 2000) (Train_loss:2160.43160028, ACU_loss:8641.72640112, Val_loss:2945.82427747)\n",
      "epoch (106 / 2000) (Train_loss:2140.57779329, ACU_loss:8562.31117316, Val_loss:2922.50180475)\n",
      "epoch (107 / 2000) (Train_loss:2120.87854119, ACU_loss:8483.51416474, Val_loss:2899.34399262)\n",
      "epoch (108 / 2000) (Train_loss:2101.33269087, ACU_loss:8405.33076347, Val_loss:2876.34964860)\n",
      "epoch (109 / 2000) (Train_loss:2081.93910943, ACU_loss:8327.75643771, Val_loss:2853.51760197)\n",
      "epoch (110 / 2000) (Train_loss:2062.69668321, ACU_loss:8250.78673284, Val_loss:2830.84670269)\n",
      "epoch (111 / 2000) (Train_loss:2043.60431693, ACU_loss:8174.41726772, Val_loss:2808.33582053)\n",
      "epoch (112 / 2000) (Train_loss:2024.66093286, ACU_loss:8098.64373143, Val_loss:2785.98384412)\n",
      "epoch (113 / 2000) (Train_loss:2005.86547002, ACU_loss:8023.46188009, Val_loss:2763.78968012)\n",
      "epoch (114 / 2000) (Train_loss:1987.21688351, ACU_loss:7948.86753404, Val_loss:2741.75225249)\n",
      "epoch (115 / 2000) (Train_loss:1968.71414375, ACU_loss:7874.85657500, Val_loss:2719.87050168)\n",
      "epoch (116 / 2000) (Train_loss:1950.35623589, ACU_loss:7801.42494354, Val_loss:2698.14338397)\n",
      "epoch (117 / 2000) (Train_loss:1932.14215917, ACU_loss:7728.56863667, Val_loss:2676.56987081)\n",
      "epoch (118 / 2000) (Train_loss:1914.07092636, ACU_loss:7656.28370545, Val_loss:2655.14894818)\n",
      "epoch (119 / 2000) (Train_loss:1896.14156323, ACU_loss:7584.56625293, Val_loss:2633.87961604)\n",
      "epoch (120 / 2000) (Train_loss:1878.35310801, ACU_loss:7513.41243204, Val_loss:2612.76088776)\n",
      "epoch (121 / 2000) (Train_loss:1860.70461092, ACU_loss:7442.81844366, Val_loss:2591.79178958)\n",
      "epoch (122 / 2000) (Train_loss:1843.19513370, ACU_loss:7372.78053482, Val_loss:2570.97136015)\n",
      "epoch (123 / 2000) (Train_loss:1825.82374923, ACU_loss:7303.29499694, Val_loss:2550.29865002)\n",
      "epoch (124 / 2000) (Train_loss:1808.58954105, ACU_loss:7234.35816420, Val_loss:2529.77272123)\n",
      "epoch (125 / 2000) (Train_loss:1791.49160300, ACU_loss:7165.96641201, Val_loss:2509.39264691)\n",
      "epoch (126 / 2000) (Train_loss:1774.52903887, ACU_loss:7098.11615549, Val_loss:2489.15751080)\n",
      "epoch (127 / 2000) (Train_loss:1757.70096203, ACU_loss:7030.80384813, Val_loss:2469.06640695)\n",
      "epoch (128 / 2000) (Train_loss:1741.00649510, ACU_loss:6964.02598041, Val_loss:2449.11843934)\n",
      "epoch (129 / 2000) (Train_loss:1724.44476965, ACU_loss:6897.77907859, Val_loss:2429.31272151)\n",
      "epoch (130 / 2000) (Train_loss:1708.01492587, ACU_loss:6832.05970347, Val_loss:2409.64837629)\n",
      "epoch (131 / 2000) (Train_loss:1691.71611232, ACU_loss:6766.86444929, Val_loss:2390.12453543)\n",
      "epoch (132 / 2000) (Train_loss:1675.54748565, ACU_loss:6702.18994262, Val_loss:2370.74033935)\n",
      "epoch (133 / 2000) (Train_loss:1659.50821034, ACU_loss:6638.03284135, Val_loss:2351.49493684)\n",
      "epoch (134 / 2000) (Train_loss:1643.59745843, ACU_loss:6574.38983371, Val_loss:2332.38748480)\n",
      "epoch (135 / 2000) (Train_loss:1627.81440933, ACU_loss:6511.25763731, Val_loss:2313.41714801)\n",
      "epoch (136 / 2000) (Train_loss:1612.15824957, ACU_loss:6448.63299829, Val_loss:2294.58309882)\n",
      "epoch (137 / 2000) (Train_loss:1596.62817261, ACU_loss:6386.51269044, Val_loss:2275.88451701)\n",
      "epoch (138 / 2000) (Train_loss:1581.22337860, ACU_loss:6324.89351441, Val_loss:2257.32058950)\n",
      "epoch (139 / 2000) (Train_loss:1565.94307423, ACU_loss:6263.77229692, Val_loss:2238.89051017)\n",
      "epoch (140 / 2000) (Train_loss:1550.78647252, ACU_loss:6203.14589006, Val_loss:2220.59347964)\n",
      "epoch (141 / 2000) (Train_loss:1535.75279263, ACU_loss:6143.01117053, Val_loss:2202.42870513)\n",
      "epoch (142 / 2000) (Train_loss:1520.84125976, ACU_loss:6083.36503903, Val_loss:2184.39540019)\n",
      "epoch (143 / 2000) (Train_loss:1506.05110489, ACU_loss:6024.20441956, Val_loss:2166.49278461)\n",
      "epoch (144 / 2000) (Train_loss:1491.38156471, ACU_loss:5965.52625885, Val_loss:2148.72008420)\n",
      "epoch (145 / 2000) (Train_loss:1476.83188144, ACU_loss:5907.32752576, Val_loss:2131.07653065)\n",
      "epoch (146 / 2000) (Train_loss:1462.40130267, ACU_loss:5849.60521069, Val_loss:2113.56136137)\n",
      "epoch (147 / 2000) (Train_loss:1448.08908128, ACU_loss:5792.35632510, Val_loss:2096.17381936)\n",
      "epoch (148 / 2000) (Train_loss:1433.89447524, ACU_loss:5735.57790094, Val_loss:2078.91315304)\n",
      "epoch (149 / 2000) (Train_loss:1419.81674755, ACU_loss:5679.26699020, Val_loss:2061.77861613)\n",
      "epoch (150 / 2000) (Train_loss:1405.85516610, ACU_loss:5623.42066439, Val_loss:2044.76946753)\n",
      "epoch (151 / 2000) (Train_loss:1392.00900354, ACU_loss:5568.03601414, Val_loss:2027.88497118)\n",
      "epoch (152 / 2000) (Train_loss:1378.27753718, ACU_loss:5513.11014874, Val_loss:2011.12439597)\n",
      "epoch (153 / 2000) (Train_loss:1364.66004893, ACU_loss:5458.64019572, Val_loss:1994.48701557)\n",
      "epoch (154 / 2000) (Train_loss:1351.15582511, ACU_loss:5404.62330046, Val_loss:1977.97210839)\n",
      "epoch (155 / 2000) (Train_loss:1337.76415645, ACU_loss:5351.05662581, Val_loss:1961.57895742)\n",
      "epoch (156 / 2000) (Train_loss:1324.48433793, ACU_loss:5297.93735174, Val_loss:1945.30685015)\n",
      "epoch (157 / 2000) (Train_loss:1311.31566873, ACU_loss:5245.26267493, Val_loss:1929.15507850)\n",
      "epoch (158 / 2000) (Train_loss:1298.25745213, ACU_loss:5193.02980851, Val_loss:1913.12293868)\n",
      "epoch (159 / 2000) (Train_loss:1285.30899542, ACU_loss:5141.23598168, Val_loss:1897.20973111)\n",
      "epoch (160 / 2000) (Train_loss:1272.46960985, ACU_loss:5089.87843941, Val_loss:1881.41476038)\n",
      "epoch (161 / 2000) (Train_loss:1259.73861054, ACU_loss:5038.95444218, Val_loss:1865.73733511)\n",
      "epoch (162 / 2000) (Train_loss:1247.11531640, ACU_loss:4988.46126561, Val_loss:1850.17676790)\n",
      "epoch (163 / 2000) (Train_loss:1234.59905007, ACU_loss:4938.39620029, Val_loss:1834.73237526)\n",
      "epoch (164 / 2000) (Train_loss:1222.18913786, ACU_loss:4888.75655143, Val_loss:1819.40347751)\n",
      "epoch (165 / 2000) (Train_loss:1209.88490966, ACU_loss:4839.53963865, Val_loss:1804.18939873)\n",
      "epoch (166 / 2000) (Train_loss:1197.68569892, ACU_loss:4790.74279570, Val_loss:1789.08946671)\n",
      "epoch (167 / 2000) (Train_loss:1185.59084257, ACU_loss:4742.36337027, Val_loss:1774.10301283)\n",
      "epoch (168 / 2000) (Train_loss:1173.59968093, ACU_loss:4694.39872373, Val_loss:1759.22937204)\n",
      "epoch (169 / 2000) (Train_loss:1161.71155773, ACU_loss:4646.84623092, Val_loss:1744.46788281)\n",
      "epoch (170 / 2000) (Train_loss:1149.92581999, ACU_loss:4599.70327995, Val_loss:1729.81788703)\n",
      "epoch (171 / 2000) (Train_loss:1138.24181800, ACU_loss:4552.96727200, Val_loss:1715.27872999)\n",
      "epoch (172 / 2000) (Train_loss:1126.65890527, ACU_loss:4506.63562109, Val_loss:1700.84976030)\n",
      "epoch (173 / 2000) (Train_loss:1115.17643849, ACU_loss:4460.70575395, Val_loss:1686.53032985)\n",
      "epoch (174 / 2000) (Train_loss:1103.79377745, ACU_loss:4415.17510980, Val_loss:1672.31979377)\n",
      "epoch (175 / 2000) (Train_loss:1092.51028505, ACU_loss:4370.04114020, Val_loss:1658.21751037)\n",
      "epoch (176 / 2000) (Train_loss:1081.32532721, ACU_loss:4325.30130886, Val_loss:1644.22284110)\n",
      "epoch (177 / 2000) (Train_loss:1070.23827288, ACU_loss:4280.95309151, Val_loss:1630.33515049)\n",
      "epoch (178 / 2000) (Train_loss:1059.24849393, ACU_loss:4236.99397572, Val_loss:1616.55380613)\n",
      "epoch (179 / 2000) (Train_loss:1048.35536519, ACU_loss:4193.42146077, Val_loss:1602.87817861)\n",
      "epoch (180 / 2000) (Train_loss:1037.55826438, ACU_loss:4150.23305751, Val_loss:1589.30764148)\n",
      "epoch (181 / 2000) (Train_loss:1026.85657205, ACU_loss:4107.42628819, Val_loss:1575.84157123)\n",
      "epoch (182 / 2000) (Train_loss:1016.24967159, ACU_loss:4064.99868637, Val_loss:1562.47934724)\n",
      "epoch (183 / 2000) (Train_loss:1005.73694919, ACU_loss:4022.94779677, Val_loss:1549.22035175)\n",
      "epoch (184 / 2000) (Train_loss:995.31779379, ACU_loss:3981.27117515, Val_loss:1536.06396980)\n",
      "epoch (185 / 2000) (Train_loss:984.99159705, ACU_loss:3939.96638821, Val_loss:1523.00958924)\n",
      "epoch (186 / 2000) (Train_loss:974.75775336, ACU_loss:3899.03101344, Val_loss:1510.05660067)\n",
      "epoch (187 / 2000) (Train_loss:964.61565976, ACU_loss:3858.46263905, Val_loss:1497.20439741)\n",
      "epoch (188 / 2000) (Train_loss:954.56471596, ACU_loss:3818.25886384, Val_loss:1484.45237547)\n",
      "epoch (189 / 2000) (Train_loss:944.60432428, ACU_loss:3778.41729711, Val_loss:1471.79993355)\n",
      "epoch (190 / 2000) (Train_loss:934.73388964, ACU_loss:3738.93555854, Val_loss:1459.24647295)\n",
      "epoch (191 / 2000) (Train_loss:924.95281954, ACU_loss:3699.81127816, Val_loss:1446.79139761)\n",
      "epoch (192 / 2000) (Train_loss:915.26052404, ACU_loss:3661.04209617, Val_loss:1434.43411405)\n",
      "epoch (193 / 2000) (Train_loss:905.65641573, ACU_loss:3622.62566293, Val_loss:1422.17403136)\n",
      "epoch (194 / 2000) (Train_loss:896.13990971, ACU_loss:3584.55963882, Val_loss:1410.01056113)\n",
      "epoch (195 / 2000) (Train_loss:886.71042356, ACU_loss:3546.84169422, Val_loss:1397.94311752)\n",
      "epoch (196 / 2000) (Train_loss:877.36737734, ACU_loss:3509.46950936, Val_loss:1385.97111713)\n",
      "epoch (197 / 2000) (Train_loss:868.11019358, ACU_loss:3472.44077432, Val_loss:1374.09397906)\n",
      "epoch (198 / 2000) (Train_loss:858.93829722, ACU_loss:3435.75318888, Val_loss:1362.31112486)\n",
      "epoch (199 / 2000) (Train_loss:849.85111564, ACU_loss:3399.40446254, Val_loss:1350.62197848)\n",
      "epoch (200 / 2000) (Train_loss:840.84807860, ACU_loss:3363.39231438, Val_loss:1339.02596631)\n",
      "epoch (201 / 2000) (Train_loss:831.92861826, ACU_loss:3327.71447303, Val_loss:1327.52251712)\n",
      "epoch (202 / 2000) (Train_loss:823.09216915, ACU_loss:3292.36867661, Val_loss:1316.11106205)\n",
      "epoch (203 / 2000) (Train_loss:814.33816816, ACU_loss:3257.35267264, Val_loss:1304.79103461)\n",
      "epoch (204 / 2000) (Train_loss:805.66605451, ACU_loss:3222.66421805, Val_loss:1293.56187064)\n",
      "epoch (205 / 2000) (Train_loss:797.07526976, ACU_loss:3188.30107904, Val_loss:1282.42300830)\n",
      "epoch (206 / 2000) (Train_loss:788.56525778, ACU_loss:3154.26103111, Val_loss:1271.37388806)\n",
      "epoch (207 / 2000) (Train_loss:780.13546474, ACU_loss:3120.54185894, Val_loss:1260.41395268)\n",
      "epoch (208 / 2000) (Train_loss:771.78533910, ACU_loss:3087.14135640, Val_loss:1249.54264722)\n",
      "epoch (209 / 2000) (Train_loss:763.51433162, ACU_loss:3054.05732647, Val_loss:1238.75941897)\n",
      "epoch (210 / 2000) (Train_loss:755.32189530, ACU_loss:3021.28758119, Val_loss:1228.06371750)\n",
      "epoch (211 / 2000) (Train_loss:747.20748541, ACU_loss:2988.82994164, Val_loss:1217.45499461)\n",
      "epoch (212 / 2000) (Train_loss:739.17055948, ACU_loss:2956.68223790, Val_loss:1206.93270432)\n",
      "epoch (213 / 2000) (Train_loss:731.21057725, ACU_loss:2924.84230900, Val_loss:1196.49630288)\n",
      "epoch (214 / 2000) (Train_loss:723.32700072, ACU_loss:2893.30800287, Val_loss:1186.14524872)\n",
      "epoch (215 / 2000) (Train_loss:715.51929408, ACU_loss:2862.07717633, Val_loss:1175.87900248)\n",
      "epoch (216 / 2000) (Train_loss:707.78692376, ACU_loss:2831.14769504, Val_loss:1165.69702697)\n",
      "epoch (217 / 2000) (Train_loss:700.12935837, ACU_loss:2800.51743349, Val_loss:1155.59878719)\n",
      "epoch (218 / 2000) (Train_loss:692.54606873, ACU_loss:2770.18427493, Val_loss:1145.58375027)\n",
      "epoch (219 / 2000) (Train_loss:685.03652784, ACU_loss:2740.14611135, Val_loss:1135.65138553)\n",
      "epoch (220 / 2000) (Train_loss:677.60021088, ACU_loss:2710.40084350, Val_loss:1125.80116441)\n",
      "epoch (221 / 2000) (Train_loss:670.23659520, ACU_loss:2680.94638079, Val_loss:1116.03256048)\n",
      "epoch (222 / 2000) (Train_loss:662.94516033, ACU_loss:2651.78064132, Val_loss:1106.34504944)\n",
      "epoch (223 / 2000) (Train_loss:655.72538795, ACU_loss:2622.90155182, Val_loss:1096.73810911)\n",
      "epoch (224 / 2000) (Train_loss:648.57676191, ACU_loss:2594.30704763, Val_loss:1087.21121944)\n",
      "epoch (225 / 2000) (Train_loss:641.49876818, ACU_loss:2565.99507273, Val_loss:1077.76386244)\n",
      "epoch (226 / 2000) (Train_loss:634.49089491, ACU_loss:2537.96357963, Val_loss:1068.39552224)\n",
      "epoch (227 / 2000) (Train_loss:627.55263235, ACU_loss:2510.21052941, Val_loss:1059.10568507)\n",
      "epoch (228 / 2000) (Train_loss:620.68347292, ACU_loss:2482.73389169, Val_loss:1049.89383921)\n",
      "epoch (229 / 2000) (Train_loss:613.88291115, ACU_loss:2455.53164460, Val_loss:1040.75947505)\n",
      "epoch (230 / 2000) (Train_loss:607.15044370, ACU_loss:2428.60177478, Val_loss:1031.70208503)\n",
      "epoch (231 / 2000) (Train_loss:600.48556934, ACU_loss:2401.94227734, Val_loss:1022.72116364)\n",
      "epoch (232 / 2000) (Train_loss:593.88778897, ACU_loss:2375.55115587, Val_loss:1013.81620746)\n",
      "epoch (233 / 2000) (Train_loss:587.35660560, ACU_loss:2349.42642238, Val_loss:1004.98671510)\n",
      "epoch (234 / 2000) (Train_loss:580.89152434, ACU_loss:2323.56609736, Val_loss:996.23218723)\n",
      "epoch (235 / 2000) (Train_loss:574.49205243, ACU_loss:2297.96820970, Val_loss:987.55212655)\n",
      "epoch (236 / 2000) (Train_loss:568.15769917, ACU_loss:2272.63079670, Val_loss:978.94603780)\n",
      "epoch (237 / 2000) (Train_loss:561.88797601, ACU_loss:2247.55190406, Val_loss:970.41342777)\n",
      "epoch (238 / 2000) (Train_loss:555.68239647, ACU_loss:2222.72958587, Val_loss:961.95380525)\n",
      "epoch (239 / 2000) (Train_loss:549.54047615, ACU_loss:2198.16190460, Val_loss:953.56668109)\n",
      "epoch (240 / 2000) (Train_loss:543.46173277, ACU_loss:2173.84693108, Val_loss:945.25156813)\n",
      "epoch (241 / 2000) (Train_loss:537.44568612, ACU_loss:2149.78274450, Val_loss:937.00798125)\n",
      "epoch (242 / 2000) (Train_loss:531.49185810, ACU_loss:2125.96743240, Val_loss:928.83543732)\n",
      "epoch (243 / 2000) (Train_loss:525.59977267, ACU_loss:2102.39909067, Val_loss:920.73345525)\n",
      "epoch (244 / 2000) (Train_loss:519.76895588, ACU_loss:2079.07582351, Val_loss:912.70155592)\n",
      "epoch (245 / 2000) (Train_loss:513.99893586, ACU_loss:2055.99574346, Val_loss:904.73926225)\n",
      "epoch (246 / 2000) (Train_loss:508.28924284, ACU_loss:2033.15697137, Val_loss:896.84609914)\n",
      "epoch (247 / 2000) (Train_loss:502.63940911, ACU_loss:2010.55763643, Val_loss:889.02159350)\n",
      "epoch (248 / 2000) (Train_loss:497.04896903, ACU_loss:1988.19587610, Val_loss:881.26527422)\n",
      "epoch (249 / 2000) (Train_loss:491.51745904, ACU_loss:1966.06983616, Val_loss:873.57667219)\n",
      "epoch (250 / 2000) (Train_loss:486.04441767, ACU_loss:1944.17767070, Val_loss:865.95532030)\n",
      "epoch (251 / 2000) (Train_loss:480.62938552, ACU_loss:1922.51754206, Val_loss:858.40075341)\n",
      "epoch (252 / 2000) (Train_loss:475.27190523, ACU_loss:1901.08762092, Val_loss:850.91250839)\n",
      "epoch (253 / 2000) (Train_loss:469.97152155, ACU_loss:1879.88608621, Val_loss:843.49012406)\n",
      "epoch (254 / 2000) (Train_loss:464.72778129, ACU_loss:1858.91112515, Val_loss:836.13314125)\n",
      "epoch (255 / 2000) (Train_loss:459.54023331, ACU_loss:1838.16093325, Val_loss:828.84110276)\n",
      "epoch (256 / 2000) (Train_loss:454.40842857, ACU_loss:1817.63371428, Val_loss:821.61355337)\n",
      "epoch (257 / 2000) (Train_loss:449.33192007, ACU_loss:1797.32768029, Val_loss:814.45003983)\n",
      "epoch (258 / 2000) (Train_loss:444.31026290, ACU_loss:1777.24105159, Val_loss:807.35011087)\n",
      "epoch (259 / 2000) (Train_loss:439.34301420, ACU_loss:1757.37205679, Val_loss:800.31331720)\n",
      "epoch (260 / 2000) (Train_loss:434.42973318, ACU_loss:1737.71893273, Val_loss:793.33921147)\n",
      "epoch (261 / 2000) (Train_loss:429.56998113, ACU_loss:1718.27992454, Val_loss:786.42734835)\n",
      "epoch (262 / 2000) (Train_loss:424.76332140, ACU_loss:1699.05328560, Val_loss:779.57728443)\n",
      "epoch (263 / 2000) (Train_loss:420.00931939, ACU_loss:1680.03727757, Val_loss:772.78857830)\n",
      "epoch (264 / 2000) (Train_loss:415.30754259, ACU_loss:1661.23017036, Val_loss:766.06079050)\n",
      "epoch (265 / 2000) (Train_loss:410.65756054, ACU_loss:1642.63024215, Val_loss:759.39348355)\n",
      "epoch (266 / 2000) (Train_loss:406.05894485, ACU_loss:1624.23577938, Val_loss:752.78622192)\n",
      "epoch (267 / 2000) (Train_loss:401.51126919, ACU_loss:1606.04507675, Val_loss:746.23857204)\n",
      "epoch (268 / 2000) (Train_loss:397.01410931, ACU_loss:1588.05643722, Val_loss:739.75010232)\n",
      "epoch (269 / 2000) (Train_loss:392.56704300, ACU_loss:1570.26817202, Val_loss:733.32038311)\n",
      "epoch (270 / 2000) (Train_loss:388.16965016, ACU_loss:1552.67860063, Val_loss:726.94898673)\n",
      "epoch (271 / 2000) (Train_loss:383.82151270, ACU_loss:1535.28605080, Val_loss:720.63548747)\n",
      "epoch (272 / 2000) (Train_loss:379.52221463, ACU_loss:1518.08885853, Val_loss:714.37946157)\n",
      "epoch (273 / 2000) (Train_loss:375.27134203, ACU_loss:1501.08536811, Val_loss:708.18048721)\n",
      "epoch (274 / 2000) (Train_loss:371.06848301, ACU_loss:1484.27393205, Val_loss:702.03814455)\n",
      "epoch (275 / 2000) (Train_loss:366.91322779, ACU_loss:1467.65291117, Val_loss:695.95201570)\n",
      "epoch (276 / 2000) (Train_loss:362.80516863, ACU_loss:1451.22067452, Val_loss:689.92168473)\n",
      "epoch (277 / 2000) (Train_loss:358.74389985, ACU_loss:1434.97559942, Val_loss:683.94673764)\n",
      "epoch (278 / 2000) (Train_loss:354.72901786, ACU_loss:1418.91607146, Val_loss:678.02676242)\n",
      "epoch (279 / 2000) (Train_loss:350.76012112, ACU_loss:1403.04048449, Val_loss:672.16134899)\n",
      "epoch (280 / 2000) (Train_loss:346.83681016, ACU_loss:1387.34724064, Val_loss:666.35008922)\n",
      "epoch (281 / 2000) (Train_loss:342.95868757, ACU_loss:1371.83475028, Val_loss:660.59257695)\n",
      "epoch (282 / 2000) (Train_loss:339.12535802, ACU_loss:1356.50143206, Val_loss:654.88840797)\n",
      "epoch (283 / 2000) (Train_loss:335.33642823, ACU_loss:1341.34571291, Val_loss:649.23717999)\n",
      "epoch (284 / 2000) (Train_loss:331.59150700, ACU_loss:1326.36602800, Val_loss:643.63849271)\n",
      "epoch (285 / 2000) (Train_loss:327.89020519, ACU_loss:1311.56082078, Val_loss:638.09194776)\n",
      "epoch (286 / 2000) (Train_loss:324.23213574, ACU_loss:1296.92854297, Val_loss:632.59714872)\n",
      "epoch (287 / 2000) (Train_loss:320.61691364, ACU_loss:1282.46765456, Val_loss:627.15370111)\n",
      "epoch (288 / 2000) (Train_loss:317.04415595, ACU_loss:1268.17662379, Val_loss:621.76121242)\n",
      "epoch (289 / 2000) (Train_loss:313.51348180, ACU_loss:1254.05392720, Val_loss:616.41929207)\n",
      "epoch (290 / 2000) (Train_loss:310.02451239, ACU_loss:1240.09804955, Val_loss:611.12755143)\n",
      "epoch (291 / 2000) (Train_loss:306.57687098, ACU_loss:1226.30748391, Val_loss:605.88560382)\n",
      "epoch (292 / 2000) (Train_loss:303.17018290, ACU_loss:1212.68073160, Val_loss:600.69306450)\n",
      "epoch (293 / 2000) (Train_loss:299.80407555, ACU_loss:1199.21630221, Val_loss:595.54955067)\n",
      "epoch (294 / 2000) (Train_loss:296.47817840, ACU_loss:1185.91271358, Val_loss:590.45468148)\n",
      "epoch (295 / 2000) (Train_loss:293.19212296, ACU_loss:1172.76849184, Val_loss:585.40807803)\n",
      "epoch (296 / 2000) (Train_loss:289.94554284, ACU_loss:1159.78217137, Val_loss:580.40936335)\n",
      "epoch (297 / 2000) (Train_loss:286.73807370, ACU_loss:1146.95229480, Val_loss:575.45816242)\n",
      "epoch (298 / 2000) (Train_loss:283.56935326, ACU_loss:1134.27741306, Val_loss:570.55410215)\n",
      "epoch (299 / 2000) (Train_loss:280.43902132, ACU_loss:1121.75608530, Val_loss:565.69681139)\n",
      "epoch (300 / 2000) (Train_loss:277.34671974, ACU_loss:1109.38687895, Val_loss:560.88592096)\n",
      "epoch (301 / 2000) (Train_loss:274.29209242, ACU_loss:1097.16836969, Val_loss:556.12106357)\n",
      "epoch (302 / 2000) (Train_loss:271.27478537, ACU_loss:1085.09914146, Val_loss:551.40187390)\n",
      "epoch (303 / 2000) (Train_loss:268.29444661, ACU_loss:1073.17778646, Val_loss:546.72798855)\n",
      "epoch (304 / 2000) (Train_loss:265.35072628, ACU_loss:1061.40290512, Val_loss:542.09904607)\n",
      "epoch (305 / 2000) (Train_loss:262.44327653, ACU_loss:1049.77310613, Val_loss:537.51468694)\n",
      "epoch (306 / 2000) (Train_loss:259.57175161, ACU_loss:1038.28700643, Val_loss:532.97455355)\n",
      "epoch (307 / 2000) (Train_loss:256.73580780, ACU_loss:1026.94323120, Val_loss:528.47829026)\n",
      "epoch (308 / 2000) (Train_loss:253.93510346, ACU_loss:1015.74041385, Val_loss:524.02554334)\n",
      "epoch (309 / 2000) (Train_loss:251.16929901, ACU_loss:1004.67719603, Val_loss:519.61596098)\n",
      "epoch (310 / 2000) (Train_loss:248.43805691, ACU_loss:993.75222764, Val_loss:515.24919332)\n",
      "epoch (311 / 2000) (Train_loss:245.74104170, ACU_loss:982.96416678, Val_loss:510.92489242)\n",
      "epoch (312 / 2000) (Train_loss:243.07791995, ACU_loss:972.31167979, Val_loss:506.64271226)\n",
      "epoch (313 / 2000) (Train_loss:240.44836031, ACU_loss:961.79344124, Val_loss:502.40230874)\n",
      "epoch (314 / 2000) (Train_loss:237.85203347, ACU_loss:951.40813388, Val_loss:498.20333970)\n",
      "epoch (315 / 2000) (Train_loss:235.28861218, ACU_loss:941.15444871, Val_loss:494.04546489)\n",
      "epoch (316 / 2000) (Train_loss:232.75777123, ACU_loss:931.03108490, Val_loss:489.92834599)\n",
      "epoch (317 / 2000) (Train_loss:230.25918747, ACU_loss:921.03674986, Val_loss:485.85164658)\n",
      "epoch (318 / 2000) (Train_loss:227.79253979, ACU_loss:911.17015916, Val_loss:481.81503218)\n",
      "epoch (319 / 2000) (Train_loss:225.35750914, ACU_loss:901.43003656, Val_loss:477.81817020)\n",
      "epoch (320 / 2000) (Train_loss:222.95377850, ACU_loss:891.81511402, Val_loss:473.86072999)\n",
      "epoch (321 / 2000) (Train_loss:220.58103292, ACU_loss:882.32413166, Val_loss:469.94238279)\n",
      "epoch (322 / 2000) (Train_loss:218.23895944, ACU_loss:872.95583778, Val_loss:466.06280177)\n",
      "epoch (323 / 2000) (Train_loss:215.92724721, ACU_loss:863.70898882, Val_loss:462.22166199)\n",
      "epoch (324 / 2000) (Train_loss:213.64558735, ACU_loss:854.58234941, Val_loss:458.41864042)\n",
      "epoch (325 / 2000) (Train_loss:211.39367307, ACU_loss:845.57469228, Val_loss:454.65341594)\n",
      "epoch (326 / 2000) (Train_loss:209.17119958, ACU_loss:836.68479832, Val_loss:450.92566933)\n",
      "epoch (327 / 2000) (Train_loss:206.97786414, ACU_loss:827.91145657, Val_loss:447.23508328)\n",
      "epoch (328 / 2000) (Train_loss:204.81336604, ACU_loss:819.25346415, Val_loss:443.58134235)\n",
      "epoch (329 / 2000) (Train_loss:202.67740658, ACU_loss:810.70962632, Val_loss:439.96413302)\n",
      "epoch (330 / 2000) (Train_loss:200.56968911, ACU_loss:802.27875643, Val_loss:436.38314366)\n",
      "epoch (331 / 2000) (Train_loss:198.48991898, ACU_loss:793.95967593, Val_loss:432.83806452)\n",
      "epoch (332 / 2000) (Train_loss:196.43780358, ACU_loss:785.75121433, Val_loss:429.32858774)\n",
      "epoch (333 / 2000) (Train_loss:194.41305231, ACU_loss:777.65220925, Val_loss:425.85440736)\n",
      "epoch (334 / 2000) (Train_loss:192.41537659, ACU_loss:769.66150635, Val_loss:422.41521928)\n",
      "epoch (335 / 2000) (Train_loss:190.44448983, ACU_loss:761.77795933, Val_loss:419.01072131)\n",
      "epoch (336 / 2000) (Train_loss:188.50010749, ACU_loss:754.00042994, Val_loss:415.64061311)\n",
      "epoch (337 / 2000) (Train_loss:186.58194699, ACU_loss:746.32778797, Val_loss:412.30459623)\n",
      "epoch (338 / 2000) (Train_loss:184.68972780, ACU_loss:738.75891121, Val_loss:409.00237409)\n",
      "epoch (339 / 2000) (Train_loss:182.82317136, ACU_loss:731.29268545, Val_loss:405.73365197)\n",
      "epoch (340 / 2000) (Train_loss:180.98200112, ACU_loss:723.92800448, Val_loss:402.49813704)\n",
      "epoch (341 / 2000) (Train_loss:179.16594251, ACU_loss:716.66377006, Val_loss:399.29553830)\n",
      "epoch (342 / 2000) (Train_loss:177.37472298, ACU_loss:709.49889193, Val_loss:396.12556663)\n",
      "epoch (343 / 2000) (Train_loss:175.60807194, ACU_loss:702.43228776, Val_loss:392.98793477)\n",
      "epoch (344 / 2000) (Train_loss:173.86572079, ACU_loss:695.46288317, Val_loss:389.88235730)\n",
      "epoch (345 / 2000) (Train_loss:172.14740292, ACU_loss:688.58961170, Val_loss:386.80855066)\n",
      "epoch (346 / 2000) (Train_loss:170.45285370, ACU_loss:681.81141479, Val_loss:383.76623313)\n",
      "epoch (347 / 2000) (Train_loss:168.78181044, ACU_loss:675.12724177, Val_loss:380.75512485)\n",
      "epoch (348 / 2000) (Train_loss:167.13401247, ACU_loss:668.53604987, Val_loss:377.77494777)\n",
      "epoch (349 / 2000) (Train_loss:165.50920104, ACU_loss:662.03680416, Val_loss:374.82542570)\n",
      "epoch (350 / 2000) (Train_loss:163.90711939, ACU_loss:655.62847756, Val_loss:371.90628428)\n",
      "epoch (351 / 2000) (Train_loss:162.32751270, ACU_loss:649.31005080, Val_loss:369.01725097)\n",
      "epoch (352 / 2000) (Train_loss:160.77012812, ACU_loss:643.08051247, Val_loss:366.15805505)\n",
      "epoch (353 / 2000) (Train_loss:159.23471472, ACU_loss:636.93885890, Val_loss:363.32842764)\n",
      "epoch (354 / 2000) (Train_loss:157.72102356, ACU_loss:630.88409423, Val_loss:360.52810167)\n",
      "epoch (355 / 2000) (Train_loss:156.22880759, ACU_loss:624.91523035, Val_loss:357.75681186)\n",
      "epoch (356 / 2000) (Train_loss:154.75782172, ACU_loss:619.03128689, Val_loss:355.01429477)\n",
      "epoch (357 / 2000) (Train_loss:153.30782280, ACU_loss:613.23129119, Val_loss:352.30028876)\n",
      "epoch (358 / 2000) (Train_loss:151.87856958, ACU_loss:607.51427832, Val_loss:349.61453396)\n",
      "epoch (359 / 2000) (Train_loss:150.46982275, ACU_loss:601.87929102, Val_loss:346.95677233)\n",
      "epoch (360 / 2000) (Train_loss:149.08134492, ACU_loss:596.32537968, Val_loss:344.32674761)\n",
      "epoch (361 / 2000) (Train_loss:147.71290059, ACU_loss:590.85160236, Val_loss:341.72420532)\n",
      "epoch (362 / 2000) (Train_loss:146.36425618, ACU_loss:585.45702471, Val_loss:339.14889278)\n",
      "epoch (363 / 2000) (Train_loss:145.03518001, ACU_loss:580.14072003, Val_loss:336.60055906)\n",
      "epoch (364 / 2000) (Train_loss:143.72544229, ACU_loss:574.90176916, Val_loss:334.07895502)\n",
      "epoch (365 / 2000) (Train_loss:142.43481513, ACU_loss:569.73926051, Val_loss:331.58383329)\n",
      "epoch (366 / 2000) (Train_loss:141.16307251, ACU_loss:564.65229005, Val_loss:329.11494827)\n",
      "epoch (367 / 2000) (Train_loss:139.90999031, ACU_loss:559.63996124, Val_loss:326.67205609)\n",
      "epoch (368 / 2000) (Train_loss:138.67534626, ACU_loss:554.70138504, Val_loss:324.25491466)\n",
      "epoch (369 / 2000) (Train_loss:137.45891998, ACU_loss:549.83567991, Val_loss:321.86328363)\n",
      "epoch (370 / 2000) (Train_loss:136.26049293, ACU_loss:545.04197171, Val_loss:319.49692439)\n",
      "epoch (371 / 2000) (Train_loss:135.07984844, ACU_loss:540.31939377, Val_loss:317.15560007)\n",
      "epoch (372 / 2000) (Train_loss:133.91677170, ACU_loss:535.66708678, Val_loss:314.83907554)\n",
      "epoch (373 / 2000) (Train_loss:132.77104971, ACU_loss:531.08419885, Val_loss:312.54711739)\n",
      "epoch (374 / 2000) (Train_loss:131.64247135, ACU_loss:526.56988540, Val_loss:310.27949392)\n",
      "epoch (375 / 2000) (Train_loss:130.53082730, ACU_loss:522.12330921, Val_loss:308.03597517)\n",
      "epoch (376 / 2000) (Train_loss:129.43591009, ACU_loss:517.74364035, Val_loss:305.81633288)\n",
      "epoch (377 / 2000) (Train_loss:128.35751404, ACU_loss:513.43005617, Val_loss:303.62034048)\n",
      "epoch (378 / 2000) (Train_loss:127.29543532, ACU_loss:509.18174126, Val_loss:301.44777314)\n",
      "epoch (379 / 2000) (Train_loss:126.24947186, ACU_loss:504.99788746, Val_loss:299.29840768)\n",
      "epoch (380 / 2000) (Train_loss:125.21942344, ACU_loss:500.87769378, Val_loss:297.17202262)\n",
      "epoch (381 / 2000) (Train_loss:124.20509160, ACU_loss:496.82036641, Val_loss:295.06839819)\n",
      "epoch (382 / 2000) (Train_loss:123.20627968, ACU_loss:492.82511871, Val_loss:292.98731626)\n",
      "epoch (383 / 2000) (Train_loss:122.22279278, ACU_loss:488.89117113, Val_loss:290.92856039)\n",
      "epoch (384 / 2000) (Train_loss:121.25443780, ACU_loss:485.01775121, Val_loss:288.89191580)\n",
      "epoch (385 / 2000) (Train_loss:120.30102339, ACU_loss:481.20409357, Val_loss:286.87716936)\n",
      "epoch (386 / 2000) (Train_loss:119.36235996, ACU_loss:477.44943985, Val_loss:284.88410960)\n",
      "epoch (387 / 2000) (Train_loss:118.43825968, ACU_loss:473.75303871, Val_loss:282.91252670)\n",
      "epoch (388 / 2000) (Train_loss:117.52853644, ACU_loss:470.11414577, Val_loss:280.96221247)\n",
      "epoch (389 / 2000) (Train_loss:116.63300590, ACU_loss:466.53202360, Val_loss:279.03296036)\n",
      "epoch (390 / 2000) (Train_loss:115.75148542, ACU_loss:463.00594170, Val_loss:277.12456543)\n",
      "epoch (391 / 2000) (Train_loss:114.88379411, ACU_loss:459.53517644, Val_loss:275.23682439)\n",
      "epoch (392 / 2000) (Train_loss:114.02975277, ACU_loss:456.11901107, Val_loss:273.36953554)\n",
      "epoch (393 / 2000) (Train_loss:113.18918391, ACU_loss:452.75673564, Val_loss:271.52249879)\n",
      "epoch (394 / 2000) (Train_loss:112.36191176, ACU_loss:449.44764703, Val_loss:269.69551565)\n",
      "epoch (395 / 2000) (Train_loss:111.54776222, ACU_loss:446.19104887, Val_loss:267.88838923)\n",
      "epoch (396 / 2000) (Train_loss:110.74656288, ACU_loss:442.98625151, Val_loss:266.10092422)\n",
      "epoch (397 / 2000) (Train_loss:109.95814301, ACU_loss:439.83257203, Val_loss:264.33292690)\n",
      "epoch (398 / 2000) (Train_loss:109.18233354, ACU_loss:436.72933417, Val_loss:262.58420511)\n",
      "epoch (399 / 2000) (Train_loss:108.41896708, ACU_loss:433.67586832, Val_loss:260.85456826)\n",
      "epoch (400 / 2000) (Train_loss:107.66787787, ACU_loss:430.67151146, Val_loss:259.14382733)\n",
      "epoch (401 / 2000) (Train_loss:106.92890179, ACU_loss:427.71560716, Val_loss:257.45179483)\n",
      "epoch (402 / 2000) (Train_loss:106.20187638, ACU_loss:424.80750554, Val_loss:255.77828483)\n",
      "epoch (403 / 2000) (Train_loss:105.48664080, ACU_loss:421.94656321, Val_loss:254.12311294)\n",
      "epoch (404 / 2000) (Train_loss:104.78303582, ACU_loss:419.13214327, Val_loss:252.48609630)\n",
      "epoch (405 / 2000) (Train_loss:104.09090382, ACU_loss:416.36361527, Val_loss:250.86705356)\n",
      "epoch (406 / 2000) (Train_loss:103.41008879, ACU_loss:413.64035515, Val_loss:249.26580489)\n",
      "epoch (407 / 2000) (Train_loss:102.74043631, ACU_loss:410.96174526, Val_loss:247.68217198)\n",
      "epoch (408 / 2000) (Train_loss:102.08179356, ACU_loss:408.32717426, Val_loss:246.11597803)\n",
      "epoch (409 / 2000) (Train_loss:101.43400928, ACU_loss:405.73603713, Val_loss:244.56704769)\n",
      "epoch (410 / 2000) (Train_loss:100.79693378, ACU_loss:403.18773513, Val_loss:243.03520715)\n",
      "epoch (411 / 2000) (Train_loss:100.17041894, ACU_loss:400.68167576, Val_loss:241.52028404)\n",
      "epoch (412 / 2000) (Train_loss:99.55431818, ACU_loss:398.21727271, Val_loss:240.02210748)\n",
      "epoch (413 / 2000) (Train_loss:98.94848647, ACU_loss:395.79394586, Val_loss:238.54050806)\n",
      "epoch (414 / 2000) (Train_loss:98.35278030, ACU_loss:393.41112121, Val_loss:237.07531780)\n",
      "epoch (415 / 2000) (Train_loss:97.76705772, ACU_loss:391.06823087, Val_loss:235.62637020)\n",
      "epoch (416 / 2000) (Train_loss:97.19117825, ACU_loss:388.76471300, Val_loss:234.19350017)\n",
      "epoch (417 / 2000) (Train_loss:96.62500295, ACU_loss:386.50001180, Val_loss:232.77654409)\n",
      "epoch (418 / 2000) (Train_loss:96.06839436, ACU_loss:384.27357745, Val_loss:231.37533972)\n",
      "epoch (419 / 2000) (Train_loss:95.52121652, ACU_loss:382.08486610, Val_loss:229.98972629)\n",
      "epoch (420 / 2000) (Train_loss:94.98333495, ACU_loss:379.93333981, Val_loss:228.61954439)\n",
      "epoch (421 / 2000) (Train_loss:94.45461663, ACU_loss:377.81846652, Val_loss:227.26463604)\n",
      "epoch (422 / 2000) (Train_loss:93.93493001, ACU_loss:375.73972004, Val_loss:225.92484466)\n",
      "epoch (423 / 2000) (Train_loss:93.42414499, ACU_loss:373.69657995, Val_loss:224.60001503)\n",
      "epoch (424 / 2000) (Train_loss:92.92213291, ACU_loss:371.68853164, Val_loss:223.28999333)\n",
      "epoch (425 / 2000) (Train_loss:92.42876655, ACU_loss:369.71506622, Val_loss:221.99462711)\n",
      "epoch (426 / 2000) (Train_loss:91.94392012, ACU_loss:367.77568049, Val_loss:220.71376527)\n",
      "epoch (427 / 2000) (Train_loss:91.46746923, ACU_loss:365.86987693, Val_loss:219.44725806)\n",
      "epoch (428 / 2000) (Train_loss:90.99929091, ACU_loss:363.99716363, Val_loss:218.19495711)\n",
      "epoch (429 / 2000) (Train_loss:90.53926357, ACU_loss:362.15705428, Val_loss:216.95671535)\n",
      "epoch (430 / 2000) (Train_loss:90.08726702, ACU_loss:360.34906810, Val_loss:215.73238706)\n",
      "epoch (431 / 2000) (Train_loss:89.64318246, ACU_loss:358.57272984, Val_loss:214.52182784)\n",
      "epoch (432 / 2000) (Train_loss:89.20689243, ACU_loss:356.82756973, Val_loss:213.32489459)\n",
      "epoch (433 / 2000) (Train_loss:88.77828085, ACU_loss:355.11312340, Val_loss:212.14144554)\n",
      "epoch (434 / 2000) (Train_loss:88.35723298, ACU_loss:353.42893191, Val_loss:210.97134020)\n",
      "epoch (435 / 2000) (Train_loss:87.94363542, ACU_loss:351.77454166, Val_loss:209.81443937)\n",
      "epoch (436 / 2000) (Train_loss:87.53737610, ACU_loss:350.14950440, Val_loss:208.67060515)\n",
      "epoch (437 / 2000) (Train_loss:87.13834428, ACU_loss:348.55337713, Val_loss:207.53970089)\n",
      "epoch (438 / 2000) (Train_loss:86.74643053, ACU_loss:346.98572212, Val_loss:206.42159121)\n",
      "epoch (439 / 2000) (Train_loss:86.36152670, ACU_loss:345.44610682, Val_loss:205.31614200)\n",
      "epoch (440 / 2000) (Train_loss:85.98352597, ACU_loss:343.93410387, Val_loss:204.22322038)\n",
      "epoch (441 / 2000) (Train_loss:85.61232276, ACU_loss:342.44929104, Val_loss:203.14269472)\n",
      "epoch (442 / 2000) (Train_loss:85.24781279, ACU_loss:340.99125117, Val_loss:202.07443463)\n",
      "epoch (443 / 2000) (Train_loss:84.88989304, ACU_loss:339.55957218, Val_loss:201.01831092)\n",
      "epoch (444 / 2000) (Train_loss:84.53846174, ACU_loss:338.15384698, Val_loss:199.97419565)\n",
      "epoch (445 / 2000) (Train_loss:84.19341837, ACU_loss:336.77367346, Val_loss:198.94196205)\n",
      "epoch (446 / 2000) (Train_loss:83.85466362, ACU_loss:335.41865447, Val_loss:197.92148457)\n",
      "epoch (447 / 2000) (Train_loss:83.52209943, ACU_loss:334.08839772, Val_loss:196.91263885)\n",
      "epoch (448 / 2000) (Train_loss:83.19562895, ACU_loss:332.78251581, Val_loss:195.91530170)\n",
      "epoch (449 / 2000) (Train_loss:82.87515653, ACU_loss:331.50062613, Val_loss:194.92935113)\n",
      "epoch (450 / 2000) (Train_loss:82.56058772, ACU_loss:330.24235088, Val_loss:193.95466628)\n",
      "epoch (451 / 2000) (Train_loss:82.25182925, ACU_loss:329.00731699, Val_loss:192.99112748)\n",
      "epoch (452 / 2000) (Train_loss:81.94878902, ACU_loss:327.79515609, Val_loss:192.03861618)\n",
      "epoch (453 / 2000) (Train_loss:81.65137612, ACU_loss:326.60550448, Val_loss:191.09701499)\n",
      "epoch (454 / 2000) (Train_loss:81.35950077, ACU_loss:325.43800308, Val_loss:190.16620765)\n",
      "epoch (455 / 2000) (Train_loss:81.07307435, ACU_loss:324.29229740, Val_loss:189.24607902)\n",
      "epoch (456 / 2000) (Train_loss:80.79200938, ACU_loss:323.16803751, Val_loss:188.33651507)\n",
      "epoch (457 / 2000) (Train_loss:80.51621949, ACU_loss:322.06487797, Val_loss:187.43740290)\n",
      "epoch (458 / 2000) (Train_loss:80.24561946, ACU_loss:320.98247782, Val_loss:186.54863069)\n",
      "epoch (459 / 2000) (Train_loss:79.98012514, ACU_loss:319.92050054, Val_loss:185.67008770)\n",
      "epoch (460 / 2000) (Train_loss:79.71965350, ACU_loss:318.87861399, Val_loss:184.80166430)\n",
      "epoch (461 / 2000) (Train_loss:79.46412259, ACU_loss:317.85649038, Val_loss:183.94325193)\n",
      "epoch (462 / 2000) (Train_loss:79.21345156, ACU_loss:316.85380626, Val_loss:183.09474307)\n",
      "epoch (463 / 2000) (Train_loss:78.96756061, ACU_loss:315.87024244, Val_loss:182.25603130)\n",
      "epoch (464 / 2000) (Train_loss:78.72637099, ACU_loss:314.90548397, Val_loss:181.42701120)\n",
      "epoch (465 / 2000) (Train_loss:78.48980503, ACU_loss:313.95922010, Val_loss:180.60757844)\n",
      "epoch (466 / 2000) (Train_loss:78.25778607, ACU_loss:313.03114426, Val_loss:179.79762968)\n",
      "epoch (467 / 2000) (Train_loss:78.03023850, ACU_loss:312.12095399, Val_loss:178.99706265)\n",
      "epoch (468 / 2000) (Train_loss:77.80708773, ACU_loss:311.22835090, Val_loss:178.20577606)\n",
      "epoch (469 / 2000) (Train_loss:77.58826017, ACU_loss:310.35304068, Val_loss:177.42366965)\n",
      "epoch (470 / 2000) (Train_loss:77.37368325, ACU_loss:309.49473301, Val_loss:176.65064415)\n",
      "epoch (471 / 2000) (Train_loss:77.16328539, ACU_loss:308.65314155, Val_loss:175.88660129)\n",
      "epoch (472 / 2000) (Train_loss:76.95699597, ACU_loss:307.82798389, Val_loss:175.13144377)\n",
      "epoch (473 / 2000) (Train_loss:76.75474538, ACU_loss:307.01898150, Val_loss:174.38507530)\n",
      "epoch (474 / 2000) (Train_loss:76.55646494, ACU_loss:306.22585975, Val_loss:173.64740052)\n",
      "epoch (475 / 2000) (Train_loss:76.36208695, ACU_loss:305.44834779, Val_loss:172.91832505)\n",
      "epoch (476 / 2000) (Train_loss:76.17154464, ACU_loss:304.68617857, Val_loss:172.19775546)\n",
      "epoch (477 / 2000) (Train_loss:75.98477220, ACU_loss:303.93908878, Val_loss:171.48559927)\n",
      "epoch (478 / 2000) (Train_loss:75.80170471, ACU_loss:303.20681884, Val_loss:170.78176493)\n",
      "epoch (479 / 2000) (Train_loss:75.62227821, ACU_loss:302.48911282, Val_loss:170.08616181)\n",
      "epoch (480 / 2000) (Train_loss:75.44642961, ACU_loss:301.78571842, Val_loss:169.39870023)\n",
      "epoch (481 / 2000) (Train_loss:75.27409674, ACU_loss:301.09638696, Val_loss:168.71929139)\n",
      "epoch (482 / 2000) (Train_loss:75.10521832, ACU_loss:300.42087330, Val_loss:168.04784742)\n",
      "epoch (483 / 2000) (Train_loss:74.93973396, ACU_loss:299.75893583, Val_loss:167.38428132)\n",
      "epoch (484 / 2000) (Train_loss:74.77758411, ACU_loss:299.11033644, Val_loss:166.72850702)\n",
      "epoch (485 / 2000) (Train_loss:74.61871011, ACU_loss:298.47484045, Val_loss:166.08043929)\n",
      "epoch (486 / 2000) (Train_loss:74.46305415, ACU_loss:297.85221661, Val_loss:165.43999379)\n",
      "epoch (487 / 2000) (Train_loss:74.31055926, ACU_loss:297.24223705, Val_loss:164.80708707)\n",
      "epoch (488 / 2000) (Train_loss:74.16116931, ACU_loss:296.64467724, Val_loss:164.18163650)\n",
      "epoch (489 / 2000) (Train_loss:74.01482899, ACU_loss:296.05931595, Val_loss:163.56356033)\n",
      "epoch (490 / 2000) (Train_loss:73.87148381, ACU_loss:295.48593522, Val_loss:162.95277764)\n",
      "epoch (491 / 2000) (Train_loss:73.73108009, ACU_loss:294.92432034, Val_loss:162.34920834)\n",
      "epoch (492 / 2000) (Train_loss:73.59356495, ACU_loss:294.37425980, Val_loss:161.75277318)\n",
      "epoch (493 / 2000) (Train_loss:73.45888631, ACU_loss:293.83554524, Val_loss:161.16339374)\n",
      "epoch (494 / 2000) (Train_loss:73.32699286, ACU_loss:293.30797144, Val_loss:160.58099239)\n",
      "epoch (495 / 2000) (Train_loss:73.19783407, ACU_loss:292.79133628, Val_loss:160.00549232)\n",
      "epoch (496 / 2000) (Train_loss:73.07136017, ACU_loss:292.28544068, Val_loss:159.43681752)\n",
      "epoch (497 / 2000) (Train_loss:72.94752215, ACU_loss:291.79008862, Val_loss:158.87489277)\n",
      "epoch (498 / 2000) (Train_loss:72.82627176, ACU_loss:291.30508702, Val_loss:158.31964362)\n",
      "epoch (499 / 2000) (Train_loss:72.70756144, ACU_loss:290.83024576, Val_loss:157.77099642)\n",
      "epoch (500 / 2000) (Train_loss:72.59134431, ACU_loss:290.36537723, Val_loss:157.22887829)\n",
      "epoch (501 / 2000) (Train_loss:72.47757325, ACU_loss:289.91029301, Val_loss:156.69321728)\n",
      "epoch (502 / 2000) (Train_loss:72.36619549, ACU_loss:289.46478195, Val_loss:156.16394479)\n",
      "epoch (503 / 2000) (Train_loss:72.25710033, ACU_loss:289.02840133, Val_loss:155.64104139)\n",
      "epoch (504 / 2000) (Train_loss:72.14848920, ACU_loss:288.59395680, Val_loss:155.12781482)\n",
      "epoch (505 / 2000) (Train_loss:71.92875079, ACU_loss:287.71500314, Val_loss:155.17309519)\n",
      "epoch (506 / 2000) (Train_loss:71.95573864, ACU_loss:287.82295454, Val_loss:158.35830035)\n",
      "epoch (507 / 2000) (Train_loss:69.04896599, ACU_loss:276.19586394, Val_loss:154.35321670)\n",
      "epoch (508 / 2000) (Train_loss:69.71064843, ACU_loss:278.84259373, Val_loss:154.31448113)\n",
      "epoch (509 / 2000) (Train_loss:69.46851080, ACU_loss:277.87404322, Val_loss:155.77428736)\n",
      "epoch (510 / 2000) (Train_loss:67.58763003, ACU_loss:270.35052012, Val_loss:154.54006453)\n",
      "epoch (511 / 2000) (Train_loss:65.21424327, ACU_loss:260.85697306, Val_loss:154.22564472)\n",
      "epoch (512 / 2000) (Train_loss:62.38120626, ACU_loss:249.52482505, Val_loss:153.52552370)\n",
      "epoch (513 / 2000) (Train_loss:60.37434416, ACU_loss:241.49737664, Val_loss:152.89378630)\n",
      "epoch (514 / 2000) (Train_loss:58.18598462, ACU_loss:232.74393850, Val_loss:151.01224681)\n",
      "epoch (515 / 2000) (Train_loss:56.31017904, ACU_loss:225.24071617, Val_loss:150.00939538)\n",
      "epoch (516 / 2000) (Train_loss:54.93931531, ACU_loss:219.75726125, Val_loss:148.77126044)\n",
      "epoch (517 / 2000) (Train_loss:53.54936023, ACU_loss:214.19744090, Val_loss:147.50396662)\n",
      "epoch (518 / 2000) (Train_loss:52.68912548, ACU_loss:210.75650193, Val_loss:146.58351418)\n",
      "epoch (519 / 2000) (Train_loss:51.77926096, ACU_loss:207.11704383, Val_loss:145.40923496)\n",
      "epoch (520 / 2000) (Train_loss:51.16928347, ACU_loss:204.67713389, Val_loss:144.54022161)\n",
      "epoch (521 / 2000) (Train_loss:50.50130810, ACU_loss:202.00523241, Val_loss:143.43408297)\n",
      "epoch (522 / 2000) (Train_loss:50.05092302, ACU_loss:200.20369207, Val_loss:142.63613943)\n",
      "epoch (523 / 2000) (Train_loss:49.50358229, ACU_loss:198.01432918, Val_loss:141.59846828)\n",
      "epoch (524 / 2000) (Train_loss:49.08765496, ACU_loss:196.35061983, Val_loss:140.85503909)\n",
      "epoch (525 / 2000) (Train_loss:48.38318077, ACU_loss:193.53272309, Val_loss:140.90765957)\n",
      "epoch (526 / 2000) (Train_loss:47.27270100, ACU_loss:189.09080401, Val_loss:139.79785898)\n",
      "epoch (527 / 2000) (Train_loss:46.54999296, ACU_loss:186.19997182, Val_loss:138.58132060)\n",
      "epoch (528 / 2000) (Train_loss:46.06426167, ACU_loss:184.25704670, Val_loss:137.95731203)\n",
      "epoch (529 / 2000) (Train_loss:45.41853274, ACU_loss:181.67413095, Val_loss:136.99131041)\n",
      "epoch (530 / 2000) (Train_loss:44.84527812, ACU_loss:179.38111248, Val_loss:135.92291637)\n",
      "epoch (531 / 2000) (Train_loss:44.34480568, ACU_loss:177.37922274, Val_loss:134.94344308)\n",
      "epoch (532 / 2000) (Train_loss:43.90082591, ACU_loss:175.60330363, Val_loss:134.14237256)\n",
      "epoch (533 / 2000) (Train_loss:43.42058046, ACU_loss:173.68232185, Val_loss:133.19651610)\n",
      "epoch (534 / 2000) (Train_loss:43.00264274, ACU_loss:172.01057097, Val_loss:132.29597213)\n",
      "epoch (535 / 2000) (Train_loss:42.58415544, ACU_loss:170.33662174, Val_loss:131.36290018)\n",
      "epoch (536 / 2000) (Train_loss:42.21608878, ACU_loss:168.86435510, Val_loss:130.53967145)\n",
      "epoch (537 / 2000) (Train_loss:41.82609065, ACU_loss:167.30436260, Val_loss:129.66454938)\n",
      "epoch (538 / 2000) (Train_loss:41.47357463, ACU_loss:165.89429854, Val_loss:128.84082057)\n",
      "epoch (539 / 2000) (Train_loss:41.10628177, ACU_loss:164.42512707, Val_loss:127.97746682)\n",
      "epoch (540 / 2000) (Train_loss:40.74210675, ACU_loss:162.96842701, Val_loss:127.29074701)\n",
      "epoch (541 / 2000) (Train_loss:40.32334676, ACU_loss:161.29338703, Val_loss:126.96541240)\n",
      "epoch (542 / 2000) (Train_loss:39.57998709, ACU_loss:158.31994835, Val_loss:125.74704556)\n",
      "epoch (543 / 2000) (Train_loss:39.20867371, ACU_loss:156.83469482, Val_loss:124.95978788)\n",
      "epoch (544 / 2000) (Train_loss:38.75615545, ACU_loss:155.02462179, Val_loss:124.34306633)\n",
      "epoch (545 / 2000) (Train_loss:38.25410832, ACU_loss:153.01643327, Val_loss:123.36230275)\n",
      "epoch (546 / 2000) (Train_loss:37.82259419, ACU_loss:151.29037674, Val_loss:122.45685696)\n",
      "epoch (547 / 2000) (Train_loss:37.43959808, ACU_loss:149.75839233, Val_loss:121.66822257)\n",
      "epoch (548 / 2000) (Train_loss:37.05003646, ACU_loss:148.20014584, Val_loss:120.88663236)\n",
      "epoch (549 / 2000) (Train_loss:36.67329500, ACU_loss:146.69318000, Val_loss:120.04013419)\n",
      "epoch (550 / 2000) (Train_loss:36.31904535, ACU_loss:145.27618141, Val_loss:119.21371546)\n",
      "epoch (551 / 2000) (Train_loss:35.98528272, ACU_loss:143.94113089, Val_loss:118.43091406)\n",
      "epoch (552 / 2000) (Train_loss:35.65578697, ACU_loss:142.62314788, Val_loss:117.66206445)\n",
      "epoch (553 / 2000) (Train_loss:35.33549888, ACU_loss:141.34199553, Val_loss:116.88939397)\n",
      "epoch (554 / 2000) (Train_loss:35.02286426, ACU_loss:140.09145705, Val_loss:116.11635391)\n",
      "epoch (555 / 2000) (Train_loss:34.72033804, ACU_loss:138.88135216, Val_loss:115.35989233)\n",
      "epoch (556 / 2000) (Train_loss:34.42371529, ACU_loss:137.69486115, Val_loss:114.61673265)\n",
      "epoch (557 / 2000) (Train_loss:34.13286189, ACU_loss:136.53144754, Val_loss:113.88210125)\n",
      "epoch (558 / 2000) (Train_loss:33.84744135, ACU_loss:135.38976539, Val_loss:113.15108590)\n",
      "epoch (559 / 2000) (Train_loss:33.56734584, ACU_loss:134.26938336, Val_loss:112.42695147)\n",
      "epoch (560 / 2000) (Train_loss:33.29259784, ACU_loss:133.17039135, Val_loss:111.71191645)\n",
      "epoch (561 / 2000) (Train_loss:33.02221570, ACU_loss:132.08886280, Val_loss:111.00587182)\n",
      "epoch (562 / 2000) (Train_loss:32.75660588, ACU_loss:131.02642352, Val_loss:110.30687138)\n",
      "epoch (563 / 2000) (Train_loss:32.49500686, ACU_loss:129.98002743, Val_loss:109.61398450)\n",
      "epoch (564 / 2000) (Train_loss:32.23784450, ACU_loss:128.95137802, Val_loss:108.92778467)\n",
      "epoch (565 / 2000) (Train_loss:31.98436013, ACU_loss:127.93744054, Val_loss:108.24888654)\n",
      "epoch (566 / 2000) (Train_loss:31.73492514, ACU_loss:126.93970055, Val_loss:107.57716919)\n",
      "epoch (567 / 2000) (Train_loss:31.48905422, ACU_loss:125.95621686, Val_loss:106.91199149)\n",
      "epoch (568 / 2000) (Train_loss:31.24694576, ACU_loss:124.98778305, Val_loss:106.25299324)\n",
      "epoch (569 / 2000) (Train_loss:31.00818767, ACU_loss:124.03275068, Val_loss:105.60025264)\n",
      "epoch (570 / 2000) (Train_loss:30.77285413, ACU_loss:123.09141653, Val_loss:104.95391307)\n",
      "epoch (571 / 2000) (Train_loss:30.54073162, ACU_loss:122.16292648, Val_loss:104.31389122)\n",
      "epoch (572 / 2000) (Train_loss:30.31187029, ACU_loss:121.24748117, Val_loss:103.67992887)\n",
      "epoch (573 / 2000) (Train_loss:30.08607093, ACU_loss:120.34428374, Val_loss:103.05185811)\n",
      "epoch (574 / 2000) (Train_loss:29.86328515, ACU_loss:119.45314061, Val_loss:102.42968637)\n",
      "epoch (575 / 2000) (Train_loss:29.64265193, ACU_loss:118.57060774, Val_loss:101.81518675)\n",
      "epoch (576 / 2000) (Train_loss:29.38926695, ACU_loss:117.55706779, Val_loss:101.28822312)\n",
      "epoch (577 / 2000) (Train_loss:29.04286151, ACU_loss:116.17144604, Val_loss:101.17901017)\n",
      "epoch (578 / 2000) (Train_loss:28.50441355, ACU_loss:114.01765418, Val_loss:100.08459800)\n",
      "epoch (579 / 2000) (Train_loss:28.28287770, ACU_loss:113.13151079, Val_loss:99.51628532)\n",
      "epoch (580 / 2000) (Train_loss:27.98548227, ACU_loss:111.94192907, Val_loss:99.08325252)\n",
      "epoch (581 / 2000) (Train_loss:27.71687332, ACU_loss:110.86749326, Val_loss:98.28060898)\n",
      "epoch (582 / 2000) (Train_loss:27.41560090, ACU_loss:109.66240359, Val_loss:97.66533644)\n",
      "epoch (583 / 2000) (Train_loss:27.10075445, ACU_loss:108.40301782, Val_loss:97.10346404)\n",
      "epoch (584 / 2000) (Train_loss:26.83104821, ACU_loss:107.32419283, Val_loss:96.56409080)\n",
      "epoch (585 / 2000) (Train_loss:26.56747831, ACU_loss:106.26991322, Val_loss:95.81944510)\n",
      "epoch (586 / 2000) (Train_loss:26.26991994, ACU_loss:105.07967975, Val_loss:95.29595568)\n",
      "epoch (587 / 2000) (Train_loss:26.07610541, ACU_loss:104.30442162, Val_loss:94.63528312)\n",
      "epoch (588 / 2000) (Train_loss:25.73947737, ACU_loss:102.95790950, Val_loss:94.01033812)\n",
      "epoch (589 / 2000) (Train_loss:25.47483790, ACU_loss:101.89935162, Val_loss:93.46512738)\n",
      "epoch (590 / 2000) (Train_loss:25.27154794, ACU_loss:101.08619174, Val_loss:92.86694455)\n",
      "epoch (591 / 2000) (Train_loss:25.03697367, ACU_loss:100.14789466, Val_loss:92.26741009)\n",
      "epoch (592 / 2000) (Train_loss:24.79663219, ACU_loss:99.18652878, Val_loss:91.70062244)\n",
      "epoch (593 / 2000) (Train_loss:24.61128512, ACU_loss:98.44514046, Val_loss:91.11681464)\n",
      "epoch (594 / 2000) (Train_loss:24.38473243, ACU_loss:97.53892972, Val_loss:90.54899425)\n",
      "epoch (595 / 2000) (Train_loss:24.16514652, ACU_loss:96.66058610, Val_loss:89.99196675)\n",
      "epoch (596 / 2000) (Train_loss:23.97437804, ACU_loss:95.89751214, Val_loss:89.43248674)\n",
      "epoch (597 / 2000) (Train_loss:23.76529408, ACU_loss:95.06117633, Val_loss:88.87719193)\n",
      "epoch (598 / 2000) (Train_loss:23.56351997, ACU_loss:94.25407987, Val_loss:88.32739094)\n",
      "epoch (599 / 2000) (Train_loss:23.37178433, ACU_loss:93.48713733, Val_loss:87.78377830)\n",
      "epoch (600 / 2000) (Train_loss:23.17188424, ACU_loss:92.68753695, Val_loss:87.24458877)\n",
      "epoch (601 / 2000) (Train_loss:22.98335831, ACU_loss:91.93343324, Val_loss:86.71547943)\n",
      "epoch (602 / 2000) (Train_loss:22.78847468, ACU_loss:91.15389873, Val_loss:86.20680115)\n",
      "epoch (603 / 2000) (Train_loss:22.58858900, ACU_loss:90.35435601, Val_loss:85.70729218)\n",
      "epoch (604 / 2000) (Train_loss:22.38225043, ACU_loss:89.52900173, Val_loss:85.17025234)\n",
      "epoch (605 / 2000) (Train_loss:22.17158745, ACU_loss:88.68634982, Val_loss:84.64956707)\n",
      "epoch (606 / 2000) (Train_loss:21.99173392, ACU_loss:87.96693570, Val_loss:84.13779598)\n",
      "epoch (607 / 2000) (Train_loss:21.77726701, ACU_loss:87.10906804, Val_loss:83.61793453)\n",
      "epoch (608 / 2000) (Train_loss:21.60244069, ACU_loss:86.40976276, Val_loss:83.11233089)\n",
      "epoch (609 / 2000) (Train_loss:21.40344605, ACU_loss:85.61378419, Val_loss:82.59744065)\n",
      "epoch (610 / 2000) (Train_loss:21.21575663, ACU_loss:84.86302653, Val_loss:82.09335656)\n",
      "epoch (611 / 2000) (Train_loss:21.03094545, ACU_loss:84.12378178, Val_loss:81.60066018)\n",
      "epoch (612 / 2000) (Train_loss:20.85435403, ACU_loss:83.41741613, Val_loss:81.11157285)\n",
      "epoch (613 / 2000) (Train_loss:20.66618116, ACU_loss:82.66472466, Val_loss:80.61888387)\n",
      "epoch (614 / 2000) (Train_loss:20.49588115, ACU_loss:81.98352459, Val_loss:80.14222637)\n",
      "epoch (615 / 2000) (Train_loss:20.31653294, ACU_loss:81.26613178, Val_loss:79.65865780)\n",
      "epoch (616 / 2000) (Train_loss:20.14701158, ACU_loss:80.58804630, Val_loss:79.17841163)\n",
      "epoch (617 / 2000) (Train_loss:19.96796286, ACU_loss:79.87185143, Val_loss:78.69575660)\n",
      "epoch (618 / 2000) (Train_loss:19.80607645, ACU_loss:79.22430582, Val_loss:78.22709646)\n",
      "epoch (619 / 2000) (Train_loss:19.62974342, ACU_loss:78.51897366, Val_loss:77.74862517)\n",
      "epoch (620 / 2000) (Train_loss:19.46946308, ACU_loss:77.87785233, Val_loss:77.28487563)\n",
      "epoch (621 / 2000) (Train_loss:19.29705131, ACU_loss:77.18820525, Val_loss:76.81485260)\n",
      "epoch (622 / 2000) (Train_loss:19.14374076, ACU_loss:76.57496303, Val_loss:76.36167966)\n",
      "epoch (623 / 2000) (Train_loss:18.97305219, ACU_loss:75.89220875, Val_loss:75.89643955)\n",
      "epoch (624 / 2000) (Train_loss:18.82584068, ACU_loss:75.30336271, Val_loss:75.45413018)\n",
      "epoch (625 / 2000) (Train_loss:18.65970189, ACU_loss:74.63880758, Val_loss:74.99471209)\n",
      "epoch (626 / 2000) (Train_loss:18.51703641, ACU_loss:74.06814565, Val_loss:74.56023913)\n",
      "epoch (627 / 2000) (Train_loss:18.35243195, ACU_loss:73.40972780, Val_loss:74.10441122)\n",
      "epoch (628 / 2000) (Train_loss:18.21511919, ACU_loss:72.86047677, Val_loss:73.68160753)\n",
      "epoch (629 / 2000) (Train_loss:18.05273803, ACU_loss:72.21095210, Val_loss:73.22986452)\n",
      "epoch (630 / 2000) (Train_loss:17.91934582, ACU_loss:71.67738330, Val_loss:72.81870907)\n",
      "epoch (631 / 2000) (Train_loss:17.75948787, ACU_loss:71.03795146, Val_loss:72.37144360)\n",
      "epoch (632 / 2000) (Train_loss:17.63071967, ACU_loss:70.52287869, Val_loss:71.97152039)\n",
      "epoch (633 / 2000) (Train_loss:17.47202676, ACU_loss:69.88810704, Val_loss:71.52574173)\n",
      "epoch (634 / 2000) (Train_loss:17.34717046, ACU_loss:69.38868185, Val_loss:71.13701822)\n",
      "epoch (635 / 2000) (Train_loss:17.19153351, ACU_loss:68.76613403, Val_loss:70.69378067)\n",
      "epoch (636 / 2000) (Train_loss:17.06975996, ACU_loss:68.27903984, Val_loss:70.31466606)\n",
      "epoch (637 / 2000) (Train_loss:16.91664452, ACU_loss:67.66657808, Val_loss:69.87467711)\n",
      "epoch (638 / 2000) (Train_loss:16.79806826, ACU_loss:67.19227305, Val_loss:69.50576887)\n",
      "epoch (639 / 2000) (Train_loss:16.64832434, ACU_loss:66.59329735, Val_loss:69.06906456)\n",
      "epoch (640 / 2000) (Train_loss:16.53151896, ACU_loss:66.12607586, Val_loss:68.70829875)\n",
      "epoch (641 / 2000) (Train_loss:16.38560218, ACU_loss:65.54240872, Val_loss:68.27694043)\n",
      "epoch (642 / 2000) (Train_loss:16.27035674, ACU_loss:65.08142698, Val_loss:67.92291739)\n",
      "epoch (643 / 2000) (Train_loss:16.12841637, ACU_loss:64.51366547, Val_loss:67.49789686)\n",
      "epoch (644 / 2000) (Train_loss:16.01404946, ACU_loss:64.05619783, Val_loss:67.14890261)\n",
      "epoch (645 / 2000) (Train_loss:15.87668433, ACU_loss:63.50673731, Val_loss:66.73212324)\n",
      "epoch (646 / 2000) (Train_loss:15.76265687, ACU_loss:63.05062748, Val_loss:66.38587374)\n",
      "epoch (647 / 2000) (Train_loss:15.62990905, ACU_loss:62.51963621, Val_loss:65.97906856)\n",
      "epoch (648 / 2000) (Train_loss:15.51614326, ACU_loss:62.06457304, Val_loss:65.63410247)\n",
      "epoch (649 / 2000) (Train_loss:15.38806823, ACU_loss:61.55227291, Val_loss:65.23830409)\n",
      "epoch (650 / 2000) (Train_loss:15.27446249, ACU_loss:61.09784997, Val_loss:64.89358296)\n",
      "epoch (651 / 2000) (Train_loss:15.15087740, ACU_loss:60.60350961, Val_loss:64.50955063)\n",
      "epoch (652 / 2000) (Train_loss:15.03764789, ACU_loss:60.15059157, Val_loss:64.16464481)\n",
      "epoch (653 / 2000) (Train_loss:14.91810216, ACU_loss:59.67240865, Val_loss:63.79193533)\n",
      "epoch (654 / 2000) (Train_loss:14.80554173, ACU_loss:59.22216694, Val_loss:63.44721395)\n",
      "epoch (655 / 2000) (Train_loss:14.68955448, ACU_loss:58.75821792, Val_loss:63.08492250)\n",
      "epoch (656 / 2000) (Train_loss:14.57794121, ACU_loss:58.31176486, Val_loss:62.74116534)\n",
      "epoch (657 / 2000) (Train_loss:14.46494769, ACU_loss:57.85979076, Val_loss:62.38801047)\n",
      "epoch (658 / 2000) (Train_loss:14.35458722, ACU_loss:57.41834887, Val_loss:62.04638116)\n",
      "epoch (659 / 2000) (Train_loss:14.24402747, ACU_loss:56.97610987, Val_loss:61.70098786)\n",
      "epoch (660 / 2000) (Train_loss:14.13505573, ACU_loss:56.54022291, Val_loss:61.36260499)\n",
      "epoch (661 / 2000) (Train_loss:14.02655235, ACU_loss:56.10620940, Val_loss:61.02399970)\n",
      "epoch (662 / 2000) (Train_loss:13.91906552, ACU_loss:55.67626208, Val_loss:60.68996673)\n",
      "epoch (663 / 2000) (Train_loss:13.81232711, ACU_loss:55.24930844, Val_loss:60.35787870)\n",
      "epoch (664 / 2000) (Train_loss:13.70642891, ACU_loss:54.82571564, Val_loss:60.02966437)\n",
      "epoch (665 / 2000) (Train_loss:13.60128884, ACU_loss:54.40515536, Val_loss:59.70458632)\n",
      "epoch (666 / 2000) (Train_loss:13.49675779, ACU_loss:53.98703114, Val_loss:59.38317726)\n",
      "epoch (667 / 2000) (Train_loss:13.39278555, ACU_loss:53.57114222, Val_loss:59.06371763)\n",
      "epoch (668 / 2000) (Train_loss:13.28985574, ACU_loss:53.15942296, Val_loss:58.74551020)\n",
      "epoch (669 / 2000) (Train_loss:13.18791280, ACU_loss:52.75165122, Val_loss:58.42837499)\n",
      "epoch (670 / 2000) (Train_loss:13.08639453, ACU_loss:52.34557812, Val_loss:58.11243967)\n",
      "epoch (671 / 2000) (Train_loss:12.98434716, ACU_loss:51.93738862, Val_loss:57.79797435)\n",
      "epoch (672 / 2000) (Train_loss:12.88312267, ACU_loss:51.53249067, Val_loss:57.48707978)\n",
      "epoch (673 / 2000) (Train_loss:12.78357000, ACU_loss:51.13427999, Val_loss:57.17879940)\n",
      "epoch (674 / 2000) (Train_loss:12.68473815, ACU_loss:50.73895258, Val_loss:56.87109473)\n",
      "epoch (675 / 2000) (Train_loss:12.58564151, ACU_loss:50.34256603, Val_loss:56.56450828)\n",
      "epoch (676 / 2000) (Train_loss:12.48737806, ACU_loss:49.94951225, Val_loss:56.26037989)\n",
      "epoch (677 / 2000) (Train_loss:12.39153756, ACU_loss:49.56615024, Val_loss:55.95975794)\n",
      "epoch (678 / 2000) (Train_loss:12.29745121, ACU_loss:49.18980485, Val_loss:55.66061820)\n",
      "epoch (679 / 2000) (Train_loss:12.20370410, ACU_loss:48.81481639, Val_loss:55.36283155)\n",
      "epoch (680 / 2000) (Train_loss:12.10994754, ACU_loss:48.43979017, Val_loss:55.06650152)\n",
      "epoch (681 / 2000) (Train_loss:12.01761520, ACU_loss:48.07046079, Val_loss:54.77332246)\n",
      "epoch (682 / 2000) (Train_loss:11.92725907, ACU_loss:47.70903628, Val_loss:54.48245173)\n",
      "epoch (683 / 2000) (Train_loss:11.83837792, ACU_loss:47.35351169, Val_loss:54.19369003)\n",
      "epoch (684 / 2000) (Train_loss:11.74989164, ACU_loss:46.99956657, Val_loss:53.90608679)\n",
      "epoch (685 / 2000) (Train_loss:11.66189225, ACU_loss:46.64756901, Val_loss:53.62078991)\n",
      "epoch (686 / 2000) (Train_loss:11.57495559, ACU_loss:46.29982236, Val_loss:53.33776145)\n",
      "epoch (687 / 2000) (Train_loss:11.48962214, ACU_loss:45.95848854, Val_loss:53.05755148)\n",
      "epoch (688 / 2000) (Train_loss:11.40550511, ACU_loss:45.62202045, Val_loss:52.77910817)\n",
      "epoch (689 / 2000) (Train_loss:11.32222807, ACU_loss:45.28891228, Val_loss:52.50274413)\n",
      "epoch (690 / 2000) (Train_loss:11.23953065, ACU_loss:44.95812260, Val_loss:52.22805620)\n",
      "epoch (691 / 2000) (Train_loss:11.15779794, ACU_loss:44.63119178, Val_loss:51.95590920)\n",
      "epoch (692 / 2000) (Train_loss:11.07718136, ACU_loss:44.30872545, Val_loss:51.68583936)\n",
      "epoch (693 / 2000) (Train_loss:10.99776229, ACU_loss:43.99104916, Val_loss:51.41818067)\n",
      "epoch (694 / 2000) (Train_loss:10.91920473, ACU_loss:43.67681893, Val_loss:51.15223775)\n",
      "epoch (695 / 2000) (Train_loss:10.84144865, ACU_loss:43.36579459, Val_loss:50.88845372)\n",
      "epoch (696 / 2000) (Train_loss:10.76442507, ACU_loss:43.05770027, Val_loss:50.62651071)\n",
      "epoch (697 / 2000) (Train_loss:10.68835787, ACU_loss:42.75343148, Val_loss:50.36690465)\n",
      "epoch (698 / 2000) (Train_loss:10.61321924, ACU_loss:42.45287696, Val_loss:50.10924379)\n",
      "epoch (699 / 2000) (Train_loss:10.53903583, ACU_loss:42.15614331, Val_loss:49.85375564)\n",
      "epoch (700 / 2000) (Train_loss:10.46562943, ACU_loss:41.86251770, Val_loss:49.60007359)\n",
      "epoch (701 / 2000) (Train_loss:10.39301836, ACU_loss:41.57207344, Val_loss:49.34845450)\n",
      "epoch (702 / 2000) (Train_loss:10.32115878, ACU_loss:41.28463510, Val_loss:49.09871924)\n",
      "epoch (703 / 2000) (Train_loss:10.25014996, ACU_loss:41.00059983, Val_loss:48.85107868)\n",
      "epoch (704 / 2000) (Train_loss:10.17995286, ACU_loss:40.71981144, Val_loss:48.60534928)\n",
      "epoch (705 / 2000) (Train_loss:10.11057884, ACU_loss:40.44231534, Val_loss:48.36161543)\n",
      "epoch (706 / 2000) (Train_loss:10.04194590, ACU_loss:40.16778362, Val_loss:48.11973168)\n",
      "epoch (707 / 2000) (Train_loss:9.97406048, ACU_loss:39.89624193, Val_loss:47.87978018)\n",
      "epoch (708 / 2000) (Train_loss:9.90689748, ACU_loss:39.62758992, Val_loss:47.64169513)\n",
      "epoch (709 / 2000) (Train_loss:9.84048915, ACU_loss:39.36195658, Val_loss:47.40553548)\n",
      "epoch (710 / 2000) (Train_loss:9.77481561, ACU_loss:39.09926243, Val_loss:47.17123446)\n",
      "epoch (711 / 2000) (Train_loss:9.70987295, ACU_loss:38.83949182, Val_loss:46.93880165)\n",
      "epoch (712 / 2000) (Train_loss:9.64562309, ACU_loss:38.58249237, Val_loss:46.70817775)\n",
      "epoch (713 / 2000) (Train_loss:9.58205647, ACU_loss:38.32822587, Val_loss:46.47937303)\n",
      "epoch (714 / 2000) (Train_loss:9.51915603, ACU_loss:38.07662412, Val_loss:46.25235408)\n",
      "epoch (715 / 2000) (Train_loss:9.45692478, ACU_loss:37.82769910, Val_loss:46.02712774)\n",
      "epoch (716 / 2000) (Train_loss:9.39534930, ACU_loss:37.58139721, Val_loss:45.80365470)\n",
      "epoch (717 / 2000) (Train_loss:9.33441918, ACU_loss:37.33767674, Val_loss:45.58192287)\n",
      "epoch (718 / 2000) (Train_loss:9.27411063, ACU_loss:37.09644254, Val_loss:45.36188771)\n",
      "epoch (719 / 2000) (Train_loss:9.21440941, ACU_loss:36.85763762, Val_loss:45.14353725)\n",
      "epoch (720 / 2000) (Train_loss:9.15529903, ACU_loss:36.62119610, Val_loss:44.92683280)\n",
      "epoch (721 / 2000) (Train_loss:9.09677237, ACU_loss:36.38708948, Val_loss:44.71176239)\n",
      "epoch (722 / 2000) (Train_loss:9.03881554, ACU_loss:36.15526217, Val_loss:44.49828058)\n",
      "epoch (723 / 2000) (Train_loss:8.98141686, ACU_loss:35.92566743, Val_loss:44.28636733)\n",
      "epoch (724 / 2000) (Train_loss:8.92455723, ACU_loss:35.69822893, Val_loss:44.07597031)\n",
      "epoch (725 / 2000) (Train_loss:8.86822297, ACU_loss:35.47289186, Val_loss:43.86707065)\n",
      "epoch (726 / 2000) (Train_loss:8.81239750, ACU_loss:35.24959001, Val_loss:43.65961550)\n",
      "epoch (727 / 2000) (Train_loss:8.75706996, ACU_loss:35.02827984, Val_loss:43.45358867)\n",
      "epoch (728 / 2000) (Train_loss:8.70222386, ACU_loss:34.80889545, Val_loss:43.24893108)\n",
      "epoch (729 / 2000) (Train_loss:8.64784457, ACU_loss:34.59137827, Val_loss:43.04562605)\n",
      "epoch (730 / 2000) (Train_loss:8.59391098, ACU_loss:34.37564392, Val_loss:42.84360694)\n",
      "epoch (731 / 2000) (Train_loss:8.54040462, ACU_loss:34.16161848, Val_loss:42.64285985)\n",
      "epoch (732 / 2000) (Train_loss:8.48730260, ACU_loss:33.94921039, Val_loss:42.44331073)\n",
      "epoch (733 / 2000) (Train_loss:8.43458426, ACU_loss:33.73833704, Val_loss:42.24494736)\n",
      "epoch (734 / 2000) (Train_loss:8.38222465, ACU_loss:33.52889861, Val_loss:42.04768492)\n",
      "epoch (735 / 2000) (Train_loss:8.33020048, ACU_loss:33.32080191, Val_loss:41.85151306)\n",
      "epoch (736 / 2000) (Train_loss:8.27848749, ACU_loss:33.11394996, Val_loss:41.65634103)\n",
      "epoch (737 / 2000) (Train_loss:8.22706610, ACU_loss:32.90826441, Val_loss:41.46216856)\n",
      "epoch (738 / 2000) (Train_loss:8.17592105, ACU_loss:32.70368421, Val_loss:41.26891120)\n",
      "epoch (739 / 2000) (Train_loss:8.12504359, ACU_loss:32.50017434, Val_loss:41.07658793)\n",
      "epoch (740 / 2000) (Train_loss:8.07443122, ACU_loss:32.29772488, Val_loss:40.88513200)\n",
      "epoch (741 / 2000) (Train_loss:8.02408603, ACU_loss:32.09634411, Val_loss:40.69458331)\n",
      "epoch (742 / 2000) (Train_loss:7.97401434, ACU_loss:31.89605737, Val_loss:40.50489583)\n",
      "epoch (743 / 2000) (Train_loss:7.92422302, ACU_loss:31.69689207, Val_loss:40.31612039)\n",
      "epoch (744 / 2000) (Train_loss:7.87472037, ACU_loss:31.49888149, Val_loss:40.12822815)\n",
      "epoch (745 / 2000) (Train_loss:7.82551331, ACU_loss:31.30205323, Val_loss:39.94126715)\n",
      "epoch (746 / 2000) (Train_loss:7.77660950, ACU_loss:31.10643801, Val_loss:39.75522417)\n",
      "epoch (747 / 2000) (Train_loss:7.72801563, ACU_loss:30.91206252, Val_loss:39.57013389)\n",
      "epoch (748 / 2000) (Train_loss:7.67973857, ACU_loss:30.71895427, Val_loss:39.38599932)\n",
      "epoch (749 / 2000) (Train_loss:7.63178422, ACU_loss:30.52713687, Val_loss:39.20283646)\n",
      "epoch (750 / 2000) (Train_loss:7.58415834, ACU_loss:30.33663335, Val_loss:39.02066972)\n",
      "epoch (751 / 2000) (Train_loss:7.53686745, ACU_loss:30.14746978, Val_loss:38.83951880)\n",
      "epoch (752 / 2000) (Train_loss:7.48993179, ACU_loss:29.95972718, Val_loss:38.65951143)\n",
      "epoch (753 / 2000) (Train_loss:7.44351198, ACU_loss:29.77404792, Val_loss:38.48105731)\n",
      "epoch (754 / 2000) (Train_loss:7.39848934, ACU_loss:29.59395735, Val_loss:38.30531892)\n",
      "epoch (755 / 2000) (Train_loss:7.35560340, ACU_loss:29.42241361, Val_loss:38.13179719)\n",
      "epoch (756 / 2000) (Train_loss:7.31293439, ACU_loss:29.25173756, Val_loss:37.95675073)\n",
      "epoch (757 / 2000) (Train_loss:7.26815163, ACU_loss:29.07260650, Val_loss:37.78155629)\n",
      "epoch (758 / 2000) (Train_loss:7.22107412, ACU_loss:28.88429647, Val_loss:37.60709853)\n",
      "epoch (759 / 2000) (Train_loss:7.17529087, ACU_loss:28.70116348, Val_loss:37.43406822)\n",
      "epoch (760 / 2000) (Train_loss:7.13093811, ACU_loss:28.52375242, Val_loss:37.26476627)\n",
      "epoch (761 / 2000) (Train_loss:7.08744730, ACU_loss:28.34978918, Val_loss:37.09114805)\n",
      "epoch (762 / 2000) (Train_loss:7.04292185, ACU_loss:28.17168742, Val_loss:36.92324135)\n",
      "epoch (763 / 2000) (Train_loss:6.99636243, ACU_loss:27.98544974, Val_loss:36.74930919)\n",
      "epoch (764 / 2000) (Train_loss:6.95148339, ACU_loss:27.80593355, Val_loss:36.58184614)\n",
      "epoch (765 / 2000) (Train_loss:6.90569762, ACU_loss:27.62279049, Val_loss:36.41546206)\n",
      "epoch (766 / 2000) (Train_loss:6.86454455, ACU_loss:27.45817819, Val_loss:36.24454195)\n",
      "epoch (767 / 2000) (Train_loss:6.82126041, ACU_loss:27.28504165, Val_loss:36.08886388)\n",
      "epoch (768 / 2000) (Train_loss:6.77963474, ACU_loss:27.11853894, Val_loss:35.91083421)\n",
      "epoch (769 / 2000) (Train_loss:6.73774197, ACU_loss:26.95096789, Val_loss:35.76075136)\n",
      "epoch (770 / 2000) (Train_loss:6.69211166, ACU_loss:26.76844664, Val_loss:35.58631481)\n",
      "epoch (771 / 2000) (Train_loss:6.65559885, ACU_loss:26.62239539, Val_loss:35.42886278)\n",
      "epoch (772 / 2000) (Train_loss:6.60928551, ACU_loss:26.43714203, Val_loss:35.27840541)\n",
      "epoch (773 / 2000) (Train_loss:6.57810677, ACU_loss:26.31242707, Val_loss:35.09851439)\n",
      "epoch (774 / 2000) (Train_loss:6.53457422, ACU_loss:26.13829686, Val_loss:34.97675012)\n",
      "epoch (775 / 2000) (Train_loss:6.49591224, ACU_loss:25.98364895, Val_loss:34.77620646)\n",
      "epoch (776 / 2000) (Train_loss:6.46080063, ACU_loss:25.84320252, Val_loss:34.65465250)\n",
      "epoch (777 / 2000) (Train_loss:6.41110097, ACU_loss:25.64440389, Val_loss:34.47979443)\n",
      "epoch (778 / 2000) (Train_loss:6.39788126, ACU_loss:25.59152504, Val_loss:34.32592685)\n",
      "epoch (779 / 2000) (Train_loss:6.35034736, ACU_loss:25.40138946, Val_loss:34.23159801)\n",
      "epoch (780 / 2000) (Train_loss:6.34340528, ACU_loss:25.37362111, Val_loss:34.00722761)\n",
      "epoch (781 / 2000) (Train_loss:6.29238861, ACU_loss:25.16955446, Val_loss:33.94090698)\n",
      "epoch (782 / 2000) (Train_loss:6.25462703, ACU_loss:25.01850811, Val_loss:33.69657299)\n",
      "epoch (783 / 2000) (Train_loss:6.23260784, ACU_loss:24.93043135, Val_loss:33.59446978)\n",
      "epoch (784 / 2000) (Train_loss:6.18549943, ACU_loss:24.74199774, Val_loss:33.46033095)\n",
      "epoch (785 / 2000) (Train_loss:6.20471621, ACU_loss:24.81886485, Val_loss:33.27040249)\n",
      "epoch (786 / 2000) (Train_loss:6.15672068, ACU_loss:24.62688272, Val_loss:33.31887706)\n",
      "epoch (787 / 2000) (Train_loss:6.19477815, ACU_loss:24.77911259, Val_loss:33.01173110)\n",
      "epoch (788 / 2000) (Train_loss:6.12863367, ACU_loss:24.51453470, Val_loss:32.90255980)\n",
      "epoch (789 / 2000) (Train_loss:6.08442701, ACU_loss:24.33770803, Val_loss:32.68920516)\n",
      "epoch (790 / 2000) (Train_loss:6.00284968, ACU_loss:24.01139873, Val_loss:32.55304414)\n",
      "epoch (791 / 2000) (Train_loss:5.92506116, ACU_loss:23.70024464, Val_loss:32.42016735)\n",
      "epoch (792 / 2000) (Train_loss:5.85428084, ACU_loss:23.41712338, Val_loss:32.24148363)\n",
      "epoch (793 / 2000) (Train_loss:5.82551835, ACU_loss:23.30207341, Val_loss:32.12638652)\n",
      "epoch (794 / 2000) (Train_loss:5.78905127, ACU_loss:23.15620507, Val_loss:31.97697326)\n",
      "epoch (795 / 2000) (Train_loss:5.76549130, ACU_loss:23.06196519, Val_loss:31.83827869)\n",
      "epoch (796 / 2000) (Train_loss:5.73503964, ACU_loss:22.94015855, Val_loss:31.70412873)\n",
      "epoch (797 / 2000) (Train_loss:5.69356145, ACU_loss:22.77424581, Val_loss:31.54106102)\n",
      "epoch (798 / 2000) (Train_loss:5.65438086, ACU_loss:22.61752344, Val_loss:31.41654250)\n",
      "epoch (799 / 2000) (Train_loss:5.62264833, ACU_loss:22.49059333, Val_loss:31.27611147)\n",
      "epoch (800 / 2000) (Train_loss:5.59858008, ACU_loss:22.39432031, Val_loss:31.15142890)\n",
      "epoch (801 / 2000) (Train_loss:5.57045760, ACU_loss:22.28183039, Val_loss:31.01615211)\n",
      "epoch (802 / 2000) (Train_loss:5.53583281, ACU_loss:22.14333125, Val_loss:30.87088103)\n",
      "epoch (803 / 2000) (Train_loss:5.49678622, ACU_loss:21.98714489, Val_loss:30.74353396)\n",
      "epoch (804 / 2000) (Train_loss:5.46653054, ACU_loss:21.86612214, Val_loss:30.60671275)\n",
      "epoch (805 / 2000) (Train_loss:5.43973292, ACU_loss:21.75893169, Val_loss:30.48614905)\n",
      "epoch (806 / 2000) (Train_loss:5.41383201, ACU_loss:21.65532806, Val_loss:30.35020661)\n",
      "epoch (807 / 2000) (Train_loss:5.38388422, ACU_loss:21.53553687, Val_loss:30.21916690)\n",
      "epoch (808 / 2000) (Train_loss:5.34929064, ACU_loss:21.39716255, Val_loss:30.08908228)\n",
      "epoch (809 / 2000) (Train_loss:5.31960401, ACU_loss:21.27841603, Val_loss:29.95832450)\n",
      "epoch (810 / 2000) (Train_loss:5.29064248, ACU_loss:21.16256994, Val_loss:29.83781967)\n",
      "epoch (811 / 2000) (Train_loss:5.26514341, ACU_loss:21.06057364, Val_loss:29.70652761)\n",
      "epoch (812 / 2000) (Train_loss:5.23755753, ACU_loss:20.95023014, Val_loss:29.58513705)\n",
      "epoch (813 / 2000) (Train_loss:5.20767255, ACU_loss:20.83069018, Val_loss:29.45508431)\n",
      "epoch (814 / 2000) (Train_loss:5.17926936, ACU_loss:20.71707743, Val_loss:29.33176780)\n",
      "epoch (815 / 2000) (Train_loss:5.14965412, ACU_loss:20.59861648, Val_loss:29.20907210)\n",
      "epoch (816 / 2000) (Train_loss:5.12383390, ACU_loss:20.49533560, Val_loss:29.08425871)\n",
      "epoch (817 / 2000) (Train_loss:5.09640336, ACU_loss:20.38561345, Val_loss:28.96626734)\n",
      "epoch (818 / 2000) (Train_loss:5.06972666, ACU_loss:20.27890664, Val_loss:28.84007838)\n",
      "epoch (819 / 2000) (Train_loss:5.04295467, ACU_loss:20.17181869, Val_loss:28.72320137)\n",
      "epoch (820 / 2000) (Train_loss:5.01488349, ACU_loss:20.05953397, Val_loss:28.59985859)\n",
      "epoch (821 / 2000) (Train_loss:4.98927739, ACU_loss:19.95710956, Val_loss:28.48202829)\n",
      "epoch (822 / 2000) (Train_loss:4.96177821, ACU_loss:19.84711283, Val_loss:28.36378853)\n",
      "epoch (823 / 2000) (Train_loss:4.93656475, ACU_loss:19.74625898, Val_loss:28.24397460)\n",
      "epoch (824 / 2000) (Train_loss:4.91050612, ACU_loss:19.64202447, Val_loss:28.12994337)\n",
      "epoch (825 / 2000) (Train_loss:4.88450833, ACU_loss:19.53803331, Val_loss:28.00953045)\n",
      "epoch (826 / 2000) (Train_loss:4.85967563, ACU_loss:19.43870252, Val_loss:27.89713201)\n",
      "epoch (827 / 2000) (Train_loss:4.83313369, ACU_loss:19.33253476, Val_loss:27.77907384)\n",
      "epoch (828 / 2000) (Train_loss:4.80882334, ACU_loss:19.23529334, Val_loss:27.66591102)\n",
      "epoch (829 / 2000) (Train_loss:4.78304104, ACU_loss:19.13216416, Val_loss:27.55209920)\n",
      "epoch (830 / 2000) (Train_loss:4.75846232, ACU_loss:19.03384930, Val_loss:27.43730467)\n",
      "epoch (831 / 2000) (Train_loss:4.73410983, ACU_loss:18.93643932, Val_loss:27.32729265)\n",
      "epoch (832 / 2000) (Train_loss:4.70899274, ACU_loss:18.83597098, Val_loss:27.21220658)\n",
      "epoch (833 / 2000) (Train_loss:4.68559265, ACU_loss:18.74237062, Val_loss:27.10388882)\n",
      "epoch (834 / 2000) (Train_loss:4.66062434, ACU_loss:18.64249734, Val_loss:26.99089094)\n",
      "epoch (835 / 2000) (Train_loss:4.63720182, ACU_loss:18.54880726, Val_loss:26.88198369)\n",
      "epoch (836 / 2000) (Train_loss:4.61322276, ACU_loss:18.45289105, Val_loss:26.77258886)\n",
      "epoch (837 / 2000) (Train_loss:4.58933271, ACU_loss:18.35733085, Val_loss:26.66250618)\n",
      "epoch (838 / 2000) (Train_loss:4.56652746, ACU_loss:18.26610982, Val_loss:26.55644383)\n",
      "epoch (839 / 2000) (Train_loss:4.54263818, ACU_loss:18.17055273, Val_loss:26.44647896)\n",
      "epoch (840 / 2000) (Train_loss:4.52024616, ACU_loss:18.08098463, Val_loss:26.34177254)\n",
      "epoch (841 / 2000) (Train_loss:4.49698210, ACU_loss:17.98792842, Val_loss:26.23377220)\n",
      "epoch (842 / 2000) (Train_loss:4.47422720, ACU_loss:17.89690882, Val_loss:26.12863056)\n",
      "epoch (843 / 2000) (Train_loss:4.45190416, ACU_loss:17.80761666, Val_loss:26.02373050)\n",
      "epoch (844 / 2000) (Train_loss:4.42904358, ACU_loss:17.71617432, Val_loss:25.91810539)\n",
      "epoch (845 / 2000) (Train_loss:4.40738381, ACU_loss:17.62953525, Val_loss:25.81569566)\n",
      "epoch (846 / 2000) (Train_loss:4.38502316, ACU_loss:17.54009265, Val_loss:25.71073548)\n",
      "epoch (847 / 2000) (Train_loss:4.36331121, ACU_loss:17.45324486, Val_loss:25.60914028)\n",
      "epoch (848 / 2000) (Train_loss:4.34165068, ACU_loss:17.36660271, Val_loss:25.50614227)\n",
      "epoch (849 / 2000) (Train_loss:4.31980806, ACU_loss:17.27923224, Val_loss:25.40452728)\n",
      "epoch (850 / 2000) (Train_loss:4.29872411, ACU_loss:17.19489643, Val_loss:25.30383081)\n",
      "epoch (851 / 2000) (Train_loss:4.27725977, ACU_loss:17.10903909, Val_loss:25.20257367)\n",
      "epoch (852 / 2000) (Train_loss:4.25637212, ACU_loss:17.02548848, Val_loss:25.10333350)\n",
      "epoch (853 / 2000) (Train_loss:4.23547895, ACU_loss:16.94191578, Val_loss:25.00323624)\n",
      "epoch (854 / 2000) (Train_loss:4.21461299, ACU_loss:16.85845197, Val_loss:24.90464360)\n",
      "epoch (855 / 2000) (Train_loss:4.19414157, ACU_loss:16.77656630, Val_loss:24.80613954)\n",
      "epoch (856 / 2000) (Train_loss:4.17355427, ACU_loss:16.69421709, Val_loss:24.70816986)\n",
      "epoch (857 / 2000) (Train_loss:4.15333786, ACU_loss:16.61335144, Val_loss:24.61102384)\n",
      "epoch (858 / 2000) (Train_loss:4.13319346, ACU_loss:16.53277385, Val_loss:24.51400747)\n",
      "epoch (859 / 2000) (Train_loss:4.11316742, ACU_loss:16.45266970, Val_loss:24.41781997)\n",
      "epoch (860 / 2000) (Train_loss:4.09334844, ACU_loss:16.37339376, Val_loss:24.32191933)\n",
      "epoch (861 / 2000) (Train_loss:4.07358092, ACU_loss:16.29432369, Val_loss:24.22661659)\n",
      "epoch (862 / 2000) (Train_loss:4.05399846, ACU_loss:16.21599385, Val_loss:24.13176789)\n",
      "epoch (863 / 2000) (Train_loss:4.03454968, ACU_loss:16.13819873, Val_loss:24.03743767)\n",
      "epoch (864 / 2000) (Train_loss:4.01522624, ACU_loss:16.06090496, Val_loss:23.94354698)\n",
      "epoch (865 / 2000) (Train_loss:3.99604784, ACU_loss:15.98419136, Val_loss:23.85016915)\n",
      "epoch (866 / 2000) (Train_loss:3.97699204, ACU_loss:15.90796815, Val_loss:23.75722348)\n",
      "epoch (867 / 2000) (Train_loss:3.95804369, ACU_loss:15.83217475, Val_loss:23.66473749)\n",
      "epoch (868 / 2000) (Train_loss:3.93923669, ACU_loss:15.75694677, Val_loss:23.57273581)\n",
      "epoch (869 / 2000) (Train_loss:3.92054264, ACU_loss:15.68217054, Val_loss:23.48114257)\n",
      "epoch (870 / 2000) (Train_loss:3.90197633, ACU_loss:15.60790533, Val_loss:23.39003819)\n",
      "epoch (871 / 2000) (Train_loss:3.88354131, ACU_loss:15.53416524, Val_loss:23.29934407)\n",
      "epoch (872 / 2000) (Train_loss:3.86521470, ACU_loss:15.46085881, Val_loss:23.20909727)\n",
      "epoch (873 / 2000) (Train_loss:3.84701290, ACU_loss:15.38805161, Val_loss:23.11927472)\n",
      "epoch (874 / 2000) (Train_loss:3.82892498, ACU_loss:15.31569991, Val_loss:23.02988109)\n",
      "epoch (875 / 2000) (Train_loss:3.81095434, ACU_loss:15.24381737, Val_loss:22.94090579)\n",
      "epoch (876 / 2000) (Train_loss:3.79310566, ACU_loss:15.17242264, Val_loss:22.85235670)\n",
      "epoch (877 / 2000) (Train_loss:3.77537697, ACU_loss:15.10150790, Val_loss:22.76421746)\n",
      "epoch (878 / 2000) (Train_loss:3.75776490, ACU_loss:15.03105960, Val_loss:22.67648903)\n",
      "epoch (879 / 2000) (Train_loss:3.74027141, ACU_loss:14.96108563, Val_loss:22.58916837)\n",
      "epoch (880 / 2000) (Train_loss:3.72289140, ACU_loss:14.89156561, Val_loss:22.50224544)\n",
      "epoch (881 / 2000) (Train_loss:3.70562671, ACU_loss:14.82250683, Val_loss:22.41572544)\n",
      "epoch (882 / 2000) (Train_loss:3.68847994, ACU_loss:14.75391974, Val_loss:22.32960050)\n",
      "epoch (883 / 2000) (Train_loss:3.67144993, ACU_loss:14.68579972, Val_loss:22.24387011)\n",
      "epoch (884 / 2000) (Train_loss:3.65453789, ACU_loss:14.61815156, Val_loss:22.15852863)\n",
      "epoch (885 / 2000) (Train_loss:3.63774180, ACU_loss:14.55096722, Val_loss:22.07357445)\n",
      "epoch (886 / 2000) (Train_loss:3.62105935, ACU_loss:14.48423742, Val_loss:21.98900103)\n",
      "epoch (887 / 2000) (Train_loss:3.60448990, ACU_loss:14.41795959, Val_loss:21.90480999)\n",
      "epoch (888 / 2000) (Train_loss:3.58803412, ACU_loss:14.35213650, Val_loss:21.82099712)\n",
      "epoch (889 / 2000) (Train_loss:3.57169190, ACU_loss:14.28676761, Val_loss:21.73756233)\n",
      "epoch (890 / 2000) (Train_loss:3.55546367, ACU_loss:14.22185467, Val_loss:21.65450208)\n",
      "epoch (891 / 2000) (Train_loss:3.53934679, ACU_loss:14.15738716, Val_loss:21.57181385)\n",
      "epoch (892 / 2000) (Train_loss:3.52333761, ACU_loss:14.09335046, Val_loss:21.48949345)\n",
      "epoch (893 / 2000) (Train_loss:3.50743246, ACU_loss:14.02972983, Val_loss:21.40753991)\n",
      "epoch (894 / 2000) (Train_loss:3.49162869, ACU_loss:13.96651474, Val_loss:21.32595105)\n",
      "epoch (895 / 2000) (Train_loss:3.47592440, ACU_loss:13.90369760, Val_loss:21.24472632)\n",
      "epoch (896 / 2000) (Train_loss:3.46031792, ACU_loss:13.84127169, Val_loss:21.16386316)\n",
      "epoch (897 / 2000) (Train_loss:3.44480539, ACU_loss:13.77922158, Val_loss:21.08335846)\n",
      "epoch (898 / 2000) (Train_loss:3.42938119, ACU_loss:13.71752476, Val_loss:21.00320811)\n",
      "epoch (899 / 2000) (Train_loss:3.41403907, ACU_loss:13.65615629, Val_loss:20.92340977)\n",
      "epoch (900 / 2000) (Train_loss:3.39877423, ACU_loss:13.59509692, Val_loss:20.84396191)\n",
      "epoch (901 / 2000) (Train_loss:3.38358411, ACU_loss:13.53433644, Val_loss:20.76486430)\n",
      "epoch (902 / 2000) (Train_loss:3.36846741, ACU_loss:13.47386964, Val_loss:20.68611532)\n",
      "epoch (903 / 2000) (Train_loss:3.35342141, ACU_loss:13.41368562, Val_loss:20.60771185)\n",
      "epoch (904 / 2000) (Train_loss:3.33844094, ACU_loss:13.35376376, Val_loss:20.52964965)\n",
      "epoch (905 / 2000) (Train_loss:3.32351958, ACU_loss:13.29407833, Val_loss:20.45192605)\n",
      "epoch (906 / 2000) (Train_loss:3.30865271, ACU_loss:13.23461083, Val_loss:20.37454057)\n",
      "epoch (907 / 2000) (Train_loss:3.29383938, ACU_loss:13.17535750, Val_loss:20.29749440)\n",
      "epoch (908 / 2000) (Train_loss:3.27908099, ACU_loss:13.11632395, Val_loss:20.22078727)\n",
      "epoch (909 / 2000) (Train_loss:3.26437741, ACU_loss:13.05750964, Val_loss:20.14441608)\n",
      "epoch (910 / 2000) (Train_loss:3.24972455, ACU_loss:12.99889822, Val_loss:20.06837595)\n",
      "epoch (911 / 2000) (Train_loss:3.23511610, ACU_loss:12.94046439, Val_loss:19.99266434)\n",
      "epoch (912 / 2000) (Train_loss:3.22054893, ACU_loss:12.88219572, Val_loss:19.91728408)\n",
      "epoch (913 / 2000) (Train_loss:3.20602615, ACU_loss:12.82410461, Val_loss:19.84223788)\n",
      "epoch (914 / 2000) (Train_loss:3.19155244, ACU_loss:12.76620974, Val_loss:19.76752549)\n",
      "epoch (915 / 2000) (Train_loss:3.17712773, ACU_loss:12.70851091, Val_loss:19.69314202)\n",
      "epoch (916 / 2000) (Train_loss:3.16274671, ACU_loss:12.65098685, Val_loss:19.61908270)\n",
      "epoch (917 / 2000) (Train_loss:3.14840416, ACU_loss:12.59361666, Val_loss:19.54534779)\n",
      "epoch (918 / 2000) (Train_loss:3.13410098, ACU_loss:12.53640392, Val_loss:19.47194290)\n",
      "epoch (919 / 2000) (Train_loss:3.11984503, ACU_loss:12.47938012, Val_loss:19.39887279)\n",
      "epoch (920 / 2000) (Train_loss:3.10564412, ACU_loss:12.42257649, Val_loss:19.32613568)\n",
      "epoch (921 / 2000) (Train_loss:3.09149805, ACU_loss:12.36599222, Val_loss:19.25372391)\n",
      "epoch (922 / 2000) (Train_loss:3.07739911, ACU_loss:12.30959643, Val_loss:19.18163222)\n",
      "epoch (923 / 2000) (Train_loss:3.06334149, ACU_loss:12.25336595, Val_loss:19.10986436)\n",
      "epoch (924 / 2000) (Train_loss:3.04933028, ACU_loss:12.19732112, Val_loss:19.03843055)\n",
      "epoch (925 / 2000) (Train_loss:3.03537955, ACU_loss:12.14151821, Val_loss:18.96733699)\n",
      "epoch (926 / 2000) (Train_loss:3.02149980, ACU_loss:12.08599921, Val_loss:18.89657843)\n",
      "epoch (927 / 2000) (Train_loss:3.00768757, ACU_loss:12.03075028, Val_loss:18.82614279)\n",
      "epoch (928 / 2000) (Train_loss:2.99392951, ACU_loss:11.97571802, Val_loss:18.75602463)\n",
      "epoch (929 / 2000) (Train_loss:2.98021854, ACU_loss:11.92087418, Val_loss:18.68623332)\n",
      "epoch (930 / 2000) (Train_loss:2.96656566, ACU_loss:11.86626264, Val_loss:18.61678556)\n",
      "epoch (931 / 2000) (Train_loss:2.95299283, ACU_loss:11.81197132, Val_loss:18.54768807)\n",
      "epoch (932 / 2000) (Train_loss:2.93951204, ACU_loss:11.75804816, Val_loss:18.47892883)\n",
      "epoch (933 / 2000) (Train_loss:2.92611201, ACU_loss:11.70444805, Val_loss:18.41048820)\n",
      "epoch (934 / 2000) (Train_loss:2.91276922, ACU_loss:11.65107687, Val_loss:18.34236101)\n",
      "epoch (935 / 2000) (Train_loss:2.89947480, ACU_loss:11.59789922, Val_loss:18.27456590)\n",
      "epoch (936 / 2000) (Train_loss:2.88624938, ACU_loss:11.54499751, Val_loss:18.20712896)\n",
      "epoch (937 / 2000) (Train_loss:2.87312646, ACU_loss:11.49250585, Val_loss:18.14005585)\n",
      "epoch (938 / 2000) (Train_loss:2.86011803, ACU_loss:11.44047211, Val_loss:18.07332192)\n",
      "epoch (939 / 2000) (Train_loss:2.84719815, ACU_loss:11.38879262, Val_loss:18.00689518)\n",
      "epoch (940 / 2000) (Train_loss:2.83432689, ACU_loss:11.33730757, Val_loss:17.94077193)\n",
      "epoch (941 / 2000) (Train_loss:2.82149448, ACU_loss:11.28597794, Val_loss:17.87498685)\n",
      "epoch (942 / 2000) (Train_loss:2.80873930, ACU_loss:11.23495721, Val_loss:17.80958117)\n",
      "epoch (943 / 2000) (Train_loss:2.79611417, ACU_loss:11.18445669, Val_loss:17.74455745)\n",
      "epoch (944 / 2000) (Train_loss:2.78362984, ACU_loss:11.13451937, Val_loss:17.67986918)\n",
      "epoch (945 / 2000) (Train_loss:2.77123517, ACU_loss:11.08494067, Val_loss:17.61546361)\n",
      "epoch (946 / 2000) (Train_loss:2.75886352, ACU_loss:11.03545408, Val_loss:17.55134027)\n",
      "epoch (947 / 2000) (Train_loss:2.74650577, ACU_loss:10.98602309, Val_loss:17.48756191)\n",
      "epoch (948 / 2000) (Train_loss:2.73423236, ACU_loss:10.93692946, Val_loss:17.42419625)\n",
      "epoch (949 / 2000) (Train_loss:2.72212993, ACU_loss:10.88851972, Val_loss:17.36124135)\n",
      "epoch (950 / 2000) (Train_loss:2.71020752, ACU_loss:10.84083010, Val_loss:17.29861310)\n",
      "epoch (951 / 2000) (Train_loss:2.69837077, ACU_loss:10.79348308, Val_loss:17.23622130)\n",
      "epoch (952 / 2000) (Train_loss:2.68650640, ACU_loss:10.74602562, Val_loss:17.17406884)\n",
      "epoch (953 / 2000) (Train_loss:2.67460533, ACU_loss:10.69842133, Val_loss:17.11226708)\n",
      "epoch (954 / 2000) (Train_loss:2.66279373, ACU_loss:10.65117491, Val_loss:17.05093367)\n",
      "epoch (955 / 2000) (Train_loss:2.65122030, ACU_loss:10.60488119, Val_loss:16.99006521)\n",
      "epoch (956 / 2000) (Train_loss:2.63989718, ACU_loss:10.55958872, Val_loss:16.92951488)\n",
      "epoch (957 / 2000) (Train_loss:2.62865776, ACU_loss:10.51463103, Val_loss:16.86912039)\n",
      "epoch (958 / 2000) (Train_loss:2.61730193, ACU_loss:10.46920771, Val_loss:16.80887906)\n",
      "epoch (959 / 2000) (Train_loss:2.60580976, ACU_loss:10.42323903, Val_loss:16.74898308)\n",
      "epoch (960 / 2000) (Train_loss:2.59439930, ACU_loss:10.37759721, Val_loss:16.68964777)\n",
      "epoch (961 / 2000) (Train_loss:2.58333693, ACU_loss:10.33334771, Val_loss:16.63088810)\n",
      "epoch (962 / 2000) (Train_loss:2.57266188, ACU_loss:10.29064752, Val_loss:16.57246064)\n",
      "epoch (963 / 2000) (Train_loss:2.56209568, ACU_loss:10.24838271, Val_loss:16.51406139)\n",
      "epoch (964 / 2000) (Train_loss:2.55127186, ACU_loss:10.20508743, Val_loss:16.45564206)\n",
      "epoch (965 / 2000) (Train_loss:2.54011525, ACU_loss:10.16046099, Val_loss:16.39751598)\n",
      "epoch (966 / 2000) (Train_loss:2.52897999, ACU_loss:10.11591995, Val_loss:16.34008747)\n",
      "epoch (967 / 2000) (Train_loss:2.51835380, ACU_loss:10.07341519, Val_loss:16.28345601)\n",
      "epoch (968 / 2000) (Train_loss:2.50838081, ACU_loss:10.03352322, Val_loss:16.22725906)\n",
      "epoch (969 / 2000) (Train_loss:2.49864121, ACU_loss:9.99456484, Val_loss:16.17092693)\n",
      "epoch (970 / 2000) (Train_loss:2.48845902, ACU_loss:9.95383607, Val_loss:16.11423953)\n",
      "epoch (971 / 2000) (Train_loss:2.47756878, ACU_loss:9.91027511, Val_loss:16.05764748)\n",
      "epoch (972 / 2000) (Train_loss:2.46647904, ACU_loss:9.86591617, Val_loss:16.00189871)\n",
      "epoch (973 / 2000) (Train_loss:2.45606842, ACU_loss:9.82427369, Val_loss:15.94734263)\n",
      "epoch (974 / 2000) (Train_loss:2.44678154, ACU_loss:9.78712617, Val_loss:15.89355913)\n",
      "epoch (975 / 2000) (Train_loss:2.43812093, ACU_loss:9.75248372, Val_loss:15.83956142)\n",
      "epoch (976 / 2000) (Train_loss:2.42890892, ACU_loss:9.71563567, Val_loss:15.78464613)\n",
      "epoch (977 / 2000) (Train_loss:2.41835544, ACU_loss:9.67342178, Val_loss:15.72926813)\n",
      "epoch (978 / 2000) (Train_loss:2.40699595, ACU_loss:9.62798381, Val_loss:15.67472388)\n",
      "epoch (979 / 2000) (Train_loss:2.39630812, ACU_loss:9.58523246, Val_loss:15.62193158)\n",
      "epoch (980 / 2000) (Train_loss:2.38740915, ACU_loss:9.54963661, Val_loss:15.57068206)\n",
      "epoch (981 / 2000) (Train_loss:2.38005005, ACU_loss:9.52020019, Val_loss:15.51959628)\n",
      "epoch (982 / 2000) (Train_loss:2.37250851, ACU_loss:9.49003406, Val_loss:15.46696287)\n",
      "epoch (983 / 2000) (Train_loss:2.36285278, ACU_loss:9.45141111, Val_loss:15.41261598)\n",
      "epoch (984 / 2000) (Train_loss:2.35104841, ACU_loss:9.40419366, Val_loss:15.35849179)\n",
      "epoch (985 / 2000) (Train_loss:2.33925989, ACU_loss:9.35703955, Val_loss:15.30660938)\n",
      "epoch (986 / 2000) (Train_loss:2.32981070, ACU_loss:9.31924280, Val_loss:15.25746363)\n",
      "epoch (987 / 2000) (Train_loss:2.32339210, ACU_loss:9.29356838, Val_loss:15.20986710)\n",
      "epoch (988 / 2000) (Train_loss:2.31835902, ACU_loss:9.27343607, Val_loss:15.16096375)\n",
      "epoch (989 / 2000) (Train_loss:2.31121330, ACU_loss:9.24485318, Val_loss:15.10843210)\n",
      "epoch (990 / 2000) (Train_loss:2.29973771, ACU_loss:9.19895084, Val_loss:15.05394660)\n",
      "epoch (991 / 2000) (Train_loss:2.28606654, ACU_loss:9.14426616, Val_loss:15.00145710)\n",
      "epoch (992 / 2000) (Train_loss:2.27436440, ACU_loss:9.09745759, Val_loss:14.95288671)\n",
      "epoch (993 / 2000) (Train_loss:2.26711638, ACU_loss:9.06846551, Val_loss:14.90799696)\n",
      "epoch (994 / 2000) (Train_loss:2.26408464, ACU_loss:9.05633857, Val_loss:14.86447674)\n",
      "epoch (995 / 2000) (Train_loss:2.26169519, ACU_loss:9.04678075, Val_loss:14.81701984)\n",
      "epoch (996 / 2000) (Train_loss:2.25391986, ACU_loss:9.01567943, Val_loss:14.76313537)\n",
      "epoch (997 / 2000) (Train_loss:2.23923026, ACU_loss:8.95692105, Val_loss:14.70815433)\n",
      "epoch (998 / 2000) (Train_loss:2.22347421, ACU_loss:8.89389683, Val_loss:14.65774948)\n",
      "epoch (999 / 2000) (Train_loss:2.21234984, ACU_loss:8.84939935, Val_loss:14.61259825)\n",
      "epoch (1000 / 2000) (Train_loss:2.20778070, ACU_loss:8.83112281, Val_loss:14.57245106)\n",
      "epoch (1001 / 2000) (Train_loss:2.20890523, ACU_loss:8.83562090, Val_loss:14.53388572)\n",
      "epoch (1002 / 2000) (Train_loss:2.20989816, ACU_loss:8.83959263, Val_loss:14.48746250)\n",
      "epoch (1003 / 2000) (Train_loss:2.20086678, ACU_loss:8.80346713, Val_loss:14.43099412)\n",
      "epoch (1004 / 2000) (Train_loss:2.18197538, ACU_loss:8.72790154, Val_loss:14.37524578)\n",
      "epoch (1005 / 2000) (Train_loss:2.16390294, ACU_loss:8.65561175, Val_loss:14.32681853)\n",
      "epoch (1006 / 2000) (Train_loss:2.15308558, ACU_loss:8.61234230, Val_loss:14.28416776)\n",
      "epoch (1007 / 2000) (Train_loss:2.15051951, ACU_loss:8.60207803, Val_loss:14.24867292)\n",
      "epoch (1008 / 2000) (Train_loss:2.15598284, ACU_loss:8.62393135, Val_loss:14.21643264)\n",
      "epoch (1009 / 2000) (Train_loss:2.16191557, ACU_loss:8.64766229, Val_loss:14.17227560)\n",
      "epoch (1010 / 2000) (Train_loss:2.15285496, ACU_loss:8.61141985, Val_loss:14.11299117)\n",
      "epoch (1011 / 2000) (Train_loss:2.12967600, ACU_loss:8.51870399, Val_loss:14.05550199)\n",
      "epoch (1012 / 2000) (Train_loss:2.10840490, ACU_loss:8.43361959, Val_loss:14.00816327)\n",
      "epoch (1013 / 2000) (Train_loss:2.09657660, ACU_loss:8.38630639, Val_loss:13.96622187)\n",
      "epoch (1014 / 2000) (Train_loss:2.09391419, ACU_loss:8.37565677, Val_loss:13.93325355)\n",
      "epoch (1015 / 2000) (Train_loss:2.10170405, ACU_loss:8.40681619, Val_loss:13.90764963)\n",
      "epoch (1016 / 2000) (Train_loss:2.11374848, ACU_loss:8.45499393, Val_loss:13.86996632)\n",
      "epoch (1017 / 2000) (Train_loss:2.10945364, ACU_loss:8.43781455, Val_loss:13.81103168)\n",
      "epoch (1018 / 2000) (Train_loss:2.08468046, ACU_loss:8.33872186, Val_loss:13.74997360)\n",
      "epoch (1019 / 2000) (Train_loss:2.05890435, ACU_loss:8.23561738, Val_loss:13.70182994)\n",
      "epoch (1020 / 2000) (Train_loss:2.04403736, ACU_loss:8.17614943, Val_loss:13.65954873)\n",
      "epoch (1021 / 2000) (Train_loss:2.03899583, ACU_loss:8.15598330, Val_loss:13.62483839)\n",
      "epoch (1022 / 2000) (Train_loss:2.04440694, ACU_loss:8.17762777, Val_loss:13.60214719)\n",
      "epoch (1023 / 2000) (Train_loss:2.05973979, ACU_loss:8.23895914, Val_loss:13.57478374)\n",
      "epoch (1024 / 2000) (Train_loss:2.06581644, ACU_loss:8.26326578, Val_loss:13.52505338)\n",
      "epoch (1025 / 2000) (Train_loss:2.04775400, ACU_loss:8.19101601, Val_loss:13.46144286)\n",
      "epoch (1026 / 2000) (Train_loss:2.01830516, ACU_loss:8.07322063, Val_loss:13.40810671)\n",
      "epoch (1027 / 2000) (Train_loss:1.99750322, ACU_loss:7.99001288, Val_loss:13.36540831)\n",
      "epoch (1028 / 2000) (Train_loss:1.98835381, ACU_loss:7.95341523, Val_loss:13.32661128)\n",
      "epoch (1029 / 2000) (Train_loss:1.98777485, ACU_loss:7.95109939, Val_loss:13.29951814)\n",
      "epoch (1030 / 2000) (Train_loss:1.99878149, ACU_loss:7.99512596, Val_loss:13.27864246)\n",
      "epoch (1031 / 2000) (Train_loss:2.01298546, ACU_loss:8.05194185, Val_loss:13.24571381)\n",
      "epoch (1032 / 2000) (Train_loss:2.01132754, ACU_loss:8.04531015, Val_loss:13.19150116)\n",
      "epoch (1033 / 2000) (Train_loss:1.98838098, ACU_loss:7.95352393, Val_loss:13.13121148)\n",
      "epoch (1034 / 2000) (Train_loss:1.96106098, ACU_loss:7.84424393, Val_loss:13.08326414)\n",
      "epoch (1035 / 2000) (Train_loss:1.94441199, ACU_loss:7.77764794, Val_loss:13.04257995)\n",
      "epoch (1036 / 2000) (Train_loss:1.93761818, ACU_loss:7.75047271, Val_loss:13.00725159)\n",
      "epoch (1037 / 2000) (Train_loss:1.93907419, ACU_loss:7.75629677, Val_loss:12.98231232)\n",
      "epoch (1038 / 2000) (Train_loss:1.95002997, ACU_loss:7.80011987, Val_loss:12.95964725)\n",
      "epoch (1039 / 2000) (Train_loss:1.96084808, ACU_loss:7.84339230, Val_loss:12.92598023)\n",
      "epoch (1040 / 2000) (Train_loss:1.95773684, ACU_loss:7.83094738, Val_loss:12.87487927)\n",
      "epoch (1041 / 2000) (Train_loss:1.93722159, ACU_loss:7.74888636, Val_loss:12.81875386)\n",
      "epoch (1042 / 2000) (Train_loss:1.91297795, ACU_loss:7.65191181, Val_loss:12.77222197)\n",
      "epoch (1043 / 2000) (Train_loss:1.89725942, ACU_loss:7.58903767, Val_loss:12.73243526)\n",
      "epoch (1044 / 2000) (Train_loss:1.89016216, ACU_loss:7.56064863, Val_loss:12.69803284)\n",
      "epoch (1045 / 2000) (Train_loss:1.89046114, ACU_loss:7.56184454, Val_loss:12.67149892)\n",
      "epoch (1046 / 2000) (Train_loss:1.89814065, ACU_loss:7.59256258, Val_loss:12.64736328)\n",
      "epoch (1047 / 2000) (Train_loss:1.90678237, ACU_loss:7.62712947, Val_loss:12.61695098)\n",
      "epoch (1048 / 2000) (Train_loss:1.90693009, ACU_loss:7.62772038, Val_loss:12.57358599)\n",
      "epoch (1049 / 2000) (Train_loss:1.89334981, ACU_loss:7.57339922, Val_loss:12.52205195)\n",
      "epoch (1050 / 2000) (Train_loss:1.87269283, ACU_loss:7.49077133, Val_loss:12.47478943)\n",
      "epoch (1051 / 2000) (Train_loss:1.85585414, ACU_loss:7.42341654, Val_loss:12.43416689)\n",
      "epoch (1052 / 2000) (Train_loss:1.84610773, ACU_loss:7.38443091, Val_loss:12.39842900)\n",
      "epoch (1053 / 2000) (Train_loss:1.84284901, ACU_loss:7.37139606, Val_loss:12.36867194)\n",
      "epoch (1054 / 2000) (Train_loss:1.84570905, ACU_loss:7.38283621, Val_loss:12.34265230)\n",
      "epoch (1055 / 2000) (Train_loss:1.85180403, ACU_loss:7.40721611, Val_loss:12.31556405)\n",
      "epoch (1056 / 2000) (Train_loss:1.85561784, ACU_loss:7.42247135, Val_loss:12.28173163)\n",
      "epoch (1057 / 2000) (Train_loss:1.85136025, ACU_loss:7.40544101, Val_loss:12.23855793)\n",
      "epoch (1058 / 2000) (Train_loss:1.83792016, ACU_loss:7.35168064, Val_loss:12.19214823)\n",
      "epoch (1059 / 2000) (Train_loss:1.82150709, ACU_loss:7.28602834, Val_loss:12.14915975)\n",
      "epoch (1060 / 2000) (Train_loss:1.80814632, ACU_loss:7.23258526, Val_loss:12.11077552)\n",
      "epoch (1061 / 2000) (Train_loss:1.79999397, ACU_loss:7.19997589, Val_loss:12.07715174)\n",
      "epoch (1062 / 2000) (Train_loss:1.79719454, ACU_loss:7.18877818, Val_loss:12.04783041)\n",
      "epoch (1063 / 2000) (Train_loss:1.79880628, ACU_loss:7.19522514, Val_loss:12.02078134)\n",
      "epoch (1064 / 2000) (Train_loss:1.80247570, ACU_loss:7.20990282, Val_loss:11.99295788)\n",
      "epoch (1065 / 2000) (Train_loss:1.80453593, ACU_loss:7.21814371, Val_loss:11.96018634)\n",
      "epoch (1066 / 2000) (Train_loss:1.80091764, ACU_loss:7.20367054, Val_loss:11.92088534)\n",
      "epoch (1067 / 2000) (Train_loss:1.79077147, ACU_loss:7.16308589, Val_loss:11.87843583)\n",
      "epoch (1068 / 2000) (Train_loss:1.77744557, ACU_loss:7.10978226, Val_loss:11.83719955)\n",
      "epoch (1069 / 2000) (Train_loss:1.76514759, ACU_loss:7.06059037, Val_loss:11.79949576)\n",
      "epoch (1070 / 2000) (Train_loss:1.75652028, ACU_loss:7.02608112, Val_loss:11.76587609)\n",
      "epoch (1071 / 2000) (Train_loss:1.75224733, ACU_loss:7.00898932, Val_loss:11.73584963)\n",
      "epoch (1072 / 2000) (Train_loss:1.75179086, ACU_loss:7.00716344, Val_loss:11.70824140)\n",
      "epoch (1073 / 2000) (Train_loss:1.75373607, ACU_loss:7.01494427, Val_loss:11.68090767)\n",
      "epoch (1074 / 2000) (Train_loss:1.75554865, ACU_loss:7.02219461, Val_loss:11.65077874)\n",
      "epoch (1075 / 2000) (Train_loss:1.75409283, ACU_loss:7.01637130, Val_loss:11.61582027)\n",
      "epoch (1076 / 2000) (Train_loss:1.74761016, ACU_loss:6.99044064, Val_loss:11.57684369)\n",
      "epoch (1077 / 2000) (Train_loss:1.73706930, ACU_loss:6.94827721, Val_loss:11.53691753)\n",
      "epoch (1078 / 2000) (Train_loss:1.72543978, ACU_loss:6.90175913, Val_loss:11.49902147)\n",
      "epoch (1079 / 2000) (Train_loss:1.71568247, ACU_loss:6.86272988, Val_loss:11.46451528)\n",
      "epoch (1080 / 2000) (Train_loss:1.70935127, ACU_loss:6.83740510, Val_loss:11.43349748)\n",
      "epoch (1081 / 2000) (Train_loss:1.70666471, ACU_loss:6.82665884, Val_loss:11.40530378)\n",
      "epoch (1082 / 2000) (Train_loss:1.70691670, ACU_loss:6.82766681, Val_loss:11.37850226)\n",
      "epoch (1083 / 2000) (Train_loss:1.70848318, ACU_loss:6.83393270, Val_loss:11.35083617)\n",
      "epoch (1084 / 2000) (Train_loss:1.70891504, ACU_loss:6.83566014, Val_loss:11.31989553)\n",
      "epoch (1085 / 2000) (Train_loss:1.70585041, ACU_loss:6.82340166, Val_loss:11.28467693)\n",
      "epoch (1086 / 2000) (Train_loss:1.69846739, ACU_loss:6.79386957, Val_loss:11.24655571)\n",
      "epoch (1087 / 2000) (Train_loss:1.68813833, ACU_loss:6.75255332, Val_loss:11.20839589)\n",
      "epoch (1088 / 2000) (Train_loss:1.67756910, ACU_loss:6.71027640, Val_loss:11.17259907)\n",
      "epoch (1089 / 2000) (Train_loss:1.66916313, ACU_loss:6.67665252, Val_loss:11.14016383)\n",
      "epoch (1090 / 2000) (Train_loss:1.66407644, ACU_loss:6.65630575, Val_loss:11.11098431)\n",
      "epoch (1091 / 2000) (Train_loss:1.66233126, ACU_loss:6.64932503, Val_loss:11.08421112)\n",
      "epoch (1092 / 2000) (Train_loss:1.66306565, ACU_loss:6.65226261, Val_loss:11.05822422)\n",
      "epoch (1093 / 2000) (Train_loss:1.66450778, ACU_loss:6.65803114, Val_loss:11.03070736)\n",
      "epoch (1094 / 2000) (Train_loss:1.66425330, ACU_loss:6.65701322, Val_loss:10.99953180)\n",
      "epoch (1095 / 2000) (Train_loss:1.66028408, ACU_loss:6.64113630, Val_loss:10.96418492)\n",
      "epoch (1096 / 2000) (Train_loss:1.65221454, ACU_loss:6.60885818, Val_loss:10.92645228)\n",
      "epoch (1097 / 2000) (Train_loss:1.64172185, ACU_loss:6.56688738, Val_loss:10.88929347)\n",
      "epoch (1098 / 2000) (Train_loss:1.63154378, ACU_loss:6.52617512, Val_loss:10.85492379)\n",
      "epoch (1099 / 2000) (Train_loss:1.62388067, ACU_loss:6.49552268, Val_loss:10.82409950)\n",
      "epoch (1100 / 2000) (Train_loss:1.61965801, ACU_loss:6.47863206, Val_loss:10.79651819)\n",
      "epoch (1101 / 2000) (Train_loss:1.61872080, ACU_loss:6.47488320, Val_loss:10.77114090)\n",
      "epoch (1102 / 2000) (Train_loss:1.62001047, ACU_loss:6.48004189, Val_loss:10.74613594)\n",
      "epoch (1103 / 2000) (Train_loss:1.62155829, ACU_loss:6.48623314, Val_loss:10.71905931)\n",
      "epoch (1104 / 2000) (Train_loss:1.62091080, ACU_loss:6.48364318, Val_loss:10.68787940)\n",
      "epoch (1105 / 2000) (Train_loss:1.61621711, ACU_loss:6.46486845, Val_loss:10.65243851)\n",
      "epoch (1106 / 2000) (Train_loss:1.60743029, ACU_loss:6.42972115, Val_loss:10.61494811)\n",
      "epoch (1107 / 2000) (Train_loss:1.59655664, ACU_loss:6.38622655, Val_loss:10.57853451)\n",
      "epoch (1108 / 2000) (Train_loss:1.58642177, ACU_loss:6.34568707, Val_loss:10.54526283)\n",
      "epoch (1109 / 2000) (Train_loss:1.57908123, ACU_loss:6.31632494, Val_loss:10.51563421)\n",
      "epoch (1110 / 2000) (Train_loss:1.57525207, ACU_loss:6.30100829, Val_loss:10.48914110)\n",
      "epoch (1111 / 2000) (Train_loss:1.57458640, ACU_loss:6.29834561, Val_loss:10.46463460)\n",
      "epoch (1112 / 2000) (Train_loss:1.57587769, ACU_loss:6.30351076, Val_loss:10.44030901)\n",
      "epoch (1113 / 2000) (Train_loss:1.57717111, ACU_loss:6.30868445, Val_loss:10.41392704)\n",
      "epoch (1114 / 2000) (Train_loss:1.57626115, ACU_loss:6.30504462, Val_loss:10.38374513)\n",
      "epoch (1115 / 2000) (Train_loss:1.57162010, ACU_loss:6.28648041, Val_loss:10.34970151)\n",
      "epoch (1116 / 2000) (Train_loss:1.56332700, ACU_loss:6.25330802, Val_loss:10.31372276)\n",
      "epoch (1117 / 2000) (Train_loss:1.55311854, ACU_loss:6.21247416, Val_loss:10.27847454)\n",
      "epoch (1118 / 2000) (Train_loss:1.54334581, ACU_loss:6.17338324, Val_loss:10.24575199)\n",
      "epoch (1119 / 2000) (Train_loss:1.53576640, ACU_loss:6.14306558, Val_loss:10.21601696)\n",
      "epoch (1120 / 2000) (Train_loss:1.53103832, ACU_loss:6.12415328, Val_loss:10.18882731)\n",
      "epoch (1121 / 2000) (Train_loss:1.52888762, ACU_loss:6.11555048, Val_loss:10.16328991)\n",
      "epoch (1122 / 2000) (Train_loss:1.52838613, ACU_loss:6.11354451, Val_loss:10.13823223)\n",
      "epoch (1123 / 2000) (Train_loss:1.52821413, ACU_loss:6.11285650, Val_loss:10.11236132)\n",
      "epoch (1124 / 2000) (Train_loss:1.52703595, ACU_loss:6.10814381, Val_loss:10.08463514)\n",
      "epoch (1125 / 2000) (Train_loss:1.52389869, ACU_loss:6.09559475, Val_loss:10.05470186)\n",
      "epoch (1126 / 2000) (Train_loss:1.51860268, ACU_loss:6.07441070, Val_loss:10.02309962)\n",
      "epoch (1127 / 2000) (Train_loss:1.51170819, ACU_loss:6.04683277, Val_loss:9.99093228)\n",
      "epoch (1128 / 2000) (Train_loss:1.50417872, ACU_loss:6.01671486, Val_loss:9.95927531)\n",
      "epoch (1129 / 2000) (Train_loss:1.49696966, ACU_loss:5.98787865, Val_loss:9.92876430)\n",
      "epoch (1130 / 2000) (Train_loss:1.49070965, ACU_loss:5.96283862, Val_loss:9.89953091)\n",
      "epoch (1131 / 2000) (Train_loss:1.48563779, ACU_loss:5.94255115, Val_loss:9.87138230)\n",
      "epoch (1132 / 2000) (Train_loss:1.48165192, ACU_loss:5.92660767, Val_loss:9.84398136)\n",
      "epoch (1133 / 2000) (Train_loss:1.47841469, ACU_loss:5.91365875, Val_loss:9.81698476)\n",
      "epoch (1134 / 2000) (Train_loss:1.47553384, ACU_loss:5.90213538, Val_loss:9.79011168)\n",
      "epoch (1135 / 2000) (Train_loss:1.47267307, ACU_loss:5.89069226, Val_loss:9.76317735)\n",
      "epoch (1136 / 2000) (Train_loss:1.46963680, ACU_loss:5.87854718, Val_loss:9.73611989)\n",
      "epoch (1137 / 2000) (Train_loss:1.46639563, ACU_loss:5.86558253, Val_loss:9.70897967)\n",
      "epoch (1138 / 2000) (Train_loss:1.46304017, ACU_loss:5.85216067, Val_loss:9.68185865)\n",
      "epoch (1139 / 2000) (Train_loss:1.45972526, ACU_loss:5.83890102, Val_loss:9.65486785)\n",
      "epoch (1140 / 2000) (Train_loss:1.45662019, ACU_loss:5.82648075, Val_loss:9.62808596)\n",
      "epoch (1141 / 2000) (Train_loss:1.45388104, ACU_loss:5.81552415, Val_loss:9.60153055)\n",
      "epoch (1142 / 2000) (Train_loss:1.45163105, ACU_loss:5.80652421, Val_loss:9.57512546)\n",
      "epoch (1143 / 2000) (Train_loss:1.44992353, ACU_loss:5.79969412, Val_loss:9.54864816)\n",
      "epoch (1144 / 2000) (Train_loss:1.44864753, ACU_loss:5.79459013, Val_loss:9.52167411)\n",
      "epoch (1145 / 2000) (Train_loss:1.44738447, ACU_loss:5.78953787, Val_loss:9.49359857)\n",
      "epoch (1146 / 2000) (Train_loss:1.44529435, ACU_loss:5.78117739, Val_loss:9.46385450)\n",
      "epoch (1147 / 2000) (Train_loss:1.44123095, ACU_loss:5.76492378, Val_loss:9.43235652)\n",
      "epoch (1148 / 2000) (Train_loss:1.43428383, ACU_loss:5.73713531, Val_loss:9.39987366)\n",
      "epoch (1149 / 2000) (Train_loss:1.42454667, ACU_loss:5.69818668, Val_loss:9.36783974)\n",
      "epoch (1150 / 2000) (Train_loss:1.41340791, ACU_loss:5.65363162, Val_loss:9.33761100)\n",
      "epoch (1151 / 2000) (Train_loss:1.40293078, ACU_loss:5.61172314, Val_loss:9.30988043)\n",
      "epoch (1152 / 2000) (Train_loss:1.39486223, ACU_loss:5.57944891, Val_loss:9.28469489)\n",
      "epoch (1153 / 2000) (Train_loss:1.39009253, ACU_loss:5.56037014, Val_loss:9.26173868)\n",
      "epoch (1154 / 2000) (Train_loss:1.38872239, ACU_loss:5.55488954, Val_loss:9.24047371)\n",
      "epoch (1155 / 2000) (Train_loss:1.39038410, ACU_loss:5.56153640, Val_loss:9.22005568)\n",
      "epoch (1156 / 2000) (Train_loss:1.39436521, ACU_loss:5.57746082, Val_loss:9.19905332)\n",
      "epoch (1157 / 2000) (Train_loss:1.39918370, ACU_loss:5.59673481, Val_loss:9.17531218)\n",
      "epoch (1158 / 2000) (Train_loss:1.40200461, ACU_loss:5.60801846, Val_loss:9.14678712)\n",
      "epoch (1159 / 2000) (Train_loss:1.39924082, ACU_loss:5.59696328, Val_loss:9.11342455)\n",
      "epoch (1160 / 2000) (Train_loss:1.38890243, ACU_loss:5.55560973, Val_loss:9.07812186)\n",
      "epoch (1161 / 2000) (Train_loss:1.37278202, ACU_loss:5.49112809, Val_loss:9.04479971)\n",
      "epoch (1162 / 2000) (Train_loss:1.35569962, ACU_loss:5.42279849, Val_loss:9.01554234)\n",
      "epoch (1163 / 2000) (Train_loss:1.34219875, ACU_loss:5.36879500, Val_loss:8.99040936)\n",
      "epoch (1164 / 2000) (Train_loss:1.33451778, ACU_loss:5.33807111, Val_loss:8.96896868)\n",
      "epoch (1165 / 2000) (Train_loss:1.33296879, ACU_loss:5.33187518, Val_loss:8.95072971)\n",
      "epoch (1166 / 2000) (Train_loss:1.33687794, ACU_loss:5.34751176, Val_loss:8.93466198)\n",
      "epoch (1167 / 2000) (Train_loss:1.34514756, ACU_loss:5.38059022, Val_loss:8.91850849)\n",
      "epoch (1168 / 2000) (Train_loss:1.35549085, ACU_loss:5.42196341, Val_loss:8.89837934)\n",
      "epoch (1169 / 2000) (Train_loss:1.36296186, ACU_loss:5.45184744, Val_loss:8.87060260)\n",
      "epoch (1170 / 2000) (Train_loss:1.36153537, ACU_loss:5.44614149, Val_loss:8.83531387)\n",
      "epoch (1171 / 2000) (Train_loss:1.34863731, ACU_loss:5.39454924, Val_loss:8.79750444)\n",
      "epoch (1172 / 2000) (Train_loss:1.32791432, ACU_loss:5.31165729, Val_loss:8.76298891)\n",
      "epoch (1173 / 2000) (Train_loss:1.30695845, ACU_loss:5.22783382, Val_loss:8.73378767)\n",
      "epoch (1174 / 2000) (Train_loss:1.29153511, ACU_loss:5.16614042, Val_loss:8.70922513)\n",
      "epoch (1175 / 2000) (Train_loss:1.28367722, ACU_loss:5.13470889, Val_loss:8.68887689)\n",
      "epoch (1176 / 2000) (Train_loss:1.28326992, ACU_loss:5.13307969, Val_loss:8.67238986)\n",
      "epoch (1177 / 2000) (Train_loss:1.28917103, ACU_loss:5.15668411, Val_loss:8.65836401)\n",
      "epoch (1178 / 2000) (Train_loss:1.29970785, ACU_loss:5.19883140, Val_loss:8.64358082)\n",
      "epoch (1179 / 2000) (Train_loss:1.31146225, ACU_loss:5.24584900, Val_loss:8.62348182)\n",
      "epoch (1180 / 2000) (Train_loss:1.31843795, ACU_loss:5.27375180, Val_loss:8.59516970)\n",
      "epoch (1181 / 2000) (Train_loss:1.31530650, ACU_loss:5.26122601, Val_loss:8.56000589)\n",
      "epoch (1182 / 2000) (Train_loss:1.30102772, ACU_loss:5.20411087, Val_loss:8.52329023)\n",
      "epoch (1183 / 2000) (Train_loss:1.28022559, ACU_loss:5.12090236, Val_loss:8.49000632)\n",
      "epoch (1184 / 2000) (Train_loss:1.26021102, ACU_loss:5.04084409, Val_loss:8.46146389)\n",
      "epoch (1185 / 2000) (Train_loss:1.24578651, ACU_loss:4.98314605, Val_loss:8.43714065)\n",
      "epoch (1186 / 2000) (Train_loss:1.23853657, ACU_loss:4.95414627, Val_loss:8.41678826)\n",
      "epoch (1187 / 2000) (Train_loss:1.23820436, ACU_loss:4.95281743, Val_loss:8.39998383)\n",
      "epoch (1188 / 2000) (Train_loss:1.24349551, ACU_loss:4.97398202, Val_loss:8.38520541)\n",
      "epoch (1189 / 2000) (Train_loss:1.25245804, ACU_loss:5.00983215, Val_loss:8.36954837)\n",
      "epoch (1190 / 2000) (Train_loss:1.26188268, ACU_loss:5.04753072, Val_loss:8.34972945)\n",
      "epoch (1191 / 2000) (Train_loss:1.26743032, ACU_loss:5.06972126, Val_loss:8.32384055)\n",
      "epoch (1192 / 2000) (Train_loss:1.26552201, ACU_loss:5.06208804, Val_loss:8.29251450)\n",
      "epoch (1193 / 2000) (Train_loss:1.25504610, ACU_loss:5.02018442, Val_loss:8.25894085)\n",
      "epoch (1194 / 2000) (Train_loss:1.23854841, ACU_loss:4.95419365, Val_loss:8.22675093)\n",
      "epoch (1195 / 2000) (Train_loss:1.22099707, ACU_loss:4.88398827, Val_loss:8.19777156)\n",
      "epoch (1196 / 2000) (Train_loss:1.20658716, ACU_loss:4.82634862, Val_loss:8.17222214)\n",
      "epoch (1197 / 2000) (Train_loss:1.19742394, ACU_loss:4.78969575, Val_loss:8.14996197)\n",
      "epoch (1198 / 2000) (Train_loss:1.19391321, ACU_loss:4.77565284, Val_loss:8.13075641)\n",
      "epoch (1199 / 2000) (Train_loss:1.19532770, ACU_loss:4.78131078, Val_loss:8.11382788)\n",
      "epoch (1200 / 2000) (Train_loss:1.20031307, ACU_loss:4.80125227, Val_loss:8.09764078)\n",
      "epoch (1201 / 2000) (Train_loss:1.20703965, ACU_loss:4.82815861, Val_loss:8.08019256)\n",
      "epoch (1202 / 2000) (Train_loss:1.21315436, ACU_loss:4.85261744, Val_loss:8.05966361)\n",
      "epoch (1203 / 2000) (Train_loss:1.21611581, ACU_loss:4.86446323, Val_loss:8.03502198)\n",
      "epoch (1204 / 2000) (Train_loss:1.21381581, ACU_loss:4.85526323, Val_loss:8.00656906)\n",
      "epoch (1205 / 2000) (Train_loss:1.20545610, ACU_loss:4.82182439, Val_loss:7.97604134)\n",
      "epoch (1206 / 2000) (Train_loss:1.19234286, ACU_loss:4.76937146, Val_loss:7.94572579)\n",
      "epoch (1207 / 2000) (Train_loss:1.17743225, ACU_loss:4.70972900, Val_loss:7.91726942)\n",
      "epoch (1208 / 2000) (Train_loss:1.16385337, ACU_loss:4.65541348, Val_loss:7.89133044)\n",
      "epoch (1209 / 2000) (Train_loss:1.15377887, ACU_loss:4.61511549, Val_loss:7.86802886)\n",
      "epoch (1210 / 2000) (Train_loss:1.14808017, ACU_loss:4.59232067, Val_loss:7.84729544)\n",
      "epoch (1211 / 2000) (Train_loss:1.14656013, ACU_loss:4.58624053, Val_loss:7.82881455)\n",
      "epoch (1212 / 2000) (Train_loss:1.14843355, ACU_loss:4.59373418, Val_loss:7.81188292)\n",
      "epoch (1213 / 2000) (Train_loss:1.15267739, ACU_loss:4.61070956, Val_loss:7.79543502)\n",
      "epoch (1214 / 2000) (Train_loss:1.15809581, ACU_loss:4.63238322, Val_loss:7.77821225)\n",
      "epoch (1215 / 2000) (Train_loss:1.16325679, ACU_loss:4.65302718, Val_loss:7.75893739)\n",
      "epoch (1216 / 2000) (Train_loss:1.16647660, ACU_loss:4.66590638, Val_loss:7.73654987)\n",
      "epoch (1217 / 2000) (Train_loss:1.16595056, ACU_loss:4.66380222, Val_loss:7.71064662)\n",
      "epoch (1218 / 2000) (Train_loss:1.16028422, ACU_loss:4.64113687, Val_loss:7.68194178)\n",
      "epoch (1219 / 2000) (Train_loss:1.14938404, ACU_loss:4.59753615, Val_loss:7.65217270)\n",
      "epoch (1220 / 2000) (Train_loss:1.13496316, ACU_loss:4.53985264, Val_loss:7.62323375)\n",
      "epoch (1221 / 2000) (Train_loss:1.11994472, ACU_loss:4.47977887, Val_loss:7.59629294)\n",
      "epoch (1222 / 2000) (Train_loss:1.10710844, ACU_loss:4.42843377, Val_loss:7.57171960)\n",
      "epoch (1223 / 2000) (Train_loss:1.09808368, ACU_loss:4.39233472, Val_loss:7.54954987)\n",
      "epoch (1224 / 2000) (Train_loss:1.09323199, ACU_loss:4.37292797, Val_loss:7.52972809)\n",
      "epoch (1225 / 2000) (Train_loss:1.09210646, ACU_loss:4.36842584, Val_loss:7.51202823)\n",
      "epoch (1226 / 2000) (Train_loss:1.09397894, ACU_loss:4.37591575, Val_loss:7.49598611)\n",
      "epoch (1227 / 2000) (Train_loss:1.09814843, ACU_loss:4.39259372, Val_loss:7.48093670)\n",
      "epoch (1228 / 2000) (Train_loss:1.10397742, ACU_loss:4.41590967, Val_loss:7.46604386)\n",
      "epoch (1229 / 2000) (Train_loss:1.11073146, ACU_loss:4.44292586, Val_loss:7.45022891)\n",
      "epoch (1230 / 2000) (Train_loss:1.11729727, ACU_loss:4.46918908, Val_loss:7.43206472)\n",
      "epoch (1231 / 2000) (Train_loss:1.12180516, ACU_loss:4.48722064, Val_loss:7.40995313)\n",
      "epoch (1232 / 2000) (Train_loss:1.12152208, ACU_loss:4.48608831, Val_loss:7.38302365)\n",
      "epoch (1233 / 2000) (Train_loss:1.11390319, ACU_loss:4.45561274, Val_loss:7.35239764)\n",
      "epoch (1234 / 2000) (Train_loss:1.09882055, ACU_loss:4.39528220, Val_loss:7.32103705)\n",
      "epoch (1235 / 2000) (Train_loss:1.07954078, ACU_loss:4.31816312, Val_loss:7.29162547)\n",
      "epoch (1236 / 2000) (Train_loss:1.06071572, ACU_loss:4.24286290, Val_loss:7.26508155)\n",
      "epoch (1237 / 2000) (Train_loss:1.04579602, ACU_loss:4.18318408, Val_loss:7.24119491)\n",
      "epoch (1238 / 2000) (Train_loss:1.03614677, ACU_loss:4.14458708, Val_loss:7.21972037)\n",
      "epoch (1239 / 2000) (Train_loss:1.03143241, ACU_loss:4.12572963, Val_loss:7.20058471)\n",
      "epoch (1240 / 2000) (Train_loss:1.03053330, ACU_loss:4.12213320, Val_loss:7.18361052)\n",
      "epoch (1241 / 2000) (Train_loss:1.03235842, ACU_loss:4.12943368, Val_loss:7.16844635)\n",
      "epoch (1242 / 2000) (Train_loss:1.03621672, ACU_loss:4.14486690, Val_loss:7.15469802)\n",
      "epoch (1243 / 2000) (Train_loss:1.04187625, ACU_loss:4.16750501, Val_loss:7.14200416)\n",
      "epoch (1244 / 2000) (Train_loss:1.04935083, ACU_loss:4.19740330, Val_loss:7.12995685)\n",
      "epoch (1245 / 2000) (Train_loss:1.05864871, ACU_loss:4.23459484, Val_loss:7.11776261)\n",
      "epoch (1246 / 2000) (Train_loss:1.06929370, ACU_loss:4.27717480, Val_loss:7.10352360)\n",
      "epoch (1247 / 2000) (Train_loss:1.07901114, ACU_loss:4.31604456, Val_loss:7.08382448)\n",
      "epoch (1248 / 2000) (Train_loss:1.08249749, ACU_loss:4.32998994, Val_loss:7.05584323)\n",
      "epoch (1249 / 2000) (Train_loss:1.07391607, ACU_loss:4.29566428, Val_loss:7.02155061)\n",
      "epoch (1250 / 2000) (Train_loss:1.05322105, ACU_loss:4.21288419, Val_loss:6.98700922)\n",
      "epoch (1251 / 2000) (Train_loss:1.02703071, ACU_loss:4.10812283, Val_loss:6.95659862)\n",
      "epoch (1252 / 2000) (Train_loss:1.00275377, ACU_loss:4.01101507, Val_loss:6.93065162)\n",
      "epoch (1253 / 2000) (Train_loss:0.98485064, ACU_loss:3.93940256, Val_loss:6.90765327)\n",
      "epoch (1254 / 2000) (Train_loss:0.97434299, ACU_loss:3.89737195, Val_loss:6.88669081)\n",
      "epoch (1255 / 2000) (Train_loss:0.96974161, ACU_loss:3.87896646, Val_loss:6.86764797)\n",
      "epoch (1256 / 2000) (Train_loss:0.96872195, ACU_loss:3.87488781, Val_loss:6.85042442)\n",
      "epoch (1257 / 2000) (Train_loss:0.96964658, ACU_loss:3.87858631, Val_loss:6.83460472)\n",
      "epoch (1258 / 2000) (Train_loss:0.97155036, ACU_loss:3.88620143, Val_loss:6.81974728)\n",
      "epoch (1259 / 2000) (Train_loss:0.97410139, ACU_loss:3.89640558, Val_loss:6.80564975)\n",
      "epoch (1260 / 2000) (Train_loss:0.97752217, ACU_loss:3.91008869, Val_loss:6.79230959)\n",
      "epoch (1261 / 2000) (Train_loss:0.98214038, ACU_loss:3.92856153, Val_loss:6.77993481)\n",
      "epoch (1262 / 2000) (Train_loss:0.98854412, ACU_loss:3.95417650, Val_loss:6.76880660)\n",
      "epoch (1263 / 2000) (Train_loss:0.99757109, ACU_loss:3.99028436, Val_loss:6.75856116)\n",
      "epoch (1264 / 2000) (Train_loss:1.00922605, ACU_loss:4.03690421, Val_loss:6.74712216)\n",
      "epoch (1265 / 2000) (Train_loss:1.02094018, ACU_loss:4.08376073, Val_loss:6.73041061)\n",
      "epoch (1266 / 2000) (Train_loss:1.02685310, ACU_loss:4.10741240, Val_loss:6.70482484)\n",
      "epoch (1267 / 2000) (Train_loss:1.02071331, ACU_loss:4.08285325, Val_loss:6.67156511)\n",
      "epoch (1268 / 2000) (Train_loss:1.00153200, ACU_loss:4.00612799, Val_loss:6.63680774)\n",
      "epoch (1269 / 2000) (Train_loss:0.97518784, ACU_loss:3.90075137, Val_loss:6.60631343)\n",
      "epoch (1270 / 2000) (Train_loss:0.94974989, ACU_loss:3.79899955, Val_loss:6.58114300)\n",
      "epoch (1271 / 2000) (Train_loss:0.93019391, ACU_loss:3.72077563, Val_loss:6.55937367)\n",
      "epoch (1272 / 2000) (Train_loss:0.91773777, ACU_loss:3.67095108, Val_loss:6.53941554)\n",
      "epoch (1273 / 2000) (Train_loss:0.91132605, ACU_loss:3.64530418, Val_loss:6.52058913)\n",
      "epoch (1274 / 2000) (Train_loss:0.90860260, ACU_loss:3.63441040, Val_loss:6.50271426)\n",
      "epoch (1275 / 2000) (Train_loss:0.90757362, ACU_loss:3.63029449, Val_loss:6.48565066)\n",
      "epoch (1276 / 2000) (Train_loss:0.90723930, ACU_loss:3.62895719, Val_loss:6.46902601)\n",
      "epoch (1277 / 2000) (Train_loss:0.90691558, ACU_loss:3.62766231, Val_loss:6.45256834)\n",
      "epoch (1278 / 2000) (Train_loss:0.90633446, ACU_loss:3.62533785, Val_loss:6.43628226)\n",
      "epoch (1279 / 2000) (Train_loss:0.90566667, ACU_loss:3.62266667, Val_loss:6.42019645)\n",
      "epoch (1280 / 2000) (Train_loss:0.90499259, ACU_loss:3.61997037, Val_loss:6.40431492)\n",
      "epoch (1281 / 2000) (Train_loss:0.90435389, ACU_loss:3.61741554, Val_loss:6.38866101)\n",
      "epoch (1282 / 2000) (Train_loss:0.90388250, ACU_loss:3.61553000, Val_loss:6.37316606)\n",
      "epoch (1283 / 2000) (Train_loss:0.90358189, ACU_loss:3.61432758, Val_loss:6.35770080)\n",
      "epoch (1284 / 2000) (Train_loss:0.90332778, ACU_loss:3.61331111, Val_loss:6.34227793)\n",
      "epoch (1285 / 2000) (Train_loss:0.90320255, ACU_loss:3.61281021, Val_loss:6.32712484)\n",
      "epoch (1286 / 2000) (Train_loss:0.90358277, ACU_loss:3.61433110, Val_loss:6.31251254)\n",
      "epoch (1287 / 2000) (Train_loss:0.90488624, ACU_loss:3.61954497, Val_loss:6.29864152)\n",
      "epoch (1288 / 2000) (Train_loss:0.90746541, ACU_loss:3.62986165, Val_loss:6.28570209)\n",
      "epoch (1289 / 2000) (Train_loss:0.91176994, ACU_loss:3.64707978, Val_loss:6.27388505)\n",
      "epoch (1290 / 2000) (Train_loss:0.91837719, ACU_loss:3.67350875, Val_loss:6.26302173)\n",
      "epoch (1291 / 2000) (Train_loss:0.92739323, ACU_loss:3.70957290, Val_loss:6.25176021)\n",
      "epoch (1292 / 2000) (Train_loss:0.93712196, ACU_loss:3.74848783, Val_loss:6.23697784)\n",
      "epoch (1293 / 2000) (Train_loss:0.94305035, ACU_loss:3.77220142, Val_loss:6.21529581)\n",
      "epoch (1294 / 2000) (Train_loss:0.93971883, ACU_loss:3.75887530, Val_loss:6.18655684)\n",
      "epoch (1295 / 2000) (Train_loss:0.92514909, ACU_loss:3.70059638, Val_loss:6.15489470)\n",
      "epoch (1296 / 2000) (Train_loss:0.90270201, ACU_loss:3.61080803, Val_loss:6.12588794)\n",
      "epoch (1297 / 2000) (Train_loss:0.87909217, ACU_loss:3.51636867, Val_loss:6.10198634)\n",
      "epoch (1298 / 2000) (Train_loss:0.85938162, ACU_loss:3.43752648, Val_loss:6.08218130)\n",
      "epoch (1299 / 2000) (Train_loss:0.84521282, ACU_loss:3.38085128, Val_loss:6.06464435)\n",
      "epoch (1300 / 2000) (Train_loss:0.83625845, ACU_loss:3.34503381, Val_loss:6.04806158)\n",
      "epoch (1301 / 2000) (Train_loss:0.83104705, ACU_loss:3.32418822, Val_loss:6.03173988)\n",
      "epoch (1302 / 2000) (Train_loss:0.82788840, ACU_loss:3.31155362, Val_loss:6.01543983)\n",
      "epoch (1303 / 2000) (Train_loss:0.82563924, ACU_loss:3.30255696, Val_loss:5.99921119)\n",
      "epoch (1304 / 2000) (Train_loss:0.82388776, ACU_loss:3.29555105, Val_loss:5.98300832)\n",
      "epoch (1305 / 2000) (Train_loss:0.82242067, ACU_loss:3.28968266, Val_loss:5.96677345)\n",
      "epoch (1306 / 2000) (Train_loss:0.82104257, ACU_loss:3.28417028, Val_loss:5.95063760)\n",
      "epoch (1307 / 2000) (Train_loss:0.81978234, ACU_loss:3.27912938, Val_loss:5.93482100)\n",
      "epoch (1308 / 2000) (Train_loss:0.81891241, ACU_loss:3.27564966, Val_loss:5.91934211)\n",
      "epoch (1309 / 2000) (Train_loss:0.81855353, ACU_loss:3.27421412, Val_loss:5.90407103)\n",
      "epoch (1310 / 2000) (Train_loss:0.81858882, ACU_loss:3.27435529, Val_loss:5.88891712)\n",
      "epoch (1311 / 2000) (Train_loss:0.81885843, ACU_loss:3.27543370, Val_loss:5.87380513)\n",
      "epoch (1312 / 2000) (Train_loss:0.81917828, ACU_loss:3.27671314, Val_loss:5.85862866)\n",
      "epoch (1313 / 2000) (Train_loss:0.81928016, ACU_loss:3.27712064, Val_loss:5.84331833)\n",
      "epoch (1314 / 2000) (Train_loss:0.81896365, ACU_loss:3.27585460, Val_loss:5.82788912)\n",
      "epoch (1315 / 2000) (Train_loss:0.81817563, ACU_loss:3.27270254, Val_loss:5.81239057)\n",
      "epoch (1316 / 2000) (Train_loss:0.81692723, ACU_loss:3.26770890, Val_loss:5.79694535)\n",
      "epoch (1317 / 2000) (Train_loss:0.81538825, ACU_loss:3.26155299, Val_loss:5.78171410)\n",
      "epoch (1318 / 2000) (Train_loss:0.81384805, ACU_loss:3.25539220, Val_loss:5.76680603)\n",
      "epoch (1319 / 2000) (Train_loss:0.81249932, ACU_loss:3.24999726, Val_loss:5.75229291)\n",
      "epoch (1320 / 2000) (Train_loss:0.81144617, ACU_loss:3.24578468, Val_loss:5.73824377)\n",
      "epoch (1321 / 2000) (Train_loss:0.81078798, ACU_loss:3.24315192, Val_loss:5.72468452)\n",
      "epoch (1322 / 2000) (Train_loss:0.81053163, ACU_loss:3.24212653, Val_loss:5.71158772)\n",
      "epoch (1323 / 2000) (Train_loss:0.81057765, ACU_loss:3.24231059, Val_loss:5.69890680)\n",
      "epoch (1324 / 2000) (Train_loss:0.81080335, ACU_loss:3.24321340, Val_loss:5.68656307)\n",
      "epoch (1325 / 2000) (Train_loss:0.81105765, ACU_loss:3.24423059, Val_loss:5.67443610)\n",
      "epoch (1326 / 2000) (Train_loss:0.81115147, ACU_loss:3.24460588, Val_loss:5.66238160)\n",
      "epoch (1327 / 2000) (Train_loss:0.81090097, ACU_loss:3.24360388, Val_loss:5.65024564)\n",
      "epoch (1328 / 2000) (Train_loss:0.81014917, ACU_loss:3.24059668, Val_loss:5.63787696)\n",
      "epoch (1329 / 2000) (Train_loss:0.80878769, ACU_loss:3.23515078, Val_loss:5.62515720)\n",
      "epoch (1330 / 2000) (Train_loss:0.80679347, ACU_loss:3.22717388, Val_loss:5.61201571)\n",
      "epoch (1331 / 2000) (Train_loss:0.80422590, ACU_loss:3.21690360, Val_loss:5.59843280)\n",
      "epoch (1332 / 2000) (Train_loss:0.80120636, ACU_loss:3.20482545, Val_loss:5.58443884)\n",
      "epoch (1333 / 2000) (Train_loss:0.79789188, ACU_loss:3.19156750, Val_loss:5.57009564)\n",
      "epoch (1334 / 2000) (Train_loss:0.79443007, ACU_loss:3.17772027, Val_loss:5.55547229)\n",
      "epoch (1335 / 2000) (Train_loss:0.79092297, ACU_loss:3.16369186, Val_loss:5.54063102)\n",
      "epoch (1336 / 2000) (Train_loss:0.78741798, ACU_loss:3.14967193, Val_loss:5.52562149)\n",
      "epoch (1337 / 2000) (Train_loss:0.78391379, ACU_loss:3.13565518, Val_loss:5.51048097)\n",
      "epoch (1338 / 2000) (Train_loss:0.78037822, ACU_loss:3.12151288, Val_loss:5.49524224)\n",
      "epoch (1339 / 2000) (Train_loss:0.77677261, ACU_loss:3.10709043, Val_loss:5.47994017)\n",
      "epoch (1340 / 2000) (Train_loss:0.77306871, ACU_loss:3.09227485, Val_loss:5.46461436)\n",
      "epoch (1341 / 2000) (Train_loss:0.76925834, ACU_loss:3.07703334, Val_loss:5.44930991)\n",
      "epoch (1342 / 2000) (Train_loss:0.76535746, ACU_loss:3.06142985, Val_loss:5.43407472)\n",
      "epoch (1343 / 2000) (Train_loss:0.76140274, ACU_loss:3.04561095, Val_loss:5.41895409)\n",
      "epoch (1344 / 2000) (Train_loss:0.75744400, ACU_loss:3.02977599, Val_loss:5.40398625)\n",
      "epoch (1345 / 2000) (Train_loss:0.75353613, ACU_loss:3.01414450, Val_loss:5.38919898)\n",
      "epoch (1346 / 2000) (Train_loss:0.74973044, ACU_loss:2.99892176, Val_loss:5.37460763)\n",
      "epoch (1347 / 2000) (Train_loss:0.74606837, ACU_loss:2.98427348, Val_loss:5.36021608)\n",
      "epoch (1348 / 2000) (Train_loss:0.74257836, ACU_loss:2.97031345, Val_loss:5.34601864)\n",
      "epoch (1349 / 2000) (Train_loss:0.73927499, ACU_loss:2.95709997, Val_loss:5.33200260)\n",
      "epoch (1350 / 2000) (Train_loss:0.73616048, ACU_loss:2.94464192, Val_loss:5.31815114)\n",
      "epoch (1351 / 2000) (Train_loss:0.73322744, ACU_loss:2.93290977, Val_loss:5.30444558)\n",
      "epoch (1352 / 2000) (Train_loss:0.73046183, ACU_loss:2.92184731, Val_loss:5.29086704)\n",
      "epoch (1353 / 2000) (Train_loss:0.72784583, ACU_loss:2.91138330, Val_loss:5.27739771)\n",
      "epoch (1354 / 2000) (Train_loss:0.72536033, ACU_loss:2.90144130, Val_loss:5.26402145)\n",
      "epoch (1355 / 2000) (Train_loss:0.72298664, ACU_loss:2.89194657, Val_loss:5.25072423)\n",
      "epoch (1356 / 2000) (Train_loss:0.72070779, ACU_loss:2.88283114, Val_loss:5.23749422)\n",
      "epoch (1357 / 2000) (Train_loss:0.71850917, ACU_loss:2.87403669, Val_loss:5.22432181)\n",
      "epoch (1358 / 2000) (Train_loss:0.71637889, ACU_loss:2.86551556, Val_loss:5.21119950)\n",
      "epoch (1359 / 2000) (Train_loss:0.71430773, ACU_loss:2.85723091, Val_loss:5.19812173)\n",
      "epoch (1360 / 2000) (Train_loss:0.71228898, ACU_loss:2.84915593, Val_loss:5.18508465)\n",
      "epoch (1361 / 2000) (Train_loss:0.71031817, ACU_loss:2.84127267, Val_loss:5.17208593)\n",
      "epoch (1362 / 2000) (Train_loss:0.70839268, ACU_loss:2.83357070, Val_loss:5.15912455)\n",
      "epoch (1363 / 2000) (Train_loss:0.70651143, ACU_loss:2.82604573, Val_loss:5.14620051)\n",
      "epoch (1364 / 2000) (Train_loss:0.70467453, ACU_loss:2.81869813, Val_loss:5.13331472)\n",
      "epoch (1365 / 2000) (Train_loss:0.70288295, ACU_loss:2.81153180, Val_loss:5.12046873)\n",
      "epoch (1366 / 2000) (Train_loss:0.70113826, ACU_loss:2.80455303, Val_loss:5.10766464)\n",
      "epoch (1367 / 2000) (Train_loss:0.69944240, ACU_loss:2.79776960, Val_loss:5.09490492)\n",
      "epoch (1368 / 2000) (Train_loss:0.69779753, ACU_loss:2.79119011, Val_loss:5.08219236)\n",
      "epoch (1369 / 2000) (Train_loss:0.69620586, ACU_loss:2.78482344, Val_loss:5.06952992)\n",
      "epoch (1370 / 2000) (Train_loss:0.69466958, ACU_loss:2.77867830, Val_loss:5.05692073)\n",
      "epoch (1371 / 2000) (Train_loss:0.69319074, ACU_loss:2.77276295, Val_loss:5.04436797)\n",
      "epoch (1372 / 2000) (Train_loss:0.69177122, ACU_loss:2.76708488, Val_loss:5.03187485)\n",
      "epoch (1373 / 2000) (Train_loss:0.69041263, ACU_loss:2.76165053, Val_loss:5.01944453)\n",
      "epoch (1374 / 2000) (Train_loss:0.68911626, ACU_loss:2.75646505, Val_loss:5.00708008)\n",
      "epoch (1375 / 2000) (Train_loss:0.68788297, ACU_loss:2.75153189, Val_loss:4.99478434)\n",
      "epoch (1376 / 2000) (Train_loss:0.68671311, ACU_loss:2.74685243, Val_loss:4.98255990)\n",
      "epoch (1377 / 2000) (Train_loss:0.68560637, ACU_loss:2.74242546, Val_loss:4.97040894)\n",
      "epoch (1378 / 2000) (Train_loss:0.68456164, ACU_loss:2.73824655, Val_loss:4.95833305)\n",
      "epoch (1379 / 2000) (Train_loss:0.68357684, ACU_loss:2.73430734, Val_loss:4.94633310)\n",
      "epoch (1380 / 2000) (Train_loss:0.68264868, ACU_loss:2.73059473, Val_loss:4.93440896)\n",
      "epoch (1381 / 2000) (Train_loss:0.68177250, ACU_loss:2.72708999, Val_loss:4.92255922)\n",
      "epoch (1382 / 2000) (Train_loss:0.68094197, ACU_loss:2.72376788, Val_loss:4.91078091)\n",
      "epoch (1383 / 2000) (Train_loss:0.68014894, ACU_loss:2.72059575, Val_loss:4.89906911)\n",
      "epoch (1384 / 2000) (Train_loss:0.67938319, ACU_loss:2.71753276, Val_loss:4.88741655)\n",
      "epoch (1385 / 2000) (Train_loss:0.67863231, ACU_loss:2.71452925, Val_loss:4.87581328)\n",
      "epoch (1386 / 2000) (Train_loss:0.67788159, ACU_loss:2.71152637, Val_loss:4.86424624)\n",
      "epoch (1387 / 2000) (Train_loss:0.67711399, ACU_loss:2.70845598, Val_loss:4.85269902)\n",
      "epoch (1388 / 2000) (Train_loss:0.67631027, ACU_loss:2.70524107, Val_loss:4.84115170)\n",
      "epoch (1389 / 2000) (Train_loss:0.67544914, ACU_loss:2.70179655, Val_loss:4.82958090)\n",
      "epoch (1390 / 2000) (Train_loss:0.67450763, ACU_loss:2.69803052, Val_loss:4.81796012)\n",
      "epoch (1391 / 2000) (Train_loss:0.67346154, ACU_loss:2.69384616, Val_loss:4.80626045)\n",
      "epoch (1392 / 2000) (Train_loss:0.67228601, ACU_loss:2.68914404, Val_loss:4.79445174)\n",
      "epoch (1393 / 2000) (Train_loss:0.67095628, ACU_loss:2.68382512, Val_loss:4.78250417)\n",
      "epoch (1394 / 2000) (Train_loss:0.66944861, ACU_loss:2.67779444, Val_loss:4.77039035)\n",
      "epoch (1395 / 2000) (Train_loss:0.66774143, ACU_loss:2.67096572, Val_loss:4.75808772)\n",
      "epoch (1396 / 2000) (Train_loss:0.66581675, ACU_loss:2.66326701, Val_loss:4.74558114)\n",
      "epoch (1397 / 2000) (Train_loss:0.66366183, ACU_loss:2.65464731, Val_loss:4.73286522)\n",
      "epoch (1398 / 2000) (Train_loss:0.66127098, ACU_loss:2.64508391, Val_loss:4.71994617)\n",
      "epoch (1399 / 2000) (Train_loss:0.65864739, ACU_loss:2.63458956, Val_loss:4.70684256)\n",
      "epoch (1400 / 2000) (Train_loss:0.65580450, ACU_loss:2.62321801, Val_loss:4.69358477)\n",
      "epoch (1401 / 2000) (Train_loss:0.65276661, ACU_loss:2.61106644, Val_loss:4.68021299)\n",
      "epoch (1402 / 2000) (Train_loss:0.64956834, ACU_loss:2.59827334, Val_loss:4.66677392)\n",
      "epoch (1403 / 2000) (Train_loss:0.64625280, ACU_loss:2.58501120, Val_loss:4.65331666)\n",
      "epoch (1404 / 2000) (Train_loss:0.64286863, ACU_loss:2.57147454, Val_loss:4.63988845)\n",
      "epoch (1405 / 2000) (Train_loss:0.63946624, ACU_loss:2.55786496, Val_loss:4.62653096)\n",
      "epoch (1406 / 2000) (Train_loss:0.63609391, ACU_loss:2.54437566, Val_loss:4.61327760)\n",
      "epoch (1407 / 2000) (Train_loss:0.63279441, ACU_loss:2.53117763, Val_loss:4.60015227)\n",
      "epoch (1408 / 2000) (Train_loss:0.62960243, ACU_loss:2.51840971, Val_loss:4.58716921)\n",
      "epoch (1409 / 2000) (Train_loss:0.62654327, ACU_loss:2.50617307, Val_loss:4.57433397)\n",
      "epoch (1410 / 2000) (Train_loss:0.62363255, ACU_loss:2.49453019, Val_loss:4.56164495)\n",
      "epoch (1411 / 2000) (Train_loss:0.62087690, ACU_loss:2.48350758, Val_loss:4.54909517)\n",
      "epoch (1412 / 2000) (Train_loss:0.61827522, ACU_loss:2.47310088, Val_loss:4.53667398)\n",
      "epoch (1413 / 2000) (Train_loss:0.61582031, ACU_loss:2.46328126, Val_loss:4.52436851)\n",
      "epoch (1414 / 2000) (Train_loss:0.61350053, ACU_loss:2.45400211, Val_loss:4.51216492)\n",
      "epoch (1415 / 2000) (Train_loss:0.61130132, ACU_loss:2.44520527, Val_loss:4.50004918)\n",
      "epoch (1416 / 2000) (Train_loss:0.60920658, ACU_loss:2.43682633, Val_loss:4.48800771)\n",
      "epoch (1417 / 2000) (Train_loss:0.60719974, ACU_loss:2.42879895, Val_loss:4.47602778)\n",
      "epoch (1418 / 2000) (Train_loss:0.60526453, ACU_loss:2.42105812, Val_loss:4.46409775)\n",
      "epoch (1419 / 2000) (Train_loss:0.60338561, ACU_loss:2.41354244, Val_loss:4.45220723)\n",
      "epoch (1420 / 2000) (Train_loss:0.60154892, ACU_loss:2.40619566, Val_loss:4.44034711)\n",
      "epoch (1421 / 2000) (Train_loss:0.59974188, ACU_loss:2.39896753, Val_loss:4.42850958)\n",
      "epoch (1422 / 2000) (Train_loss:0.59795355, ACU_loss:2.39181421, Val_loss:4.41668812)\n",
      "epoch (1423 / 2000) (Train_loss:0.59617457, ACU_loss:2.38469829, Val_loss:4.40487739)\n",
      "epoch (1424 / 2000) (Train_loss:0.59439714, ACU_loss:2.37758857, Val_loss:4.39307318)\n",
      "epoch (1425 / 2000) (Train_loss:0.59261491, ACU_loss:2.37045964, Val_loss:4.38127226)\n",
      "epoch (1426 / 2000) (Train_loss:0.59082284, ACU_loss:2.36329134, Val_loss:4.36947228)\n",
      "epoch (1427 / 2000) (Train_loss:0.58901704, ACU_loss:2.35606817, Val_loss:4.35767164)\n",
      "epoch (1428 / 2000) (Train_loss:0.58719467, ACU_loss:2.34877866, Val_loss:4.34586939)\n",
      "epoch (1429 / 2000) (Train_loss:0.58535368, ACU_loss:2.34141474, Val_loss:4.33406508)\n",
      "epoch (1430 / 2000) (Train_loss:0.58349279, ACU_loss:2.33397114, Val_loss:4.32225867)\n",
      "epoch (1431 / 2000) (Train_loss:0.58161122, ACU_loss:2.32644489, Val_loss:4.31045044)\n",
      "epoch (1432 / 2000) (Train_loss:0.57970869, ACU_loss:2.31883477, Val_loss:4.29864095)\n",
      "epoch (1433 / 2000) (Train_loss:0.57778525, ACU_loss:2.31114099, Val_loss:4.28683092)\n",
      "epoch (1434 / 2000) (Train_loss:0.57584120, ACU_loss:2.30336479, Val_loss:4.27502121)\n",
      "epoch (1435 / 2000) (Train_loss:0.57387706, ACU_loss:2.29550825, Val_loss:4.26321281)\n",
      "epoch (1436 / 2000) (Train_loss:0.57189351, ACU_loss:2.28757405, Val_loss:4.25140679)\n",
      "epoch (1437 / 2000) (Train_loss:0.56989136, ACU_loss:2.27956543, Val_loss:4.23960433)\n",
      "epoch (1438 / 2000) (Train_loss:0.56787152, ACU_loss:2.27148609, Val_loss:4.22780671)\n",
      "epoch (1439 / 2000) (Train_loss:0.56583506, ACU_loss:2.26334024, Val_loss:4.21601531)\n",
      "epoch (1440 / 2000) (Train_loss:0.56378315, ACU_loss:2.25513260, Val_loss:4.20423170)\n",
      "epoch (1441 / 2000) (Train_loss:0.56171714, ACU_loss:2.24686856, Val_loss:4.19245761)\n",
      "epoch (1442 / 2000) (Train_loss:0.55963856, ACU_loss:2.23855423, Val_loss:4.18069498)\n",
      "epoch (1443 / 2000) (Train_loss:0.55754914, ACU_loss:2.23019657, Val_loss:4.16894601)\n",
      "epoch (1444 / 2000) (Train_loss:0.55545088, ACU_loss:2.22180351, Val_loss:4.15721319)\n",
      "epoch (1445 / 2000) (Train_loss:0.55334601, ACU_loss:2.21338403, Val_loss:4.14549930)\n",
      "epoch (1446 / 2000) (Train_loss:0.55123706, ACU_loss:2.20494824, Val_loss:4.13380741)\n",
      "epoch (1447 / 2000) (Train_loss:0.54912684, ACU_loss:2.19650735, Val_loss:4.12214089)\n",
      "epoch (1448 / 2000) (Train_loss:0.54701840, ACU_loss:2.18807361, Val_loss:4.11050335)\n",
      "epoch (1449 / 2000) (Train_loss:0.54491505, ACU_loss:2.17966019, Val_loss:4.09889861)\n",
      "epoch (1450 / 2000) (Train_loss:0.54282025, ACU_loss:2.17128099, Val_loss:4.08733057)\n",
      "epoch (1451 / 2000) (Train_loss:0.54073758, ACU_loss:2.16295031, Val_loss:4.07580315)\n",
      "epoch (1452 / 2000) (Train_loss:0.53867064, ACU_loss:2.15468257, Val_loss:4.06432014)\n",
      "epoch (1453 / 2000) (Train_loss:0.53662297, ACU_loss:2.14649189, Val_loss:4.05288509)\n",
      "epoch (1454 / 2000) (Train_loss:0.53459794, ACU_loss:2.13839175, Val_loss:4.04150116)\n",
      "epoch (1455 / 2000) (Train_loss:0.53259867, ACU_loss:2.13039468, Val_loss:4.03017103)\n",
      "epoch (1456 / 2000) (Train_loss:0.53062798, ACU_loss:2.12251191, Val_loss:4.01889684)\n",
      "epoch (1457 / 2000) (Train_loss:0.52868832, ACU_loss:2.11475329, Val_loss:4.00768011)\n",
      "epoch (1458 / 2000) (Train_loss:0.52678180, ACU_loss:2.10712720, Val_loss:3.99652174)\n",
      "epoch (1459 / 2000) (Train_loss:0.52491015, ACU_loss:2.09964060, Val_loss:3.98542208)\n",
      "epoch (1460 / 2000) (Train_loss:0.52307480, ACU_loss:2.09229920, Val_loss:3.97438101)\n",
      "epoch (1461 / 2000) (Train_loss:0.52127692, ACU_loss:2.08510769, Val_loss:3.96339800)\n",
      "epoch (1462 / 2000) (Train_loss:0.51951750, ACU_loss:2.07806998, Val_loss:3.95247230)\n",
      "epoch (1463 / 2000) (Train_loss:0.51779734, ACU_loss:2.07118938, Val_loss:3.94160297)\n",
      "epoch (1464 / 2000) (Train_loss:0.51611718, ACU_loss:2.06446874, Val_loss:3.93078906)\n",
      "epoch (1465 / 2000) (Train_loss:0.51447762, ACU_loss:2.05791050, Val_loss:3.92002963)\n",
      "epoch (1466 / 2000) (Train_loss:0.51287916, ACU_loss:2.05151663, Val_loss:3.90932380)\n",
      "epoch (1467 / 2000) (Train_loss:0.51132212, ACU_loss:2.04528849, Val_loss:3.89867078)\n",
      "epoch (1468 / 2000) (Train_loss:0.50980667, ACU_loss:2.03922666, Val_loss:3.88806984)\n",
      "epoch (1469 / 2000) (Train_loss:0.50833270, ACU_loss:2.03333079, Val_loss:3.87752032)\n",
      "epoch (1470 / 2000) (Train_loss:0.50689987, ACU_loss:2.02759947, Val_loss:3.86702159)\n",
      "epoch (1471 / 2000) (Train_loss:0.50550758, ACU_loss:2.02203030, Val_loss:3.85657305)\n",
      "epoch (1472 / 2000) (Train_loss:0.50415501, ACU_loss:2.01662005, Val_loss:3.84617412)\n",
      "epoch (1473 / 2000) (Train_loss:0.50284123, ACU_loss:2.01136491, Val_loss:3.83582430)\n",
      "epoch (1474 / 2000) (Train_loss:0.50156526, ACU_loss:2.00626103, Val_loss:3.82552316)\n",
      "epoch (1475 / 2000) (Train_loss:0.50032624, ACU_loss:2.00130497, Val_loss:3.81527043)\n",
      "epoch (1476 / 2000) (Train_loss:0.49912358, ACU_loss:1.99649434, Val_loss:3.80506604)\n",
      "epoch (1477 / 2000) (Train_loss:0.49795708, ACU_loss:1.99182830, Val_loss:3.79491015)\n",
      "epoch (1478 / 2000) (Train_loss:0.49682701, ACU_loss:1.98730803, Val_loss:3.78480319)\n",
      "epoch (1479 / 2000) (Train_loss:0.49573426, ACU_loss:1.98293705, Val_loss:3.77474589)\n",
      "epoch (1480 / 2000) (Train_loss:0.49468034, ACU_loss:1.97872138, Val_loss:3.76473924)\n",
      "epoch (1481 / 2000) (Train_loss:0.49366740, ACU_loss:1.97466960, Val_loss:3.75478453)\n",
      "epoch (1482 / 2000) (Train_loss:0.49269821, ACU_loss:1.97079286, Val_loss:3.74488330)\n",
      "epoch (1483 / 2000) (Train_loss:0.49177619, ACU_loss:1.96710477, Val_loss:3.73503732)\n",
      "epoch (1484 / 2000) (Train_loss:0.49090538, ACU_loss:1.96362153, Val_loss:3.72524865)\n",
      "epoch (1485 / 2000) (Train_loss:0.49009051, ACU_loss:1.96036205, Val_loss:3.71551964)\n",
      "epoch (1486 / 2000) (Train_loss:0.48933710, ACU_loss:1.95734841, Val_loss:3.70585299)\n",
      "epoch (1487 / 2000) (Train_loss:0.48865160, ACU_loss:1.95460641, Val_loss:3.69625183)\n",
      "epoch (1488 / 2000) (Train_loss:0.48804161, ACU_loss:1.95216644, Val_loss:3.68671984)\n",
      "epoch (1489 / 2000) (Train_loss:0.48751613, ACU_loss:1.95006453, Val_loss:3.67726136)\n",
      "epoch (1490 / 2000) (Train_loss:0.48708589, ACU_loss:1.94834357, Val_loss:3.66788155)\n",
      "epoch (1491 / 2000) (Train_loss:0.48676370, ACU_loss:1.94705480, Val_loss:3.65858655)\n",
      "epoch (1492 / 2000) (Train_loss:0.48656491, ACU_loss:1.94625965, Val_loss:3.64938374)\n",
      "epoch (1493 / 2000) (Train_loss:0.48650797, ACU_loss:1.94603188, Val_loss:3.64028203)\n",
      "epoch (1494 / 2000) (Train_loss:0.48661510, ACU_loss:1.94646039, Val_loss:3.63129221)\n",
      "epoch (1495 / 2000) (Train_loss:0.48691317, ACU_loss:1.94765269, Val_loss:3.62242750)\n",
      "epoch (1496 / 2000) (Train_loss:0.48743486, ACU_loss:1.94973944, Val_loss:3.61370423)\n",
      "epoch (1497 / 2000) (Train_loss:0.48822004, ACU_loss:1.95288016, Val_loss:3.60514276)\n",
      "epoch (1498 / 2000) (Train_loss:0.48931760, ACU_loss:1.95727039, Val_loss:3.59676877)\n",
      "epoch (1499 / 2000) (Train_loss:0.49078769, ACU_loss:1.96315077, Val_loss:3.58861493)\n",
      "epoch (1500 / 2000) (Train_loss:0.49270447, ACU_loss:1.97081789, Val_loss:3.58072329)\n",
      "epoch (1501 / 2000) (Train_loss:0.49515929, ACU_loss:1.98063717, Val_loss:3.57314856)\n",
      "epoch (1502 / 2000) (Train_loss:0.49826419, ACU_loss:1.99305675, Val_loss:3.56596270)\n",
      "epoch (1503 / 2000) (Train_loss:0.50215509, ACU_loss:2.00862036, Val_loss:3.55926126)\n",
      "epoch (1504 / 2000) (Train_loss:0.50699348, ACU_loss:2.02797393, Val_loss:3.55317219)\n",
      "epoch (1505 / 2000) (Train_loss:0.51296371, ACU_loss:2.05185484, Val_loss:3.54786752)\n",
      "epoch (1506 / 2000) (Train_loss:0.52026075, ACU_loss:2.08104299, Val_loss:3.54357790)\n",
      "epoch (1507 / 2000) (Train_loss:0.52905922, ACU_loss:2.11623689, Val_loss:3.54060788)\n",
      "epoch (1508 / 2000) (Train_loss:0.53945018, ACU_loss:2.15780073, Val_loss:3.53934436)\n",
      "epoch (1509 / 2000) (Train_loss:0.55133245, ACU_loss:2.20532981, Val_loss:3.54023982)\n",
      "epoch (1510 / 2000) (Train_loss:0.56426591, ACU_loss:2.25706364, Val_loss:3.54373388)\n",
      "epoch (1511 / 2000) (Train_loss:0.57736486, ACU_loss:2.30945944, Val_loss:3.55005928)\n",
      "epoch (1512 / 2000) (Train_loss:0.58944633, ACU_loss:2.35778531, Val_loss:3.55887242)\n",
      "epoch (1513 / 2000) (Train_loss:0.59971011, ACU_loss:2.39884043, Val_loss:3.56858735)\n",
      "epoch (1514 / 2000) (Train_loss:0.60865009, ACU_loss:2.43460035, Val_loss:3.57489567)\n",
      "epoch (1515 / 2000) (Train_loss:0.61697201, ACU_loss:2.46788803, Val_loss:3.56813116)\n",
      "epoch (1516 / 2000) (Train_loss:0.61974709, ACU_loss:2.47898837, Val_loss:3.53551927)\n",
      "epoch (1517 / 2000) (Train_loss:0.60353691, ACU_loss:2.41414765, Val_loss:3.47744813)\n",
      "epoch (1518 / 2000) (Train_loss:0.56147103, ACU_loss:2.24588413, Val_loss:3.41700054)\n",
      "epoch (1519 / 2000) (Train_loss:0.50789095, ACU_loss:2.03156380, Val_loss:3.37887204)\n",
      "epoch (1520 / 2000) (Train_loss:0.46529446, ACU_loss:1.86117783, Val_loss:3.36397989)\n",
      "epoch (1521 / 2000) (Train_loss:0.44019380, ACU_loss:1.76077518, Val_loss:3.35842139)\n",
      "epoch (1522 / 2000) (Train_loss:0.42685232, ACU_loss:1.70740929, Val_loss:3.35211235)\n",
      "epoch (1523 / 2000) (Train_loss:0.41892466, ACU_loss:1.67569865, Val_loss:3.34322224)\n",
      "epoch (1524 / 2000) (Train_loss:0.41458788, ACU_loss:1.65835150, Val_loss:3.33378731)\n",
      "epoch (1525 / 2000) (Train_loss:0.41327559, ACU_loss:1.65310238, Val_loss:3.32536957)\n",
      "epoch (1526 / 2000) (Train_loss:0.41457534, ACU_loss:1.65830138, Val_loss:3.31759520)\n",
      "epoch (1527 / 2000) (Train_loss:0.41775243, ACU_loss:1.67100973, Val_loss:3.31057933)\n",
      "epoch (1528 / 2000) (Train_loss:0.42099017, ACU_loss:1.68396069, Val_loss:3.30331365)\n",
      "epoch (1529 / 2000) (Train_loss:0.42416287, ACU_loss:1.69665148, Val_loss:3.29518523)\n",
      "epoch (1530 / 2000) (Train_loss:0.42514978, ACU_loss:1.70059914, Val_loss:3.28719887)\n",
      "epoch (1531 / 2000) (Train_loss:0.42537392, ACU_loss:1.70149569, Val_loss:3.27777000)\n",
      "epoch (1532 / 2000) (Train_loss:0.42417743, ACU_loss:1.69670972, Val_loss:3.26923781)\n",
      "epoch (1533 / 2000) (Train_loss:0.42173924, ACU_loss:1.68695695, Val_loss:3.26040676)\n",
      "epoch (1534 / 2000) (Train_loss:0.42173080, ACU_loss:1.68692320, Val_loss:3.25128627)\n",
      "epoch (1535 / 2000) (Train_loss:0.41654793, ACU_loss:1.66619171, Val_loss:3.24482671)\n",
      "epoch (1536 / 2000) (Train_loss:0.42108230, ACU_loss:1.68432919, Val_loss:3.23427387)\n",
      "epoch (1537 / 2000) (Train_loss:0.41328119, ACU_loss:1.65312474, Val_loss:3.23082318)\n",
      "epoch (1538 / 2000) (Train_loss:0.42210671, ACU_loss:1.68842685, Val_loss:3.21667244)\n",
      "epoch (1539 / 2000) (Train_loss:0.41590433, ACU_loss:1.66361730, Val_loss:3.21627747)\n",
      "epoch (1540 / 2000) (Train_loss:0.41847682, ACU_loss:1.67390729, Val_loss:3.20202735)\n",
      "epoch (1541 / 2000) (Train_loss:0.42994348, ACU_loss:1.71977394, Val_loss:3.22168543)\n",
      "epoch (1542 / 2000) (Train_loss:0.41450143, ACU_loss:1.65800573, Val_loss:3.23698717)\n",
      "epoch (1543 / 2000) (Train_loss:0.50345831, ACU_loss:2.01383323, Val_loss:3.30099929)\n",
      "epoch (1544 / 2000) (Train_loss:0.54798480, ACU_loss:2.19193920, Val_loss:3.22090499)\n",
      "epoch (1545 / 2000) (Train_loss:0.60280456, ACU_loss:2.41121825, Val_loss:3.29619962)\n",
      "epoch (1546 / 2000) (Train_loss:0.68977553, ACU_loss:2.75910211, Val_loss:3.32120220)\n",
      "epoch (1547 / 2000) (Train_loss:0.56226793, ACU_loss:2.24907172, Val_loss:3.24315193)\n",
      "epoch (1548 / 2000) (Train_loss:0.93974229, ACU_loss:3.75896917, Val_loss:3.33723930)\n",
      "epoch (1549 / 2000) (Train_loss:0.86326259, ACU_loss:3.45305037, Val_loss:3.26384810)\n",
      "epoch (1550 / 2000) (Train_loss:1.32296767, ACU_loss:5.29187068, Val_loss:4.14311083)\n",
      "epoch (1551 / 2000) (Train_loss:1.11647265, ACU_loss:4.46589062, Val_loss:3.88093003)\n",
      "epoch (1552 / 2000) (Train_loss:1.55844021, ACU_loss:6.23376083, Val_loss:4.18500034)\n",
      "epoch (1553 / 2000) (Train_loss:1.49223894, ACU_loss:5.96895575, Val_loss:3.78009630)\n",
      "epoch (1554 / 2000) (Train_loss:1.06290309, ACU_loss:4.25161237, Val_loss:4.12022897)\n",
      "epoch (1555 / 2000) (Train_loss:1.09444975, ACU_loss:4.37779901, Val_loss:3.20201323)\n",
      "epoch (1556 / 2000) (Train_loss:0.99764262, ACU_loss:3.99057048, Val_loss:4.92161013)\n",
      "epoch (1557 / 2000) (Train_loss:1.20576811, ACU_loss:4.82307245, Val_loss:3.26652443)\n",
      "epoch (1558 / 2000) (Train_loss:1.10353642, ACU_loss:4.41414568, Val_loss:3.77382620)\n",
      "epoch (1559 / 2000) (Train_loss:1.40538302, ACU_loss:5.62153209, Val_loss:4.83234928)\n",
      "epoch (1560 / 2000) (Train_loss:2.01799402, ACU_loss:8.07197610, Val_loss:3.31823701)\n",
      "epoch (1561 / 2000) (Train_loss:1.24466046, ACU_loss:4.97864185, Val_loss:4.19941449)\n",
      "epoch (1562 / 2000) (Train_loss:1.71913510, ACU_loss:6.87654038, Val_loss:3.65200976)\n",
      "epoch (1563 / 2000) (Train_loss:1.79370629, ACU_loss:7.17482518, Val_loss:7.17729420)\n",
      "epoch (1564 / 2000) (Train_loss:2.12609049, ACU_loss:8.50436195, Val_loss:8.44915672)\n",
      "epoch (1565 / 2000) (Train_loss:1.58461748, ACU_loss:6.33846990, Val_loss:6.29471664)\n",
      "epoch (1566 / 2000) (Train_loss:1.24290630, ACU_loss:4.97162519, Val_loss:3.86943671)\n",
      "epoch (1567 / 2000) (Train_loss:1.43599347, ACU_loss:5.74397389, Val_loss:3.75720170)\n",
      "epoch (1568 / 2000) (Train_loss:1.30521251, ACU_loss:5.22085002, Val_loss:3.29676325)\n",
      "epoch (1569 / 2000) (Train_loss:1.19825606, ACU_loss:4.79302425, Val_loss:3.42993397)\n",
      "epoch (1570 / 2000) (Train_loss:0.96898563, ACU_loss:3.87594253, Val_loss:3.49396094)\n",
      "epoch (1571 / 2000) (Train_loss:0.97006402, ACU_loss:3.88025607, Val_loss:3.51274175)\n",
      "epoch (1572 / 2000) (Train_loss:1.18500157, ACU_loss:4.74000628, Val_loss:3.46213000)\n",
      "epoch (1573 / 2000) (Train_loss:1.17064958, ACU_loss:4.68259831, Val_loss:3.40915650)\n",
      "epoch (1574 / 2000) (Train_loss:1.22072703, ACU_loss:4.88290814, Val_loss:3.17176149)\n",
      "epoch (1575 / 2000) (Train_loss:0.98199618, ACU_loss:3.92798472, Val_loss:3.24366873)\n",
      "epoch (1576 / 2000) (Train_loss:0.87795361, ACU_loss:3.51181445, Val_loss:3.23395194)\n",
      "epoch (1577 / 2000) (Train_loss:1.01160046, ACU_loss:4.04640183, Val_loss:3.24056898)\n",
      "epoch (1578 / 2000) (Train_loss:1.00811496, ACU_loss:4.03245982, Val_loss:3.61373146)\n",
      "epoch (1579 / 2000) (Train_loss:1.02986453, ACU_loss:4.11945810, Val_loss:3.27887709)\n",
      "epoch (1580 / 2000) (Train_loss:0.88651275, ACU_loss:3.54605101, Val_loss:3.26288935)\n",
      "epoch (1581 / 2000) (Train_loss:0.71837611, ACU_loss:2.87350446, Val_loss:3.13729380)\n",
      "epoch (1582 / 2000) (Train_loss:0.64656110, ACU_loss:2.58624440, Val_loss:3.22056919)\n",
      "epoch (1583 / 2000) (Train_loss:0.71610385, ACU_loss:2.86441539, Val_loss:3.26531568)\n",
      "epoch (1584 / 2000) (Train_loss:0.67730201, ACU_loss:2.70920804, Val_loss:3.10666668)\n",
      "epoch (1585 / 2000) (Train_loss:0.62791893, ACU_loss:2.51167570, Val_loss:3.06127068)\n",
      "epoch (1586 / 2000) (Train_loss:0.60097729, ACU_loss:2.40390917, Val_loss:3.08961674)\n",
      "epoch (1587 / 2000) (Train_loss:0.57798477, ACU_loss:2.31193909, Val_loss:3.06923217)\n",
      "epoch (1588 / 2000) (Train_loss:0.60143679, ACU_loss:2.40574717, Val_loss:3.08915068)\n",
      "epoch (1589 / 2000) (Train_loss:0.64869401, ACU_loss:2.59477604, Val_loss:2.99136850)\n",
      "epoch (1590 / 2000) (Train_loss:0.64868796, ACU_loss:2.59475184, Val_loss:3.00715413)\n",
      "epoch (1591 / 2000) (Train_loss:0.56418983, ACU_loss:2.25675933, Val_loss:2.97562472)\n",
      "epoch (1592 / 2000) (Train_loss:0.55410353, ACU_loss:2.21641411, Val_loss:2.97829953)\n",
      "epoch (1593 / 2000) (Train_loss:0.60893224, ACU_loss:2.43572894, Val_loss:2.96776173)\n",
      "epoch (1594 / 2000) (Train_loss:0.62041641, ACU_loss:2.48166565, Val_loss:2.94952347)\n",
      "epoch (1595 / 2000) (Train_loss:0.57351680, ACU_loss:2.29406720, Val_loss:3.07680500)\n",
      "epoch (1596 / 2000) (Train_loss:0.49697134, ACU_loss:1.98788536, Val_loss:2.85931524)\n",
      "epoch (1597 / 2000) (Train_loss:0.47623311, ACU_loss:1.90493243, Val_loss:2.86279417)\n",
      "epoch (1598 / 2000) (Train_loss:0.51375181, ACU_loss:2.05500725, Val_loss:2.93905197)\n",
      "epoch (1599 / 2000) (Train_loss:0.51383992, ACU_loss:2.05535968, Val_loss:2.82703289)\n",
      "epoch (1600 / 2000) (Train_loss:0.50084878, ACU_loss:2.00339514, Val_loss:2.97887265)\n",
      "epoch (1601 / 2000) (Train_loss:0.61312384, ACU_loss:2.45249537, Val_loss:2.95176406)\n",
      "epoch (1602 / 2000) (Train_loss:0.63138058, ACU_loss:2.52552230, Val_loss:2.84380563)\n",
      "epoch (1603 / 2000) (Train_loss:0.65946041, ACU_loss:2.63784164, Val_loss:3.11375172)\n",
      "epoch (1604 / 2000) (Train_loss:0.84937689, ACU_loss:3.39750755, Val_loss:3.10116253)\n",
      "epoch (1605 / 2000) (Train_loss:0.85286310, ACU_loss:3.41145240, Val_loss:2.88186434)\n",
      "epoch (1606 / 2000) (Train_loss:0.87019113, ACU_loss:3.48076451, Val_loss:3.14028232)\n",
      "epoch (1607 / 2000) (Train_loss:1.01419291, ACU_loss:4.05677166, Val_loss:3.45241070)\n",
      "epoch (1608 / 2000) (Train_loss:1.00200408, ACU_loss:4.00801633, Val_loss:2.95444846)\n",
      "epoch (1609 / 2000) (Train_loss:1.07158152, ACU_loss:4.28632608, Val_loss:2.85656772)\n",
      "epoch (1610 / 2000) (Train_loss:0.92741611, ACU_loss:3.70966444, Val_loss:3.23345601)\n",
      "epoch (1611 / 2000) (Train_loss:0.62464478, ACU_loss:2.49857912, Val_loss:2.92223940)\n",
      "epoch (1612 / 2000) (Train_loss:0.65833787, ACU_loss:2.63335148, Val_loss:2.99588117)\n",
      "epoch (1613 / 2000) (Train_loss:0.65933239, ACU_loss:2.63732957, Val_loss:3.18512852)\n",
      "epoch (1614 / 2000) (Train_loss:0.66132274, ACU_loss:2.64529098, Val_loss:2.83867798)\n",
      "epoch (1615 / 2000) (Train_loss:0.66014420, ACU_loss:2.64057681, Val_loss:2.79301356)\n",
      "epoch (1616 / 2000) (Train_loss:0.59521529, ACU_loss:2.38086117, Val_loss:2.79215538)\n",
      "epoch (1617 / 2000) (Train_loss:0.54159257, ACU_loss:2.16637027, Val_loss:2.84722553)\n",
      "epoch (1618 / 2000) (Train_loss:0.62943282, ACU_loss:2.51773127, Val_loss:2.88019222)\n",
      "epoch (1619 / 2000) (Train_loss:0.64702943, ACU_loss:2.58811772, Val_loss:2.75934425)\n",
      "epoch (1620 / 2000) (Train_loss:0.55761623, ACU_loss:2.23046494, Val_loss:2.87320432)\n",
      "epoch (1621 / 2000) (Train_loss:0.48819684, ACU_loss:1.95278737, Val_loss:2.77195475)\n",
      "epoch (1622 / 2000) (Train_loss:0.51219101, ACU_loss:2.04876403, Val_loss:2.74643152)\n",
      "epoch (1623 / 2000) (Train_loss:0.57237511, ACU_loss:2.28950043, Val_loss:2.82363464)\n",
      "epoch (1624 / 2000) (Train_loss:0.50686541, ACU_loss:2.02746162, Val_loss:2.75889533)\n",
      "epoch (1625 / 2000) (Train_loss:0.41906285, ACU_loss:1.67625138, Val_loss:2.77942799)\n",
      "epoch (1626 / 2000) (Train_loss:0.38323528, ACU_loss:1.53294112, Val_loss:2.65787314)\n",
      "epoch (1627 / 2000) (Train_loss:0.39635560, ACU_loss:1.58542239, Val_loss:2.62559241)\n",
      "epoch (1628 / 2000) (Train_loss:0.39490724, ACU_loss:1.57962897, Val_loss:2.69148976)\n",
      "epoch (1629 / 2000) (Train_loss:0.36816077, ACU_loss:1.47264307, Val_loss:2.63084275)\n",
      "epoch (1630 / 2000) (Train_loss:0.35004701, ACU_loss:1.40018805, Val_loss:2.63112665)\n",
      "epoch (1631 / 2000) (Train_loss:0.33178950, ACU_loss:1.32715801, Val_loss:2.60922702)\n",
      "epoch (1632 / 2000) (Train_loss:0.33567846, ACU_loss:1.34271383, Val_loss:2.59597197)\n",
      "epoch (1633 / 2000) (Train_loss:0.34215655, ACU_loss:1.36862620, Val_loss:2.58853822)\n",
      "epoch (1634 / 2000) (Train_loss:0.33427328, ACU_loss:1.33709313, Val_loss:2.59974566)\n",
      "epoch (1635 / 2000) (Train_loss:0.34212777, ACU_loss:1.36851108, Val_loss:2.59339821)\n",
      "epoch (1636 / 2000) (Train_loss:0.35409249, ACU_loss:1.41636998, Val_loss:2.56434880)\n",
      "epoch (1637 / 2000) (Train_loss:0.34464164, ACU_loss:1.37856654, Val_loss:2.59268413)\n",
      "epoch (1638 / 2000) (Train_loss:0.35448366, ACU_loss:1.41793462, Val_loss:2.58098043)\n",
      "epoch (1639 / 2000) (Train_loss:0.36830753, ACU_loss:1.47323013, Val_loss:2.55213415)\n",
      "epoch (1640 / 2000) (Train_loss:0.35311096, ACU_loss:1.41244383, Val_loss:2.58129137)\n",
      "epoch (1641 / 2000) (Train_loss:0.37124572, ACU_loss:1.48498287, Val_loss:2.58879476)\n",
      "epoch (1642 / 2000) (Train_loss:0.39931570, ACU_loss:1.59726282, Val_loss:2.53821677)\n",
      "epoch (1643 / 2000) (Train_loss:0.38138312, ACU_loss:1.52553249, Val_loss:2.58116654)\n",
      "epoch (1644 / 2000) (Train_loss:0.40805752, ACU_loss:1.63223006, Val_loss:2.61520024)\n",
      "epoch (1645 / 2000) (Train_loss:0.45698695, ACU_loss:1.82794780, Val_loss:2.53947823)\n",
      "epoch (1646 / 2000) (Train_loss:0.43865235, ACU_loss:1.75460941, Val_loss:2.58510960)\n",
      "epoch (1647 / 2000) (Train_loss:0.47296073, ACU_loss:1.89184292, Val_loss:2.66362956)\n",
      "epoch (1648 / 2000) (Train_loss:0.55011501, ACU_loss:2.20046005, Val_loss:2.57823164)\n",
      "epoch (1649 / 2000) (Train_loss:0.54073032, ACU_loss:2.16292127, Val_loss:2.57693149)\n",
      "epoch (1650 / 2000) (Train_loss:0.57280206, ACU_loss:2.29120824, Val_loss:2.71598167)\n",
      "epoch (1651 / 2000) (Train_loss:0.66478135, ACU_loss:2.65912540, Val_loss:2.70082342)\n",
      "epoch (1652 / 2000) (Train_loss:0.68765568, ACU_loss:2.75062273, Val_loss:2.53991332)\n",
      "epoch (1653 / 2000) (Train_loss:0.70260110, ACU_loss:2.81040441, Val_loss:2.65748258)\n",
      "epoch (1654 / 2000) (Train_loss:0.70587592, ACU_loss:2.82350369, Val_loss:2.85164243)\n",
      "epoch (1655 / 2000) (Train_loss:0.72694851, ACU_loss:2.90779404, Val_loss:2.59118277)\n",
      "epoch (1656 / 2000) (Train_loss:0.78433419, ACU_loss:3.13733675, Val_loss:2.50238768)\n",
      "epoch (1657 / 2000) (Train_loss:0.69678443, ACU_loss:2.78713773, Val_loss:2.73537740)\n",
      "epoch (1658 / 2000) (Train_loss:0.53744769, ACU_loss:2.14979074, Val_loss:2.61872670)\n",
      "epoch (1659 / 2000) (Train_loss:0.61278436, ACU_loss:2.45113743, Val_loss:2.59636152)\n",
      "epoch (1660 / 2000) (Train_loss:0.65522528, ACU_loss:2.62090112, Val_loss:2.72311380)\n",
      "epoch (1661 / 2000) (Train_loss:0.53254659, ACU_loss:2.13018636, Val_loss:2.54287640)\n",
      "epoch (1662 / 2000) (Train_loss:0.44403765, ACU_loss:1.77615062, Val_loss:2.51939599)\n",
      "epoch (1663 / 2000) (Train_loss:0.45847597, ACU_loss:1.83390386, Val_loss:2.58093507)\n",
      "epoch (1664 / 2000) (Train_loss:0.53374422, ACU_loss:2.13497688, Val_loss:2.55479893)\n",
      "epoch (1665 / 2000) (Train_loss:0.58956097, ACU_loss:2.35824387, Val_loss:2.54193974)\n",
      "epoch (1666 / 2000) (Train_loss:0.56706741, ACU_loss:2.26826962, Val_loss:2.46237771)\n",
      "epoch (1667 / 2000) (Train_loss:0.49433336, ACU_loss:1.97733344, Val_loss:2.58129236)\n",
      "epoch (1668 / 2000) (Train_loss:0.54528491, ACU_loss:2.18113962, Val_loss:2.58611778)\n",
      "epoch (1669 / 2000) (Train_loss:0.61215052, ACU_loss:2.44860207, Val_loss:2.46919153)\n",
      "epoch (1670 / 2000) (Train_loss:0.60922672, ACU_loss:2.43690687, Val_loss:2.57397465)\n",
      "epoch (1671 / 2000) (Train_loss:0.51169500, ACU_loss:2.04678000, Val_loss:2.47939601)\n",
      "epoch (1672 / 2000) (Train_loss:0.46380288, ACU_loss:1.85521150, Val_loss:2.52369757)\n",
      "epoch (1673 / 2000) (Train_loss:0.55391067, ACU_loss:2.21564268, Val_loss:2.59767588)\n",
      "epoch (1674 / 2000) (Train_loss:0.54363540, ACU_loss:2.17454161, Val_loss:2.47172077)\n",
      "epoch (1675 / 2000) (Train_loss:0.48791256, ACU_loss:1.95165024, Val_loss:2.45711364)\n",
      "epoch (1676 / 2000) (Train_loss:0.46572575, ACU_loss:1.86290299, Val_loss:2.45304294)\n",
      "epoch (1677 / 2000) (Train_loss:0.50995295, ACU_loss:2.03981180, Val_loss:2.56857253)\n",
      "epoch (1678 / 2000) (Train_loss:0.59237539, ACU_loss:2.36950156, Val_loss:2.56565027)\n",
      "epoch (1679 / 2000) (Train_loss:0.59829577, ACU_loss:2.39318308, Val_loss:2.36960839)\n",
      "epoch (1680 / 2000) (Train_loss:0.54851273, ACU_loss:2.19405093, Val_loss:2.45648284)\n",
      "epoch (1681 / 2000) (Train_loss:0.52319972, ACU_loss:2.09279889, Val_loss:2.52348755)\n",
      "epoch (1682 / 2000) (Train_loss:0.62402554, ACU_loss:2.49610214, Val_loss:2.52445372)\n",
      "epoch (1683 / 2000) (Train_loss:0.70735649, ACU_loss:2.82942595, Val_loss:2.56894710)\n",
      "epoch (1684 / 2000) (Train_loss:0.61936645, ACU_loss:2.47746581, Val_loss:2.36615130)\n",
      "epoch (1685 / 2000) (Train_loss:0.52432599, ACU_loss:2.09730394, Val_loss:2.51572209)\n",
      "epoch (1686 / 2000) (Train_loss:0.55676954, ACU_loss:2.22707815, Val_loss:2.61594255)\n",
      "epoch (1687 / 2000) (Train_loss:0.67170527, ACU_loss:2.68682109, Val_loss:2.48749085)\n",
      "epoch (1688 / 2000) (Train_loss:0.73528402, ACU_loss:2.94113610, Val_loss:2.38480014)\n",
      "epoch (1689 / 2000) (Train_loss:0.66894053, ACU_loss:2.67576213, Val_loss:2.31779874)\n",
      "epoch (1690 / 2000) (Train_loss:0.58457100, ACU_loss:2.33828399, Val_loss:2.71196648)\n",
      "epoch (1691 / 2000) (Train_loss:0.62664588, ACU_loss:2.50658351, Val_loss:2.62408367)\n",
      "epoch (1692 / 2000) (Train_loss:0.76520383, ACU_loss:3.06081531, Val_loss:2.35788331)\n",
      "epoch (1693 / 2000) (Train_loss:0.78554408, ACU_loss:3.14217631, Val_loss:2.34268562)\n",
      "epoch (1694 / 2000) (Train_loss:0.60197665, ACU_loss:2.40790659, Val_loss:2.34461652)\n",
      "epoch (1695 / 2000) (Train_loss:0.50646019, ACU_loss:2.02584076, Val_loss:2.43903112)\n",
      "epoch (1696 / 2000) (Train_loss:0.56265939, ACU_loss:2.25063758, Val_loss:2.45612591)\n",
      "epoch (1697 / 2000) (Train_loss:0.52723929, ACU_loss:2.10895717, Val_loss:2.28603268)\n",
      "epoch (1698 / 2000) (Train_loss:0.48336023, ACU_loss:1.93344092, Val_loss:2.36543166)\n",
      "epoch (1699 / 2000) (Train_loss:0.41237181, ACU_loss:1.64948725, Val_loss:2.33595821)\n",
      "epoch (1700 / 2000) (Train_loss:0.40729417, ACU_loss:1.62917668, Val_loss:2.31198063)\n",
      "epoch (1701 / 2000) (Train_loss:0.43812081, ACU_loss:1.75248323, Val_loss:2.27660725)\n",
      "epoch (1702 / 2000) (Train_loss:0.42404454, ACU_loss:1.69617816, Val_loss:2.20886807)\n",
      "epoch (1703 / 2000) (Train_loss:0.37804016, ACU_loss:1.51216062, Val_loss:2.26557544)\n",
      "epoch (1704 / 2000) (Train_loss:0.37438488, ACU_loss:1.49753951, Val_loss:2.32535418)\n",
      "epoch (1705 / 2000) (Train_loss:0.41247668, ACU_loss:1.64990670, Val_loss:2.28155713)\n",
      "epoch (1706 / 2000) (Train_loss:0.43753999, ACU_loss:1.75015996, Val_loss:2.24086708)\n",
      "epoch (1707 / 2000) (Train_loss:0.42662663, ACU_loss:1.70650651, Val_loss:2.18194294)\n",
      "epoch (1708 / 2000) (Train_loss:0.40200753, ACU_loss:1.60803011, Val_loss:2.32527493)\n",
      "epoch (1709 / 2000) (Train_loss:0.42219430, ACU_loss:1.68877721, Val_loss:2.36596288)\n",
      "epoch (1710 / 2000) (Train_loss:0.48944104, ACU_loss:1.95776417, Val_loss:2.23050075)\n",
      "epoch (1711 / 2000) (Train_loss:0.50858246, ACU_loss:2.03432985, Val_loss:2.18370116)\n",
      "epoch (1712 / 2000) (Train_loss:0.46084817, ACU_loss:1.84339268, Val_loss:2.20037077)\n",
      "epoch (1713 / 2000) (Train_loss:0.43824199, ACU_loss:1.75296796, Val_loss:2.35863940)\n",
      "epoch (1714 / 2000) (Train_loss:0.49634178, ACU_loss:1.98536713, Val_loss:2.37463412)\n",
      "epoch (1715 / 2000) (Train_loss:0.54828595, ACU_loss:2.19314380, Val_loss:2.17431390)\n",
      "epoch (1716 / 2000) (Train_loss:0.52513032, ACU_loss:2.10052129, Val_loss:2.20378363)\n",
      "epoch (1717 / 2000) (Train_loss:0.46208188, ACU_loss:1.84832751, Val_loss:2.25817763)\n",
      "epoch (1718 / 2000) (Train_loss:0.47940939, ACU_loss:1.91763757, Val_loss:2.30711494)\n",
      "epoch (1719 / 2000) (Train_loss:0.55341002, ACU_loss:2.21364008, Val_loss:2.27136532)\n",
      "epoch (1720 / 2000) (Train_loss:0.54315133, ACU_loss:2.17260531, Val_loss:2.12586567)\n",
      "epoch (1721 / 2000) (Train_loss:0.47314718, ACU_loss:1.89258870, Val_loss:2.28699569)\n",
      "epoch (1722 / 2000) (Train_loss:0.42713118, ACU_loss:1.70852473, Val_loss:2.28657863)\n",
      "epoch (1723 / 2000) (Train_loss:0.48574051, ACU_loss:1.94296204, Val_loss:2.21447241)\n",
      "epoch (1724 / 2000) (Train_loss:0.52642162, ACU_loss:2.10568646, Val_loss:2.13913263)\n",
      "epoch (1725 / 2000) (Train_loss:0.46144750, ACU_loss:1.84579000, Val_loss:2.10021423)\n",
      "epoch (1726 / 2000) (Train_loss:0.38316389, ACU_loss:1.53265557, Val_loss:2.22842624)\n",
      "epoch (1727 / 2000) (Train_loss:0.38570136, ACU_loss:1.54280542, Val_loss:2.24526490)\n",
      "epoch (1728 / 2000) (Train_loss:0.43613524, ACU_loss:1.74454097, Val_loss:2.13659055)\n",
      "epoch (1729 / 2000) (Train_loss:0.43680040, ACU_loss:1.74720161, Val_loss:2.08770823)\n",
      "epoch (1730 / 2000) (Train_loss:0.38874538, ACU_loss:1.55498153, Val_loss:2.10167050)\n",
      "epoch (1731 / 2000) (Train_loss:0.35522471, ACU_loss:1.42089884, Val_loss:2.17672415)\n",
      "epoch (1732 / 2000) (Train_loss:0.38734797, ACU_loss:1.54939188, Val_loss:2.18123589)\n",
      "epoch (1733 / 2000) (Train_loss:0.41971095, ACU_loss:1.67884378, Val_loss:2.06982578)\n",
      "epoch (1734 / 2000) (Train_loss:0.39535503, ACU_loss:1.58142013, Val_loss:2.08319862)\n",
      "epoch (1735 / 2000) (Train_loss:0.36243367, ACU_loss:1.44973466, Val_loss:2.12890418)\n",
      "epoch (1736 / 2000) (Train_loss:0.37658848, ACU_loss:1.50635394, Val_loss:2.14504848)\n",
      "epoch (1737 / 2000) (Train_loss:0.41844799, ACU_loss:1.67379196, Val_loss:2.11437448)\n",
      "epoch (1738 / 2000) (Train_loss:0.41950979, ACU_loss:1.67803917, Val_loss:2.02561638)\n",
      "epoch (1739 / 2000) (Train_loss:0.37707435, ACU_loss:1.50829738, Val_loss:2.12075254)\n",
      "epoch (1740 / 2000) (Train_loss:0.36615801, ACU_loss:1.46463205, Val_loss:2.16467220)\n",
      "epoch (1741 / 2000) (Train_loss:0.41928955, ACU_loss:1.67715819, Val_loss:2.09566127)\n",
      "epoch (1742 / 2000) (Train_loss:0.44819749, ACU_loss:1.79278998, Val_loss:2.03615978)\n",
      "epoch (1743 / 2000) (Train_loss:0.41050755, ACU_loss:1.64203020, Val_loss:2.01635687)\n",
      "epoch (1744 / 2000) (Train_loss:0.36462968, ACU_loss:1.45851874, Val_loss:2.14164332)\n",
      "epoch (1745 / 2000) (Train_loss:0.39012218, ACU_loss:1.56048873, Val_loss:2.16342299)\n",
      "epoch (1746 / 2000) (Train_loss:0.44799400, ACU_loss:1.79197599, Val_loss:2.03167482)\n",
      "epoch (1747 / 2000) (Train_loss:0.44189117, ACU_loss:1.76756468, Val_loss:2.01136021)\n",
      "epoch (1748 / 2000) (Train_loss:0.38922091, ACU_loss:1.55688366, Val_loss:2.04968781)\n",
      "epoch (1749 / 2000) (Train_loss:0.37860802, ACU_loss:1.51443209, Val_loss:2.11127073)\n",
      "epoch (1750 / 2000) (Train_loss:0.43004093, ACU_loss:1.72016371, Val_loss:2.09430110)\n",
      "epoch (1751 / 2000) (Train_loss:0.44606428, ACU_loss:1.78425712, Val_loss:1.97452135)\n",
      "epoch (1752 / 2000) (Train_loss:0.40061311, ACU_loss:1.60245243, Val_loss:2.05150068)\n",
      "epoch (1753 / 2000) (Train_loss:0.36726907, ACU_loss:1.46907628, Val_loss:2.09322124)\n",
      "epoch (1754 / 2000) (Train_loss:0.40970801, ACU_loss:1.63883202, Val_loss:2.05509395)\n",
      "epoch (1755 / 2000) (Train_loss:0.45017815, ACU_loss:1.80071258, Val_loss:1.99425335)\n",
      "epoch (1756 / 2000) (Train_loss:0.41563882, ACU_loss:1.66255526, Val_loss:1.94929384)\n",
      "epoch (1757 / 2000) (Train_loss:0.35589283, ACU_loss:1.42357131, Val_loss:2.06848145)\n",
      "epoch (1758 / 2000) (Train_loss:0.36419929, ACU_loss:1.45679716, Val_loss:2.09559241)\n",
      "epoch (1759 / 2000) (Train_loss:0.42347153, ACU_loss:1.69388611, Val_loss:1.98790503)\n",
      "epoch (1760 / 2000) (Train_loss:0.42811842, ACU_loss:1.71247369, Val_loss:1.94394780)\n",
      "epoch (1761 / 2000) (Train_loss:0.37613561, ACU_loss:1.50454242, Val_loss:1.96642752)\n",
      "epoch (1762 / 2000) (Train_loss:0.34615693, ACU_loss:1.38462771, Val_loss:2.03998589)\n",
      "epoch (1763 / 2000) (Train_loss:0.38725381, ACU_loss:1.54901525, Val_loss:2.03868660)\n",
      "epoch (1764 / 2000) (Train_loss:0.41663781, ACU_loss:1.66655124, Val_loss:1.92431837)\n",
      "epoch (1765 / 2000) (Train_loss:0.38314472, ACU_loss:1.53257889, Val_loss:1.95976257)\n",
      "epoch (1766 / 2000) (Train_loss:0.34592798, ACU_loss:1.38371191, Val_loss:2.00508137)\n",
      "epoch (1767 / 2000) (Train_loss:0.36953222, ACU_loss:1.47812890, Val_loss:1.99548629)\n",
      "epoch (1768 / 2000) (Train_loss:0.41085744, ACU_loss:1.64342975, Val_loss:1.94931116)\n",
      "epoch (1769 / 2000) (Train_loss:0.39457328, ACU_loss:1.57829311, Val_loss:1.88908082)\n",
      "epoch (1770 / 2000) (Train_loss:0.34174862, ACU_loss:1.36699449, Val_loss:1.98727123)\n",
      "epoch (1771 / 2000) (Train_loss:0.34073174, ACU_loss:1.36292696, Val_loss:2.02299690)\n",
      "epoch (1772 / 2000) (Train_loss:0.39560005, ACU_loss:1.58240021, Val_loss:1.93637375)\n",
      "epoch (1773 / 2000) (Train_loss:0.40929507, ACU_loss:1.63718027, Val_loss:1.88615970)\n",
      "epoch (1774 / 2000) (Train_loss:0.36510088, ACU_loss:1.46040352, Val_loss:1.89778470)\n",
      "epoch (1775 / 2000) (Train_loss:0.32999053, ACU_loss:1.31996212, Val_loss:1.98031056)\n",
      "epoch (1776 / 2000) (Train_loss:0.36592520, ACU_loss:1.46370081, Val_loss:1.98837319)\n",
      "epoch (1777 / 2000) (Train_loss:0.40416488, ACU_loss:1.61665950, Val_loss:1.87319823)\n",
      "epoch (1778 / 2000) (Train_loss:0.37928741, ACU_loss:1.51714963, Val_loss:1.89185167)\n",
      "epoch (1779 / 2000) (Train_loss:0.33936898, ACU_loss:1.35747592, Val_loss:1.93872095)\n",
      "epoch (1780 / 2000) (Train_loss:0.35501134, ACU_loss:1.42004537, Val_loss:1.94393289)\n",
      "epoch (1781 / 2000) (Train_loss:0.39937346, ACU_loss:1.59749386, Val_loss:1.90486989)\n",
      "epoch (1782 / 2000) (Train_loss:0.39019804, ACU_loss:1.56079215, Val_loss:1.83397843)\n",
      "epoch (1783 / 2000) (Train_loss:0.33869969, ACU_loss:1.35479878, Val_loss:1.92721779)\n",
      "epoch (1784 / 2000) (Train_loss:0.33291410, ACU_loss:1.33165642, Val_loss:1.96663326)\n",
      "epoch (1785 / 2000) (Train_loss:0.38751730, ACU_loss:1.55006920, Val_loss:1.88724642)\n",
      "epoch (1786 / 2000) (Train_loss:0.40641398, ACU_loss:1.62565593, Val_loss:1.83447712)\n",
      "epoch (1787 / 2000) (Train_loss:0.36257313, ACU_loss:1.45029254, Val_loss:1.84100881)\n",
      "epoch (1788 / 2000) (Train_loss:0.32343323, ACU_loss:1.29373292, Val_loss:1.92790507)\n",
      "epoch (1789 / 2000) (Train_loss:0.35835871, ACU_loss:1.43343483, Val_loss:1.93935901)\n",
      "epoch (1790 / 2000) (Train_loss:0.40009921, ACU_loss:1.60039685, Val_loss:1.82288140)\n",
      "epoch (1791 / 2000) (Train_loss:0.37780389, ACU_loss:1.51121557, Val_loss:1.83713984)\n",
      "epoch (1792 / 2000) (Train_loss:0.33489985, ACU_loss:1.33959938, Val_loss:1.88394612)\n",
      "epoch (1793 / 2000) (Train_loss:0.34742796, ACU_loss:1.38971183, Val_loss:1.89271403)\n",
      "epoch (1794 / 2000) (Train_loss:0.39331395, ACU_loss:1.57325578, Val_loss:1.85561770)\n",
      "epoch (1795 / 2000) (Train_loss:0.38505021, ACU_loss:1.54020085, Val_loss:1.78242811)\n",
      "epoch (1796 / 2000) (Train_loss:0.33305940, ACU_loss:1.33223762, Val_loss:1.87383224)\n",
      "epoch (1797 / 2000) (Train_loss:0.32570246, ACU_loss:1.30280985, Val_loss:1.91397166)\n",
      "epoch (1798 / 2000) (Train_loss:0.38003530, ACU_loss:1.52014120, Val_loss:1.83632438)\n",
      "epoch (1799 / 2000) (Train_loss:0.39994709, ACU_loss:1.59978837, Val_loss:1.78354991)\n",
      "epoch (1800 / 2000) (Train_loss:0.35548583, ACU_loss:1.42194333, Val_loss:1.79049493)\n",
      "epoch (1801 / 2000) (Train_loss:0.31548432, ACU_loss:1.26193729, Val_loss:1.87442562)\n",
      "epoch (1802 / 2000) (Train_loss:0.35055011, ACU_loss:1.40220044, Val_loss:1.88627510)\n",
      "epoch (1803 / 2000) (Train_loss:0.39162389, ACU_loss:1.56649556, Val_loss:1.77186172)\n",
      "epoch (1804 / 2000) (Train_loss:0.36902901, ACU_loss:1.47611604, Val_loss:1.78748414)\n",
      "epoch (1805 / 2000) (Train_loss:0.32611399, ACU_loss:1.30445596, Val_loss:1.83425099)\n",
      "epoch (1806 / 2000) (Train_loss:0.33923686, ACU_loss:1.35694744, Val_loss:1.83956639)\n",
      "epoch (1807 / 2000) (Train_loss:0.38435749, ACU_loss:1.53742995, Val_loss:1.80205522)\n",
      "epoch (1808 / 2000) (Train_loss:0.37454060, ACU_loss:1.49816239, Val_loss:1.73322740)\n",
      "epoch (1809 / 2000) (Train_loss:0.32289313, ACU_loss:1.29157253, Val_loss:1.82335335)\n",
      "epoch (1810 / 2000) (Train_loss:0.31739049, ACU_loss:1.26956194, Val_loss:1.86294230)\n",
      "epoch (1811 / 2000) (Train_loss:0.37157006, ACU_loss:1.48628024, Val_loss:1.78340805)\n",
      "epoch (1812 / 2000) (Train_loss:0.38947061, ACU_loss:1.55788244, Val_loss:1.73356555)\n",
      "epoch (1813 / 2000) (Train_loss:0.34444873, ACU_loss:1.37779493, Val_loss:1.74520911)\n",
      "epoch (1814 / 2000) (Train_loss:0.30727486, ACU_loss:1.22909943, Val_loss:1.82174389)\n",
      "epoch (1815 / 2000) (Train_loss:0.34397689, ACU_loss:1.37590755, Val_loss:1.83155114)\n",
      "epoch (1816 / 2000) (Train_loss:0.38141508, ACU_loss:1.52566033, Val_loss:1.72021875)\n",
      "epoch (1817 / 2000) (Train_loss:0.35635385, ACU_loss:1.42541539, Val_loss:1.74298220)\n",
      "epoch (1818 / 2000) (Train_loss:0.31587262, ACU_loss:1.26349050, Val_loss:1.79049245)\n",
      "epoch (1819 / 2000) (Train_loss:0.33369183, ACU_loss:1.33476733, Val_loss:1.78707760)\n",
      "epoch (1820 / 2000) (Train_loss:0.37706359, ACU_loss:1.50825437, Val_loss:1.74634463)\n",
      "epoch (1821 / 2000) (Train_loss:0.36311424, ACU_loss:1.45245697, Val_loss:1.68660371)\n",
      "epoch (1822 / 2000) (Train_loss:0.31183509, ACU_loss:1.24734036, Val_loss:1.77832408)\n",
      "epoch (1823 / 2000) (Train_loss:0.31138947, ACU_loss:1.24555787, Val_loss:1.81592025)\n",
      "epoch (1824 / 2000) (Train_loss:0.36660459, ACU_loss:1.46641835, Val_loss:1.72989673)\n",
      "epoch (1825 / 2000) (Train_loss:0.38012320, ACU_loss:1.52049280, Val_loss:1.68611537)\n",
      "epoch (1826 / 2000) (Train_loss:0.33316409, ACU_loss:1.33265637, Val_loss:1.70607286)\n",
      "epoch (1827 / 2000) (Train_loss:0.30180691, ACU_loss:1.20722764, Val_loss:1.77194888)\n",
      "epoch (1828 / 2000) (Train_loss:0.34192821, ACU_loss:1.36771283, Val_loss:1.77673217)\n",
      "epoch (1829 / 2000) (Train_loss:0.37256466, ACU_loss:1.49025864, Val_loss:1.66894193)\n",
      "epoch (1830 / 2000) (Train_loss:0.34255830, ACU_loss:1.37023318, Val_loss:1.70508140)\n",
      "epoch (1831 / 2000) (Train_loss:0.30642999, ACU_loss:1.22571996, Val_loss:1.75344875)\n",
      "epoch (1832 / 2000) (Train_loss:0.33266979, ACU_loss:1.33067914, Val_loss:1.73583586)\n",
      "epoch (1833 / 2000) (Train_loss:0.37324626, ACU_loss:1.49298503, Val_loss:1.68926221)\n",
      "epoch (1834 / 2000) (Train_loss:0.35219894, ACU_loss:1.40879576, Val_loss:1.64392947)\n",
      "epoch (1835 / 2000) (Train_loss:0.30121870, ACU_loss:1.20487481, Val_loss:1.73809170)\n",
      "epoch (1836 / 2000) (Train_loss:0.30888706, ACU_loss:1.23554822, Val_loss:1.77176691)\n",
      "epoch (1837 / 2000) (Train_loss:0.36496640, ACU_loss:1.45986558, Val_loss:1.67604798)\n",
      "epoch (1838 / 2000) (Train_loss:0.37138225, ACU_loss:1.48552902, Val_loss:1.64364887)\n",
      "epoch (1839 / 2000) (Train_loss:0.32189163, ACU_loss:1.28756651, Val_loss:1.67363447)\n",
      "epoch (1840 / 2000) (Train_loss:0.29996021, ACU_loss:1.19984083, Val_loss:1.72400045)\n",
      "epoch (1841 / 2000) (Train_loss:0.34388592, ACU_loss:1.37554369, Val_loss:1.71998030)\n",
      "epoch (1842 / 2000) (Train_loss:0.36366387, ACU_loss:1.45465548, Val_loss:1.61930182)\n",
      "epoch (1843 / 2000) (Train_loss:0.32681517, ACU_loss:1.30726067, Val_loss:1.67320025)\n",
      "epoch (1844 / 2000) (Train_loss:0.29792925, ACU_loss:1.19171701, Val_loss:1.72141742)\n",
      "epoch (1845 / 2000) (Train_loss:0.33481757, ACU_loss:1.33927030, Val_loss:1.68448012)\n",
      "epoch (1846 / 2000) (Train_loss:0.37032602, ACU_loss:1.48130407, Val_loss:1.63210448)\n",
      "epoch (1847 / 2000) (Train_loss:0.34014721, ACU_loss:1.36058883, Val_loss:1.60692644)\n",
      "epoch (1848 / 2000) (Train_loss:0.29103037, ACU_loss:1.16412146, Val_loss:1.69869289)\n",
      "epoch (1849 / 2000) (Train_loss:0.30932873, ACU_loss:1.23731492, Val_loss:1.72645125)\n",
      "epoch (1850 / 2000) (Train_loss:0.36304496, ACU_loss:1.45217984, Val_loss:1.62186217)\n",
      "epoch (1851 / 2000) (Train_loss:0.35942819, ACU_loss:1.43771275, Val_loss:1.60850874)\n",
      "epoch (1852 / 2000) (Train_loss:0.30966847, ACU_loss:1.23867388, Val_loss:1.64736216)\n",
      "epoch (1853 / 2000) (Train_loss:0.30184275, ACU_loss:1.20737100, Val_loss:1.67693930)\n",
      "epoch (1854 / 2000) (Train_loss:0.34772577, ACU_loss:1.39090308, Val_loss:1.65960548)\n",
      "epoch (1855 / 2000) (Train_loss:0.35316460, ACU_loss:1.41265842, Val_loss:1.57305730)\n",
      "epoch (1856 / 2000) (Train_loss:0.30935707, ACU_loss:1.23742827, Val_loss:1.64537094)\n",
      "epoch (1857 / 2000) (Train_loss:0.29137348, ACU_loss:1.16549394, Val_loss:1.69150773)\n",
      "epoch (1858 / 2000) (Train_loss:0.33877782, ACU_loss:1.35511127, Val_loss:1.63181383)\n",
      "epoch (1859 / 2000) (Train_loss:0.36607057, ACU_loss:1.46428228, Val_loss:1.57879719)\n",
      "epoch (1860 / 2000) (Train_loss:0.32615992, ACU_loss:1.30463969, Val_loss:1.57714990)\n",
      "epoch (1861 / 2000) (Train_loss:0.28274806, ACU_loss:1.13099224, Val_loss:1.65714286)\n",
      "epoch (1862 / 2000) (Train_loss:0.31261419, ACU_loss:1.25045674, Val_loss:1.67652089)\n",
      "epoch (1863 / 2000) (Train_loss:0.35771509, ACU_loss:1.43086035, Val_loss:1.56832040)\n",
      "epoch (1864 / 2000) (Train_loss:0.34163776, ACU_loss:1.36655104, Val_loss:1.58098936)\n",
      "epoch (1865 / 2000) (Train_loss:0.29657819, ACU_loss:1.18631278, Val_loss:1.62601059)\n",
      "epoch (1866 / 2000) (Train_loss:0.30705158, ACU_loss:1.22820633, Val_loss:1.63019931)\n",
      "epoch (1867 / 2000) (Train_loss:0.35128533, ACU_loss:1.40514133, Val_loss:1.59622316)\n",
      "epoch (1868 / 2000) (Train_loss:0.34095533, ACU_loss:1.36382131, Val_loss:1.53263539)\n",
      "epoch (1869 / 2000) (Train_loss:0.29231035, ACU_loss:1.16924142, Val_loss:1.61877280)\n",
      "epoch (1870 / 2000) (Train_loss:0.28877617, ACU_loss:1.15510467, Val_loss:1.65998948)\n",
      "epoch (1871 / 2000) (Train_loss:0.34355055, ACU_loss:1.37420219, Val_loss:1.57754983)\n",
      "epoch (1872 / 2000) (Train_loss:0.35926458, ACU_loss:1.43705833, Val_loss:1.53532354)\n",
      "epoch (1873 / 2000) (Train_loss:0.31132173, ACU_loss:1.24528691, Val_loss:1.55550622)\n",
      "epoch (1874 / 2000) (Train_loss:0.27990557, ACU_loss:1.11962227, Val_loss:1.61421752)\n",
      "epoch (1875 / 2000) (Train_loss:0.31962008, ACU_loss:1.27848031, Val_loss:1.62056512)\n",
      "epoch (1876 / 2000) (Train_loss:0.34855606, ACU_loss:1.39422423, Val_loss:1.51769638)\n",
      "epoch (1877 / 2000) (Train_loss:0.31892113, ACU_loss:1.27568452, Val_loss:1.55943752)\n",
      "epoch (1878 / 2000) (Train_loss:0.28442141, ACU_loss:1.13768562, Val_loss:1.60786123)\n",
      "epoch (1879 / 2000) (Train_loss:0.31452632, ACU_loss:1.25810529, Val_loss:1.58218324)\n",
      "epoch (1880 / 2000) (Train_loss:0.35258361, ACU_loss:1.41033444, Val_loss:1.53357798)\n",
      "epoch (1881 / 2000) (Train_loss:0.32684684, ACU_loss:1.30738736, Val_loss:1.50076204)\n",
      "epoch (1882 / 2000) (Train_loss:0.27757483, ACU_loss:1.11029933, Val_loss:1.58888673)\n",
      "epoch (1883 / 2000) (Train_loss:0.29097550, ACU_loss:1.16390201, Val_loss:1.62206650)\n",
      "epoch (1884 / 2000) (Train_loss:0.34578376, ACU_loss:1.38313504, Val_loss:1.52244721)\n",
      "epoch (1885 / 2000) (Train_loss:0.34663789, ACU_loss:1.38655155, Val_loss:1.50551448)\n",
      "epoch (1886 / 2000) (Train_loss:0.29638836, ACU_loss:1.18555344, Val_loss:1.54138086)\n",
      "epoch (1887 / 2000) (Train_loss:0.28494261, ACU_loss:1.13977043, Val_loss:1.57242666)\n",
      "epoch (1888 / 2000) (Train_loss:0.32961547, ACU_loss:1.31846188, Val_loss:1.55847524)\n",
      "epoch (1889 / 2000) (Train_loss:0.33737397, ACU_loss:1.34949586, Val_loss:1.47314801)\n",
      "epoch (1890 / 2000) (Train_loss:0.29575000, ACU_loss:1.18299998, Val_loss:1.54167869)\n",
      "epoch (1891 / 2000) (Train_loss:0.27700492, ACU_loss:1.10801970, Val_loss:1.58994066)\n",
      "epoch (1892 / 2000) (Train_loss:0.32360217, ACU_loss:1.29440869, Val_loss:1.53116821)\n",
      "epoch (1893 / 2000) (Train_loss:0.35041724, ACU_loss:1.40166896, Val_loss:1.47936587)\n",
      "epoch (1894 / 2000) (Train_loss:0.31103913, ACU_loss:1.24415653, Val_loss:1.47927227)\n",
      "epoch (1895 / 2000) (Train_loss:0.26790110, ACU_loss:1.07160442, Val_loss:1.55235252)\n",
      "epoch (1896 / 2000) (Train_loss:0.29786380, ACU_loss:1.19145521, Val_loss:1.57315066)\n",
      "epoch (1897 / 2000) (Train_loss:0.34094571, ACU_loss:1.36378283, Val_loss:1.46899122)\n",
      "epoch (1898 / 2000) (Train_loss:0.32400482, ACU_loss:1.29601928, Val_loss:1.48549163)\n",
      "epoch (1899 / 2000) (Train_loss:0.28076767, ACU_loss:1.12307068, Val_loss:1.53094629)\n",
      "epoch (1900 / 2000) (Train_loss:0.29438933, ACU_loss:1.17755733, Val_loss:1.53003256)\n",
      "epoch (1901 / 2000) (Train_loss:0.33698135, ACU_loss:1.34792542, Val_loss:1.49331921)\n",
      "epoch (1902 / 2000) (Train_loss:0.32413938, ACU_loss:1.29655750, Val_loss:1.43828025)\n",
      "epoch (1903 / 2000) (Train_loss:0.27640812, ACU_loss:1.10563248, Val_loss:1.52261854)\n",
      "epoch (1904 / 2000) (Train_loss:0.27676777, ACU_loss:1.10707109, Val_loss:1.56395873)\n",
      "epoch (1905 / 2000) (Train_loss:0.33248512, ACU_loss:1.32994050, Val_loss:1.47780876)\n",
      "epoch (1906 / 2000) (Train_loss:0.34473740, ACU_loss:1.37894961, Val_loss:1.44309281)\n",
      "epoch (1907 / 2000) (Train_loss:0.29545594, ACU_loss:1.18182377, Val_loss:1.46897047)\n",
      "epoch (1908 / 2000) (Train_loss:0.27000525, ACU_loss:1.08002101, Val_loss:1.51686602)\n",
      "epoch (1909 / 2000) (Train_loss:0.31133484, ACU_loss:1.24533936, Val_loss:1.51692460)\n",
      "epoch (1910 / 2000) (Train_loss:0.33358837, ACU_loss:1.33435348, Val_loss:1.42172253)\n",
      "epoch (1911 / 2000) (Train_loss:0.29984659, ACU_loss:1.19938635, Val_loss:1.47370801)\n",
      "epoch (1912 / 2000) (Train_loss:0.27115716, ACU_loss:1.08462863, Val_loss:1.52357273)\n",
      "epoch (1913 / 2000) (Train_loss:0.30896633, ACU_loss:1.23586530, Val_loss:1.48500592)\n",
      "epoch (1914 / 2000) (Train_loss:0.34313278, ACU_loss:1.37253111, Val_loss:1.43316424)\n",
      "epoch (1915 / 2000) (Train_loss:0.31047242, ACU_loss:1.24188969, Val_loss:1.41618436)\n",
      "epoch (1916 / 2000) (Train_loss:0.26308678, ACU_loss:1.05234713, Val_loss:1.49706604)\n",
      "epoch (1917 / 2000) (Train_loss:0.28402451, ACU_loss:1.13609804, Val_loss:1.52628233)\n",
      "epoch (1918 / 2000) (Train_loss:0.33536111, ACU_loss:1.34144445, Val_loss:1.42425775)\n",
      "epoch (1919 / 2000) (Train_loss:0.32849361, ACU_loss:1.31397445, Val_loss:1.42448217)\n",
      "epoch (1920 / 2000) (Train_loss:0.28041993, ACU_loss:1.12167973, Val_loss:1.46587231)\n",
      "epoch (1921 / 2000) (Train_loss:0.28170559, ACU_loss:1.12682237, Val_loss:1.48034240)\n",
      "epoch (1922 / 2000) (Train_loss:0.32595347, ACU_loss:1.30381389, Val_loss:1.45295335)\n",
      "epoch (1923 / 2000) (Train_loss:0.32254358, ACU_loss:1.29017433, Val_loss:1.38490396)\n",
      "epoch (1924 / 2000) (Train_loss:0.27631298, ACU_loss:1.10525194, Val_loss:1.46198224)\n",
      "epoch (1925 / 2000) (Train_loss:0.26789624, ACU_loss:1.07158495, Val_loss:1.50903569)\n",
      "epoch (1926 / 2000) (Train_loss:0.32021590, ACU_loss:1.28086359, Val_loss:1.43438124)\n",
      "epoch (1927 / 2000) (Train_loss:0.33908481, ACU_loss:1.35633926, Val_loss:1.39096054)\n",
      "epoch (1928 / 2000) (Train_loss:0.29391019, ACU_loss:1.17564074, Val_loss:1.40554244)\n",
      "epoch (1929 / 2000) (Train_loss:0.25839742, ACU_loss:1.03358970, Val_loss:1.46236032)\n",
      "epoch (1930 / 2000) (Train_loss:0.29509562, ACU_loss:1.18038247, Val_loss:1.47234092)\n",
      "epoch (1931 / 2000) (Train_loss:0.32598809, ACU_loss:1.30395236, Val_loss:1.37552651)\n",
      "epoch (1932 / 2000) (Train_loss:0.29873107, ACU_loss:1.19492428, Val_loss:1.41094692)\n",
      "epoch (1933 / 2000) (Train_loss:0.26394739, ACU_loss:1.05578954, Val_loss:1.45987813)\n",
      "epoch (1934 / 2000) (Train_loss:0.29181997, ACU_loss:1.16727988, Val_loss:1.43824951)\n",
      "epoch (1935 / 2000) (Train_loss:0.32932088, ACU_loss:1.31728351, Val_loss:1.39127428)\n",
      "epoch (1936 / 2000) (Train_loss:0.30560182, ACU_loss:1.22240728, Val_loss:1.36062365)\n",
      "epoch (1937 / 2000) (Train_loss:0.25804910, ACU_loss:1.03219641, Val_loss:1.44136423)\n",
      "epoch (1938 / 2000) (Train_loss:0.27035387, ACU_loss:1.08141547, Val_loss:1.47641420)\n",
      "epoch (1939 / 2000) (Train_loss:0.32463294, ACU_loss:1.29853177, Val_loss:1.38221758)\n",
      "epoch (1940 / 2000) (Train_loss:0.32575052, ACU_loss:1.30300208, Val_loss:1.36843918)\n",
      "epoch (1941 / 2000) (Train_loss:0.27716798, ACU_loss:1.10867192, Val_loss:1.40442784)\n",
      "epoch (1942 / 2000) (Train_loss:0.26791749, ACU_loss:1.07166997, Val_loss:1.43156701)\n",
      "epoch (1943 / 2000) (Train_loss:0.31116611, ACU_loss:1.24466444, Val_loss:1.41369991)\n",
      "epoch (1944 / 2000) (Train_loss:0.31798945, ACU_loss:1.27195780, Val_loss:1.33721829)\n",
      "epoch (1945 / 2000) (Train_loss:0.27584419, ACU_loss:1.10337675, Val_loss:1.40383524)\n",
      "epoch (1946 / 2000) (Train_loss:0.25998197, ACU_loss:1.03992790, Val_loss:1.45378605)\n",
      "epoch (1947 / 2000) (Train_loss:0.30840651, ACU_loss:1.23362602, Val_loss:1.39341618)\n",
      "epoch (1948 / 2000) (Train_loss:0.33352450, ACU_loss:1.33409800, Val_loss:1.34491693)\n",
      "epoch (1949 / 2000) (Train_loss:0.29199189, ACU_loss:1.16796756, Val_loss:1.35034059)\n",
      "epoch (1950 / 2000) (Train_loss:0.25186199, ACU_loss:1.00744794, Val_loss:1.41612843)\n",
      "epoch (1951 / 2000) (Train_loss:0.28320493, ACU_loss:1.13281973, Val_loss:1.43275863)\n",
      "epoch (1952 / 2000) (Train_loss:0.32349313, ACU_loss:1.29397253, Val_loss:1.33407186)\n",
      "epoch (1953 / 2000) (Train_loss:0.30376958, ACU_loss:1.21507832, Val_loss:1.35933194)\n",
      "epoch (1954 / 2000) (Train_loss:0.26371191, ACU_loss:1.05484762, Val_loss:1.40701057)\n",
      "epoch (1955 / 2000) (Train_loss:0.28391871, ACU_loss:1.13567483, Val_loss:1.39721375)\n",
      "epoch (1956 / 2000) (Train_loss:0.32450048, ACU_loss:1.29800193, Val_loss:1.35369508)\n",
      "epoch (1957 / 2000) (Train_loss:0.30716055, ACU_loss:1.22864221, Val_loss:1.31201474)\n",
      "epoch (1958 / 2000) (Train_loss:0.25714477, ACU_loss:1.02857906, Val_loss:1.39108299)\n",
      "epoch (1959 / 2000) (Train_loss:0.26290979, ACU_loss:1.05163916, Val_loss:1.43332400)\n",
      "epoch (1960 / 2000) (Train_loss:0.31720382, ACU_loss:1.26881526, Val_loss:1.34440307)\n",
      "epoch (1961 / 2000) (Train_loss:0.32430940, ACU_loss:1.29723759, Val_loss:1.32045527)\n",
      "epoch (1962 / 2000) (Train_loss:0.27677261, ACU_loss:1.10709045, Val_loss:1.34800287)\n",
      "epoch (1963 / 2000) (Train_loss:0.25664363, ACU_loss:1.02657450, Val_loss:1.38661695)\n",
      "epoch (1964 / 2000) (Train_loss:0.29854130, ACU_loss:1.19416520, Val_loss:1.37759636)\n",
      "epoch (1965 / 2000) (Train_loss:0.31404108, ACU_loss:1.25616432, Val_loss:1.29506339)\n",
      "epoch (1966 / 2000) (Train_loss:0.27607496, ACU_loss:1.10429985, Val_loss:1.34946525)\n",
      "epoch (1967 / 2000) (Train_loss:0.25257406, ACU_loss:1.01029623, Val_loss:1.39985299)\n",
      "epoch (1968 / 2000) (Train_loss:0.29395539, ACU_loss:1.17582156, Val_loss:1.35535498)\n",
      "epoch (1969 / 2000) (Train_loss:0.32406201, ACU_loss:1.29624805, Val_loss:1.30525426)\n",
      "epoch (1970 / 2000) (Train_loss:0.28925106, ACU_loss:1.15700423, Val_loss:1.29904054)\n",
      "epoch (1971 / 2000) (Train_loss:0.24603498, ACU_loss:0.98413993, Val_loss:1.37035081)\n",
      "epoch (1972 / 2000) (Train_loss:0.26924279, ACU_loss:1.07697115, Val_loss:1.39349728)\n",
      "epoch (1973 / 2000) (Train_loss:0.31689905, ACU_loss:1.26759619, Val_loss:1.29786425)\n",
      "epoch (1974 / 2000) (Train_loss:0.30580684, ACU_loss:1.22322735, Val_loss:1.30788455)\n",
      "epoch (1975 / 2000) (Train_loss:0.26224701, ACU_loss:1.04898803, Val_loss:1.35015875)\n",
      "epoch (1976 / 2000) (Train_loss:0.27010610, ACU_loss:1.08042440, Val_loss:1.35742451)\n",
      "epoch (1977 / 2000) (Train_loss:0.31246807, ACU_loss:1.24987227, Val_loss:1.32244994)\n",
      "epoch (1978 / 2000) (Train_loss:0.30518135, ACU_loss:1.22072540, Val_loss:1.26750311)\n",
      "epoch (1979 / 2000) (Train_loss:0.25640352, ACU_loss:1.02561406, Val_loss:1.34014408)\n",
      "epoch (1980 / 2000) (Train_loss:0.25252355, ACU_loss:1.01009420, Val_loss:1.38849357)\n",
      "epoch (1981 / 2000) (Train_loss:0.30457471, ACU_loss:1.21829882, Val_loss:1.31109476)\n",
      "epoch (1982 / 2000) (Train_loss:0.31888283, ACU_loss:1.27553132, Val_loss:1.27554604)\n",
      "epoch (1983 / 2000) (Train_loss:0.27615075, ACU_loss:1.10460301, Val_loss:1.29282893)\n",
      "epoch (1984 / 2000) (Train_loss:0.24500389, ACU_loss:0.98001556, Val_loss:1.34328549)\n",
      "epoch (1985 / 2000) (Train_loss:0.28222821, ACU_loss:1.12891282, Val_loss:1.34533923)\n",
      "epoch (1986 / 2000) (Train_loss:0.30928070, ACU_loss:1.23712279, Val_loss:1.25850851)\n",
      "epoch (1987 / 2000) (Train_loss:0.27889878, ACU_loss:1.11559510, Val_loss:1.29692027)\n",
      "epoch (1988 / 2000) (Train_loss:0.24734030, ACU_loss:0.98936120, Val_loss:1.34578769)\n",
      "epoch (1989 / 2000) (Train_loss:0.27782008, ACU_loss:1.11128031, Val_loss:1.32085025)\n",
      "epoch (1990 / 2000) (Train_loss:0.31313004, ACU_loss:1.25252015, Val_loss:1.27362747)\n",
      "epoch (1991 / 2000) (Train_loss:0.28933064, ACU_loss:1.15732255, Val_loss:1.25046635)\n",
      "epoch (1992 / 2000) (Train_loss:0.24330351, ACU_loss:0.97321403, Val_loss:1.32455473)\n",
      "epoch (1993 / 2000) (Train_loss:0.25607134, ACU_loss:1.02428534, Val_loss:1.35734297)\n",
      "epoch (1994 / 2000) (Train_loss:0.30835176, ACU_loss:1.23340703, Val_loss:1.26815019)\n",
      "epoch (1995 / 2000) (Train_loss:0.30766240, ACU_loss:1.23064961, Val_loss:1.25881280)\n",
      "epoch (1996 / 2000) (Train_loss:0.26256163, ACU_loss:1.05024650, Val_loss:1.29274888)\n",
      "epoch (1997 / 2000) (Train_loss:0.25433990, ACU_loss:1.01735961, Val_loss:1.31988059)\n",
      "epoch (1998 / 2000) (Train_loss:0.29629313, ACU_loss:1.18517250, Val_loss:1.29805376)\n",
      "epoch (1999 / 2000) (Train_loss:0.30423376, ACU_loss:1.21693506, Val_loss:1.22840791)\n",
      "epoch (2000 / 2000) (Train_loss:0.26114763, ACU_loss:1.04459051, Val_loss:1.28932321)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = myDataset(com_train, train_orig, past_wafer, future_step)\n",
    "test_dataset = myDataset(com_test, test_extend, past_wafer, future_step)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "# split training and validation dataset\n",
    "train_dataloader, val_dataloader = get_loaders(train_dataset, seed, batch_size, val_ratio)\n",
    "\n",
    "# establish the model\n",
    "model = GRUmodel(input_dim, inter_dim, layer_num).to('cuda')\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "# save path of the best model\n",
    "now = datetime.now()\n",
    "datestr = now.strftime('%m_%d-%H_%M_%S')\n",
    "save_path = f'./save_path/{datestr}.pt'\n",
    "\n",
    "# start training\n",
    "train(model, train_dataloader, val_dataloader, optimizer, 2000, 'cuda', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  20.458\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the best model for testing\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "best_model = model.to('cuda')\n",
    "avg_loss, test_list = test(best_model, test_dataloader, 'cuda')\n",
    "print('MSE : ', round(avg_loss, 3))\n",
    "\n",
    "# plot the result\n",
    "y_train = train_orig\n",
    "y_pred = test_list[0]\n",
    "y_truth = test_list[1]\n",
    "\n",
    "plt.figure(figsize=(15, 2), dpi=100)\n",
    "plt.plot(range(y_train.shape[0]), y_train, label='Train')\n",
    "plt.plot(range(y_train.shape[0], y_train.shape[0] + len(y_truth)), y_truth, label='Test')\n",
    "plt.plot(range(y_train.shape[0], y_train.shape[0] + len(y_truth)), y_pred, label='pred')\n",
    "plt.title(dataset)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wuenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
